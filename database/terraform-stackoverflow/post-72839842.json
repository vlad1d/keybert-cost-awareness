{"Id": "72839842", "PostTypeId": "1", "AcceptedAnswerId": "72872305", "CreationDate": "2022-07-02T14:29:32.553", "Score": "3", "ViewCount": "923", "Body": "<p>I have a rather interesting situation that I'm trying to figure out how to configure on AWS ECS/EC2.</p>\n<p>I have a Dockerized application with the following requirements:</p>\n<ul>\n<li>Very low CPU usage (~256 CPU)</li>\n<li>Moderate memory usage (~256 MB)</li>\n<li>Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container).</li>\n</ul>\n<p>Fargate is not an option due to the cost, so we're looking at EC2-based solutions.</p>\n<p>Since the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (<code>t4g.nano</code>, <code>t3a.nano</code>, etc.), and either the <code>host</code> or <code>bridge</code> networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). This gives me a 1-to-1 mapping of hosts to containers, which is what I need.</p>\n<p>The issue is, how do I set up ECS cluster-managed autoscaling for this?</p>\n<p>I've configured an EC2 auto-scaling group (Terraform):</p>\n<pre><code>resource &quot;aws_autoscaling_group&quot; &quot;ecs&quot; {\n  name                = &quot;ecs&quot;\n  vpc_zone_identifier = var.subnet_ids\n  min_size            = 1\n  max_size            = 20\n  capacity_rebalance  = true\n  default_cooldown    = 0\n  health_check_type   = &quot;EC2&quot;\n  mixed_instances_policy {\n    ...\n  }\n  instance_refresh {\n    strategy = &quot;Rolling&quot;\n  }\n}\n</code></pre>\n<p>I've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling:</p>\n<pre><code>resource &quot;aws_ecs_capacity_provider&quot; &quot;ec2&quot; {\n  name = &quot;ec2&quot;\n  auto_scaling_group_provider {\n    auto_scaling_group_arn = aws_autoscaling_group.ecs.arn\n    managed_scaling {\n      target_capacity           = 100\n      instance_warmup_period    = 30\n      minimum_scaling_step_size = 1\n      maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size\n      status                    = &quot;ENABLED&quot;\n    }\n    managed_termination_protection = &quot;DISABLED&quot;\n  }\n}\n</code></pre>\n<p>I've configured this capacity provider as the one and only provider for the ECS cluster:</p>\n<pre><code>resource &quot;aws_ecs_cluster_capacity_providers&quot; &quot;this&quot; {\n  cluster_name = aws_ecs_cluster.this.name\n  capacity_providers = [\n    aws_ecs_capacity_provider.ec2.name\n  ]\n  default_capacity_provider_strategy {\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\n    weight            = 100\n    base              = 0\n  }\n}\n</code></pre>\n<p>I've set up an ECS service:</p>\n<pre><code>resource &quot;aws_ecs_service&quot; &quot;this&quot; {\n  name            = local.task_family\n  cluster         = aws_ecs_cluster.this.id\n  task_definition = aws_ecs_task_definition.this.arn\n  desired_count   = 1\n  launch_type     = &quot;EC2&quot;\n  lifecycle {\n    ignore_changes = [desired_count]\n  }\n}\n</code></pre>\n<p>I've set up an App Autoscaling Target for the ECS service:</p>\n<pre><code>resource &quot;aws_appautoscaling_target&quot; &quot;ecs&quot; {\n  min_capacity       = 5\n  max_capacity       = 20\n  resource_id        = &quot;service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}&quot;\n  scalable_dimension = &quot;ecs:service:DesiredCount&quot;\n  service_namespace  = &quot;ecs&quot;\n}\n</code></pre>\n<p>And I've set up an App Autoscaling Policy for that target:</p>\n<pre><code>resource &quot;aws_appautoscaling_policy&quot; &quot;ecs_policy&quot; {\n  name               = &quot;ecs-scaling&quot;\n  policy_type        = &quot;TargetTrackingScaling&quot;\n  resource_id        = aws_appautoscaling_target.ecs.resource_id\n  scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension\n  service_namespace  = aws_appautoscaling_target.ecs.service_namespace\n\n  target_tracking_scaling_policy_configuration {\n    target_value       = 70\n    scale_in_cooldown  = 0\n    scale_out_cooldown = 0\n    predefined_metric_specification {\n      predefined_metric_type = &quot;ECSServiceAverageCPUUtilization&quot;\n    }\n  }\n}\n</code></pre>\n<p>This &quot;works&quot; in the sense that it deploys, the service runs, and my application is functional. However, the scaling is not working. As you can see in the <code>aws_autoscaling_group</code>, I've set the minimum to 1 instance and the maximum to 20 instances. In the <code>aws_appautoscaling_target</code>, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1).</p>\n<p>When I deploy this, the ECS service in the AWS console shows:</p>\n<ul>\n<li>Desired count: 5</li>\n<li>Pending count: 0</li>\n<li>Running count: 1</li>\n</ul>\n<p>And in the events log, it says:</p>\n<blockquote>\n<p>service my-service was unable to place a task because no container instance met all of its requirements. The closest matching container-instance xyzabc1234 has insufficient memory available.</p>\n</blockquote>\n<p>So it's trying to achieve the desired minimum number of containers (5), and it's recognizing that there are insufficient EC2 instances, but for some reason (and this is what I can't figure out) it's not scaling out the number of EC2 instances to meet the desired container count.</p>\n<p>From <a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html#how-it-works\" rel=\"nofollow noreferrer\">AWS's documentation</a>, it says:</p>\n<blockquote>\n<p>When launched tasks cannot be placed on available instances, the Auto Scaling group scales-out by launching new instances. When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks.</p>\n</blockquote>\n<p>Since the launched tasks cannot be placed on any of the available instances, it would seem that it <em>should</em> automatically scale out the Auto Scaling Group.</p>\n<p>Any ideas on why it's failing to do so?</p>\n", "OwnerUserId": "612580", "LastEditorUserId": "612580", "LastEditDate": "2022-07-02T16:49:54.663", "LastActivityDate": "2022-07-05T15:52:10.640", "Title": "AWS ECS: Auto-Scaling an EC2 Auto-Scaling Group with Single-Container Hosts", "Tags": "<amazon-web-services><amazon-ec2><terraform><amazon-ecs><autoscaling>", "AnswerCount": "1", "CommentCount": "0", "FavoriteCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "273437340", "PostHistoryTypeId": "2", "PostId": "72839842", "RevisionGUID": "f979c3e4-e058-459e-bfff-f188681333be", "CreationDate": "2022-07-02T14:29:32.553", "UserId": "612580", "Text": "I have a rather interesting situation that I'm trying to figure out how to configure on AWS ECS/EC2.\r\n\r\nI have a Dockerized application with the following requirements:\r\n- Very low CPU usage (~256 CPU)\r\n- Moderate memory usage (~256 MB)\r\n- Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container).\r\n\r\nFargate is not an option due to the cost, so we're looking at EC2-based solutions.\r\n\r\nSince the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). This gives me a 1-to-1 mapping of hosts to containers, which is what I need.\r\n\r\nThe issue is, how do I set up ECS cluster-managed autoscaling for this? \r\n\r\nI've configured an EC2 auto-scaling group (Terraform):\r\n```\r\nresource \"aws_autoscaling_group\" \"ecs\" {\r\n  name                = \"ecs\"\r\n  vpc_zone_identifier = var.subnet_ids\r\n  min_size            = 1\r\n  max_size            = 20\r\n  capacity_rebalance  = true\r\n  default_cooldown    = 0\r\n  health_check_type   = \"EC2\"\r\n  mixed_instances_policy {\r\n    ...\r\n  }\r\n  instance_refresh {\r\n    strategy = \"Rolling\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling:\r\n```\r\nresource \"aws_ecs_capacity_provider\" \"ec2\" {\r\n  name = \"ec2\"\r\n  auto_scaling_group_provider {\r\n    auto_scaling_group_arn = aws_autoscaling_group.ecs.arn\r\n    managed_scaling {\r\n      target_capacity           = 100\r\n      instance_warmup_period    = 30\r\n      minimum_scaling_step_size = 1\r\n      maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size\r\n      status                    = \"ENABLED\"\r\n    }\r\n    managed_termination_protection = \"DISABLED\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured this capacity provider as the one and only provider for the ECS cluster:\r\n```\r\nresource \"aws_ecs_cluster_capacity_providers\" \"this\" {\r\n  cluster_name = aws_ecs_cluster.this.name\r\n  capacity_providers = [\r\n    aws_ecs_capacity_provider.ec2.name\r\n  ]\r\n  default_capacity_provider_strategy {\r\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\r\n    weight            = 100\r\n    base              = 0\r\n  }\r\n}\r\n```\r\n\r\nI've set up an ECS service:\r\n```\r\nresource \"aws_ecs_service\" \"this\" {\r\n  name            = local.task_family\r\n  cluster         = aws_ecs_cluster.this.id\r\n  task_definition = aws_ecs_task_definition.this.arn\r\n  desired_count   = 1\r\n  launch_type     = \"EC2\"\r\n  lifecycle {\r\n    ignore_changes = [desired_count]\r\n  }\r\n}\r\n```\r\n\r\nI've set up an App Autoscaling Target for the ECS service:\r\n```\r\nresource \"aws_appautoscaling_target\" \"ecs\" {\r\n  min_capacity       = 5\r\n  max_capacity       = 20\r\n  resource_id        = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\"\r\n  scalable_dimension = \"ecs:service:DesiredCount\"\r\n  service_namespace  = \"ecs\"\r\n}\r\n```\r\n\r\nAnd I've set up an App Autoscaling Policy for that target:\r\n```\r\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\r\n  name               = \"ecs-scaling\"\r\n  policy_type        = \"TargetTrackingScaling\"\r\n  resource_id        = aws_appautoscaling_target.ecs.resource_id\r\n  scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension\r\n  service_namespace  = aws_appautoscaling_target.ecs.service_namespace\r\n\r\n  target_tracking_scaling_policy_configuration {\r\n    target_value       = 70\r\n    scale_in_cooldown  = 0\r\n    scale_out_cooldown = 0\r\n    predefined_metric_specification {\r\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis \"works\" in the sense that it deploys, the service runs, and my application is functional. However, the scaling is not working. As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1).\r\n\r\nWhen I deploy this, the ECS service in the AWS console shows:\r\n- Desired count: 5\r\n- Pending count: 0\r\n- Running count: 1\r\n\r\nAnd in the events log, it says:\r\n> service my-service was unable to place a task because no container instance met all of its requirements. The closest matching container-instance xyzabc1234 has insufficient memory available.\r\n\r\nSo it's trying to achieve the desired minimum number of containers (5), and it's recognizing that there are insufficient EC2 instances, but for some reason (and this is what I can't figure out) it's not scaling out the number of EC2 instances to meet the desired container count.\r\n\r\nAny ideas on why that is?", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "I have a Dockerized application with the following requirements: - Very low CPU usage (~256 CPU) - Moderate memory usage (~256 MB) - Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container). ", "keywords": ["cpu"]}, {"source": "Text", "text": "Fargate is not an option due to the cost, so we're looking at EC2-based solutions. ", "keywords": ["cost"]}, {"source": "Text", "text": "Since the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). ", "keywords": ["networking", "cpu", "provider", "billing mode"]}, {"source": "Text", "text": "The issue is, how do I set up ECS cluster-managed autoscaling for this? ", "keywords": ["cluster"]}, {"source": "Text", "text": "I've configured an EC2 auto-scaling group (Terraform): ``` resource \"aws_autoscaling_group\" \"ecs\" { name = \"ecs\" vpc_zone_identifier = var.subnet_ids min_size = 1 max_size = 20 capacity_rebalance = true default_cooldown = 0 health_check_type = \"EC2\" mixed_instances_policy { ... } instance_refresh { strategy = \"Rolling\" } } ``` I've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling: ``` resource \"aws_ecs_capacity_provider\" \"ec2\" { name = \"ec2\" auto_scaling_group_provider { auto_scaling_group_arn = aws_autoscaling_group.ecs.arn managed_scaling { target_capacity = 100 instance_warmup_period = 30 minimum_scaling_step_size = 1 maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size status = \"ENABLED\" } managed_termination_protection = \"DISABLED\" } } ``` I've configured this capacity provider as the one and only provider for the ECS cluster: ``` resource \"aws_ecs_cluster_capacity_providers\" \"this\" { cluster_name = aws_ecs_cluster.this.name capacity_providers = [ aws_ecs_capacity_provider.ec2.name ] default_capacity_provider_strategy { capacity_provider = aws_ecs_capacity_provider.ec2.name weight = 100 base = 0 } } ``` I've set up an ECS service: ``` resource \"aws_ecs_service\" \"this\" { name = local.task_family cluster = aws_ecs_cluster.this.id task_definition = aws_ecs_task_definition.this.arn desired_count = 1 launch_type = \"EC2\" lifecycle { ignore_changes = [desired_count] } } ``` I've set up an App Autoscaling Target for the ECS service: ``` resource \"aws_appautoscaling_target\" \"ecs\" { min_capacity = 5 max_capacity = 20 resource_id = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\" scalable_dimension = \"ecs:service:DesiredCount\" service_namespace = \"ecs\" } ``` ", "keywords": ["provider", "cluster"]}, {"source": "Text", "text": "And I've set up an App Autoscaling Policy for that target: ``` resource \"aws_appautoscaling_policy\" \"ecs_policy\" { name = \"ecs-scaling\" policy_type = \"TargetTrackingScaling\" resource_id = aws_appautoscaling_target.ecs.resource_id scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension service_namespace = aws_appautoscaling_target.ecs.service_namespace target_tracking_scaling_policy_configuration { target_value = 70 scale_in_cooldown = 0 scale_out_cooldown = 0 predefined_metric_specification { predefined_metric_type = \"ECSServiceAverageCPUUtilization\" } } } ``` ", "keywords": ["policy"]}, {"source": "Text", "text": "As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. ", "keywords": ["instance"]}, {"source": "Text", "text": "In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1). ", "keywords": ["test"]}, {"source": "Text", "text": "When I deploy this, the ECS service in the AWS console shows: - Desired count: 5 - Pending count: 0 - Running count: 1 And in the events log, it says: > service my-service was unable to place a task because no container instance met all of its requirements. ", "keywords": ["instance"]}, {"source": "Text", "text": "The closest matching container-instance xyzabc1234 has insufficient memory available. ", "keywords": ["instance"]}]}, {"Id": "273437342", "PostHistoryTypeId": "1", "PostId": "72839842", "RevisionGUID": "f979c3e4-e058-459e-bfff-f188681333be", "CreationDate": "2022-07-02T14:29:32.553", "UserId": "612580", "Text": "AWS ECS: Auto-Scaling an EC2 Auto-Scaling Group with Single-Container Hosts", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "273437343", "PostHistoryTypeId": "3", "PostId": "72839842", "RevisionGUID": "f979c3e4-e058-459e-bfff-f188681333be", "CreationDate": "2022-07-02T14:29:32.553", "UserId": "612580", "Text": "<amazon-web-services><amazon-ec2><terraform><amazon-ecs><autoscaling>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "273437637", "PostHistoryTypeId": "5", "PostId": "72839842", "RevisionGUID": "a16456ae-629f-419d-ad50-8b8f87507b16", "CreationDate": "2022-07-02T14:37:18.987", "UserId": "612580", "Comment": "added 555 characters in body", "Text": "I have a rather interesting situation that I'm trying to figure out how to configure on AWS ECS/EC2.\r\n\r\nI have a Dockerized application with the following requirements:\r\n- Very low CPU usage (~256 CPU)\r\n- Moderate memory usage (~256 MB)\r\n- Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container).\r\n\r\nFargate is not an option due to the cost, so we're looking at EC2-based solutions.\r\n\r\nSince the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). This gives me a 1-to-1 mapping of hosts to containers, which is what I need.\r\n\r\nThe issue is, how do I set up ECS cluster-managed autoscaling for this? \r\n\r\nI've configured an EC2 auto-scaling group (Terraform):\r\n```\r\nresource \"aws_autoscaling_group\" \"ecs\" {\r\n  name                = \"ecs\"\r\n  vpc_zone_identifier = var.subnet_ids\r\n  min_size            = 1\r\n  max_size            = 20\r\n  capacity_rebalance  = true\r\n  default_cooldown    = 0\r\n  health_check_type   = \"EC2\"\r\n  mixed_instances_policy {\r\n    ...\r\n  }\r\n  instance_refresh {\r\n    strategy = \"Rolling\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling:\r\n```\r\nresource \"aws_ecs_capacity_provider\" \"ec2\" {\r\n  name = \"ec2\"\r\n  auto_scaling_group_provider {\r\n    auto_scaling_group_arn = aws_autoscaling_group.ecs.arn\r\n    managed_scaling {\r\n      target_capacity           = 100\r\n      instance_warmup_period    = 30\r\n      minimum_scaling_step_size = 1\r\n      maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size\r\n      status                    = \"ENABLED\"\r\n    }\r\n    managed_termination_protection = \"DISABLED\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured this capacity provider as the one and only provider for the ECS cluster:\r\n```\r\nresource \"aws_ecs_cluster_capacity_providers\" \"this\" {\r\n  cluster_name = aws_ecs_cluster.this.name\r\n  capacity_providers = [\r\n    aws_ecs_capacity_provider.ec2.name\r\n  ]\r\n  default_capacity_provider_strategy {\r\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\r\n    weight            = 100\r\n    base              = 0\r\n  }\r\n}\r\n```\r\n\r\nI've set up an ECS service:\r\n```\r\nresource \"aws_ecs_service\" \"this\" {\r\n  name            = local.task_family\r\n  cluster         = aws_ecs_cluster.this.id\r\n  task_definition = aws_ecs_task_definition.this.arn\r\n  desired_count   = 1\r\n  launch_type     = \"EC2\"\r\n  lifecycle {\r\n    ignore_changes = [desired_count]\r\n  }\r\n}\r\n```\r\n\r\nI've set up an App Autoscaling Target for the ECS service:\r\n```\r\nresource \"aws_appautoscaling_target\" \"ecs\" {\r\n  min_capacity       = 5\r\n  max_capacity       = 20\r\n  resource_id        = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\"\r\n  scalable_dimension = \"ecs:service:DesiredCount\"\r\n  service_namespace  = \"ecs\"\r\n}\r\n```\r\n\r\nAnd I've set up an App Autoscaling Policy for that target:\r\n```\r\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\r\n  name               = \"ecs-scaling\"\r\n  policy_type        = \"TargetTrackingScaling\"\r\n  resource_id        = aws_appautoscaling_target.ecs.resource_id\r\n  scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension\r\n  service_namespace  = aws_appautoscaling_target.ecs.service_namespace\r\n\r\n  target_tracking_scaling_policy_configuration {\r\n    target_value       = 70\r\n    scale_in_cooldown  = 0\r\n    scale_out_cooldown = 0\r\n    predefined_metric_specification {\r\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis \"works\" in the sense that it deploys, the service runs, and my application is functional. However, the scaling is not working. As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1).\r\n\r\nWhen I deploy this, the ECS service in the AWS console shows:\r\n- Desired count: 5\r\n- Pending count: 0\r\n- Running count: 1\r\n\r\nAnd in the events log, it says:\r\n> service my-service was unable to place a task because no container instance met all of its requirements. The closest matching container-instance xyzabc1234 has insufficient memory available.\r\n\r\nSo it's trying to achieve the desired minimum number of containers (5), and it's recognizing that there are insufficient EC2 instances, but for some reason (and this is what I can't figure out) it's not scaling out the number of EC2 instances to meet the desired container count.\r\n\r\nFrom [AWS's documentation][1], it says:\r\n> When launched tasks cannot be placed on available instances, the Auto Scaling group scales-out by launching new instances. When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks.\r\n\r\nSince the launched tasks cannot be placed on any of the available instances, it would seem that it *should* automatically scale out the Auto\r\n\r\nAny ideas on why that is?\r\n\r\n\r\n  [1]: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html#how-it-works", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "I have a Dockerized application with the following requirements: - Very low CPU usage (~256 CPU) - Moderate memory usage (~256 MB) - Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container). ", "keywords": ["cpu"]}, {"source": "Text", "text": "Fargate is not an option due to the cost, so we're looking at EC2-based solutions. ", "keywords": ["cost"]}, {"source": "Text", "text": "Since the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). ", "keywords": ["networking", "cpu", "provider", "billing mode"]}, {"source": "Text", "text": "The issue is, how do I set up ECS cluster-managed autoscaling for this? ", "keywords": ["cluster"]}, {"source": "Text", "text": "I've configured an EC2 auto-scaling group (Terraform): ``` resource \"aws_autoscaling_group\" \"ecs\" { name = \"ecs\" vpc_zone_identifier = var.subnet_ids min_size = 1 max_size = 20 capacity_rebalance = true default_cooldown = 0 health_check_type = \"EC2\" mixed_instances_policy { ... } instance_refresh { strategy = \"Rolling\" } } ``` I've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling: ``` resource \"aws_ecs_capacity_provider\" \"ec2\" { name = \"ec2\" auto_scaling_group_provider { auto_scaling_group_arn = aws_autoscaling_group.ecs.arn managed_scaling { target_capacity = 100 instance_warmup_period = 30 minimum_scaling_step_size = 1 maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size status = \"ENABLED\" } managed_termination_protection = \"DISABLED\" } } ``` I've configured this capacity provider as the one and only provider for the ECS cluster: ``` resource \"aws_ecs_cluster_capacity_providers\" \"this\" { cluster_name = aws_ecs_cluster.this.name capacity_providers = [ aws_ecs_capacity_provider.ec2.name ] default_capacity_provider_strategy { capacity_provider = aws_ecs_capacity_provider.ec2.name weight = 100 base = 0 } } ``` I've set up an ECS service: ``` resource \"aws_ecs_service\" \"this\" { name = local.task_family cluster = aws_ecs_cluster.this.id task_definition = aws_ecs_task_definition.this.arn desired_count = 1 launch_type = \"EC2\" lifecycle { ignore_changes = [desired_count] } } ``` I've set up an App Autoscaling Target for the ECS service: ``` resource \"aws_appautoscaling_target\" \"ecs\" { min_capacity = 5 max_capacity = 20 resource_id = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\" scalable_dimension = \"ecs:service:DesiredCount\" service_namespace = \"ecs\" } ``` ", "keywords": ["provider", "cluster"]}, {"source": "Text", "text": "And I've set up an App Autoscaling Policy for that target: ``` resource \"aws_appautoscaling_policy\" \"ecs_policy\" { name = \"ecs-scaling\" policy_type = \"TargetTrackingScaling\" resource_id = aws_appautoscaling_target.ecs.resource_id scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension service_namespace = aws_appautoscaling_target.ecs.service_namespace target_tracking_scaling_policy_configuration { target_value = 70 scale_in_cooldown = 0 scale_out_cooldown = 0 predefined_metric_specification { predefined_metric_type = \"ECSServiceAverageCPUUtilization\" } } } ``` ", "keywords": ["policy"]}, {"source": "Text", "text": "As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. ", "keywords": ["instance"]}, {"source": "Text", "text": "In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1). ", "keywords": ["test"]}, {"source": "Text", "text": "When I deploy this, the ECS service in the AWS console shows: - Desired count: 5 - Pending count: 0 - Running count: 1 And in the events log, it says: > service my-service was unable to place a task because no container instance met all of its requirements. ", "keywords": ["instance"]}, {"source": "Text", "text": "The closest matching container-instance xyzabc1234 has insufficient memory available. ", "keywords": ["instance"]}, {"source": "Text", "text": "When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks. ", "keywords": ["instance"]}, {"source": "Text", "text": "Any ideas on why that is? [1]: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html#how-it-works", "keywords": ["cluster"]}]}, {"Id": "273442520", "PostHistoryTypeId": "5", "PostId": "72839842", "RevisionGUID": "076f65f7-7794-435e-9191-932809c45829", "CreationDate": "2022-07-02T16:49:54.663", "UserId": "612580", "Comment": "added 29 characters in body", "Text": "I have a rather interesting situation that I'm trying to figure out how to configure on AWS ECS/EC2.\r\n\r\nI have a Dockerized application with the following requirements:\r\n- Very low CPU usage (~256 CPU)\r\n- Moderate memory usage (~256 MB)\r\n- Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container).\r\n\r\nFargate is not an option due to the cost, so we're looking at EC2-based solutions.\r\n\r\nSince the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). This gives me a 1-to-1 mapping of hosts to containers, which is what I need.\r\n\r\nThe issue is, how do I set up ECS cluster-managed autoscaling for this? \r\n\r\nI've configured an EC2 auto-scaling group (Terraform):\r\n```\r\nresource \"aws_autoscaling_group\" \"ecs\" {\r\n  name                = \"ecs\"\r\n  vpc_zone_identifier = var.subnet_ids\r\n  min_size            = 1\r\n  max_size            = 20\r\n  capacity_rebalance  = true\r\n  default_cooldown    = 0\r\n  health_check_type   = \"EC2\"\r\n  mixed_instances_policy {\r\n    ...\r\n  }\r\n  instance_refresh {\r\n    strategy = \"Rolling\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling:\r\n```\r\nresource \"aws_ecs_capacity_provider\" \"ec2\" {\r\n  name = \"ec2\"\r\n  auto_scaling_group_provider {\r\n    auto_scaling_group_arn = aws_autoscaling_group.ecs.arn\r\n    managed_scaling {\r\n      target_capacity           = 100\r\n      instance_warmup_period    = 30\r\n      minimum_scaling_step_size = 1\r\n      maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size\r\n      status                    = \"ENABLED\"\r\n    }\r\n    managed_termination_protection = \"DISABLED\"\r\n  }\r\n}\r\n```\r\n\r\nI've configured this capacity provider as the one and only provider for the ECS cluster:\r\n```\r\nresource \"aws_ecs_cluster_capacity_providers\" \"this\" {\r\n  cluster_name = aws_ecs_cluster.this.name\r\n  capacity_providers = [\r\n    aws_ecs_capacity_provider.ec2.name\r\n  ]\r\n  default_capacity_provider_strategy {\r\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\r\n    weight            = 100\r\n    base              = 0\r\n  }\r\n}\r\n```\r\n\r\nI've set up an ECS service:\r\n```\r\nresource \"aws_ecs_service\" \"this\" {\r\n  name            = local.task_family\r\n  cluster         = aws_ecs_cluster.this.id\r\n  task_definition = aws_ecs_task_definition.this.arn\r\n  desired_count   = 1\r\n  launch_type     = \"EC2\"\r\n  lifecycle {\r\n    ignore_changes = [desired_count]\r\n  }\r\n}\r\n```\r\n\r\nI've set up an App Autoscaling Target for the ECS service:\r\n```\r\nresource \"aws_appautoscaling_target\" \"ecs\" {\r\n  min_capacity       = 5\r\n  max_capacity       = 20\r\n  resource_id        = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\"\r\n  scalable_dimension = \"ecs:service:DesiredCount\"\r\n  service_namespace  = \"ecs\"\r\n}\r\n```\r\n\r\nAnd I've set up an App Autoscaling Policy for that target:\r\n```\r\nresource \"aws_appautoscaling_policy\" \"ecs_policy\" {\r\n  name               = \"ecs-scaling\"\r\n  policy_type        = \"TargetTrackingScaling\"\r\n  resource_id        = aws_appautoscaling_target.ecs.resource_id\r\n  scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension\r\n  service_namespace  = aws_appautoscaling_target.ecs.service_namespace\r\n\r\n  target_tracking_scaling_policy_configuration {\r\n    target_value       = 70\r\n    scale_in_cooldown  = 0\r\n    scale_out_cooldown = 0\r\n    predefined_metric_specification {\r\n      predefined_metric_type = \"ECSServiceAverageCPUUtilization\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis \"works\" in the sense that it deploys, the service runs, and my application is functional. However, the scaling is not working. As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1).\r\n\r\nWhen I deploy this, the ECS service in the AWS console shows:\r\n- Desired count: 5\r\n- Pending count: 0\r\n- Running count: 1\r\n\r\nAnd in the events log, it says:\r\n> service my-service was unable to place a task because no container instance met all of its requirements. The closest matching container-instance xyzabc1234 has insufficient memory available.\r\n\r\nSo it's trying to achieve the desired minimum number of containers (5), and it's recognizing that there are insufficient EC2 instances, but for some reason (and this is what I can't figure out) it's not scaling out the number of EC2 instances to meet the desired container count.\r\n\r\nFrom [AWS's documentation][1], it says:\r\n> When launched tasks cannot be placed on available instances, the Auto Scaling group scales-out by launching new instances. When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks.\r\n\r\nSince the launched tasks cannot be placed on any of the available instances, it would seem that it *should* automatically scale out the Auto Scaling Group.\r\n\r\nAny ideas on why it's failing to do so?\r\n\r\n\r\n  [1]: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html#how-it-works", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "I have a Dockerized application with the following requirements: - Very low CPU usage (~256 CPU) - Moderate memory usage (~256 MB) - Each container needs a public IP address that is assigned only to that container (it doesn't share it with any other container). ", "keywords": ["cpu"]}, {"source": "Text", "text": "Fargate is not an option due to the cost, so we're looking at EC2-based solutions. ", "keywords": ["cost"]}, {"source": "Text", "text": "Since the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (`t4g.nano`, `t3a.nano`, etc.), and either the `host` or `bridge` networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). ", "keywords": ["networking", "cpu", "provider", "billing mode"]}, {"source": "Text", "text": "The issue is, how do I set up ECS cluster-managed autoscaling for this? ", "keywords": ["cluster"]}, {"source": "Text", "text": "I've configured an EC2 auto-scaling group (Terraform): ``` resource \"aws_autoscaling_group\" \"ecs\" { name = \"ecs\" vpc_zone_identifier = var.subnet_ids min_size = 1 max_size = 20 capacity_rebalance = true default_cooldown = 0 health_check_type = \"EC2\" mixed_instances_policy { ... } instance_refresh { strategy = \"Rolling\" } } ``` I've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling: ``` resource \"aws_ecs_capacity_provider\" \"ec2\" { name = \"ec2\" auto_scaling_group_provider { auto_scaling_group_arn = aws_autoscaling_group.ecs.arn managed_scaling { target_capacity = 100 instance_warmup_period = 30 minimum_scaling_step_size = 1 maximum_scaling_step_size = aws_autoscaling_group.ecs.max_size status = \"ENABLED\" } managed_termination_protection = \"DISABLED\" } } ``` I've configured this capacity provider as the one and only provider for the ECS cluster: ``` resource \"aws_ecs_cluster_capacity_providers\" \"this\" { cluster_name = aws_ecs_cluster.this.name capacity_providers = [ aws_ecs_capacity_provider.ec2.name ] default_capacity_provider_strategy { capacity_provider = aws_ecs_capacity_provider.ec2.name weight = 100 base = 0 } } ``` I've set up an ECS service: ``` resource \"aws_ecs_service\" \"this\" { name = local.task_family cluster = aws_ecs_cluster.this.id task_definition = aws_ecs_task_definition.this.arn desired_count = 1 launch_type = \"EC2\" lifecycle { ignore_changes = [desired_count] } } ``` I've set up an App Autoscaling Target for the ECS service: ``` resource \"aws_appautoscaling_target\" \"ecs\" { min_capacity = 5 max_capacity = 20 resource_id = \"service/${aws_ecs_cluster.this.name}/${aws_ecs_service.this.name}\" scalable_dimension = \"ecs:service:DesiredCount\" service_namespace = \"ecs\" } ``` ", "keywords": ["provider", "cluster"]}, {"source": "Text", "text": "And I've set up an App Autoscaling Policy for that target: ``` resource \"aws_appautoscaling_policy\" \"ecs_policy\" { name = \"ecs-scaling\" policy_type = \"TargetTrackingScaling\" resource_id = aws_appautoscaling_target.ecs.resource_id scalable_dimension = aws_appautoscaling_target.ecs.scalable_dimension service_namespace = aws_appautoscaling_target.ecs.service_namespace target_tracking_scaling_policy_configuration { target_value = 70 scale_in_cooldown = 0 scale_out_cooldown = 0 predefined_metric_specification { predefined_metric_type = \"ECSServiceAverageCPUUtilization\" } } } ``` ", "keywords": ["policy"]}, {"source": "Text", "text": "As you can see in the `aws_autoscaling_group`, I've set the minimum to 1 instance and the maximum to 20 instances. ", "keywords": ["instance"]}, {"source": "Text", "text": "In the `aws_appautoscaling_target`, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1). ", "keywords": ["test"]}, {"source": "Text", "text": "When I deploy this, the ECS service in the AWS console shows: - Desired count: 5 - Pending count: 0 - Running count: 1 And in the events log, it says: > service my-service was unable to place a task because no container instance met all of its requirements. ", "keywords": ["instance"]}, {"source": "Text", "text": "The closest matching container-instance xyzabc1234 has insufficient memory available. ", "keywords": ["instance"]}, {"source": "Text", "text": "When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks. ", "keywords": ["instance"]}, {"source": "Text", "text": "Any ideas on why it's failing to do so? [1]: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cluster-auto-scaling.html#how-it-works", "keywords": ["cluster"]}]}, {"Id": "273542436", "PostHistoryTypeId": "33", "PostId": "72839842", "RevisionGUID": "a83905c6-788d-47df-991c-90b7fd82c617", "CreationDate": "2022-07-04T15:46:36.517", "UserId": "612580", "Comment": "280057", "filtered-sentences": []}, {"Id": "274066667", "PostHistoryTypeId": "34", "PostId": "72839842", "RevisionGUID": "61bddd0a-9a2d-4c23-9757-a96f4edc67c5", "CreationDate": "2022-07-12T18:07:45.813", "UserId": "-1", "Comment": "280057", "filtered-sentences": []}], "answers": [{"Id": "72872305", "PostTypeId": "2", "ParentId": "72839842", "CreationDate": "2022-07-05T15:52:10.640", "Score": "6", "Body": "<p>I found the issue:</p>\n<pre><code>resource &quot;aws_ecs_service&quot; &quot;this&quot; {\n...\n  launch_type     = &quot;EC2&quot;\n...\n}\n</code></pre>\n<p>If you specify a launch type, it will override the cluster's default capacity provider strategy, and it won't use the managed EC2 autoscaling. The correct approach is:</p>\n<pre><code>resource &quot;aws_ecs_service&quot; &quot;this&quot; {\n  name            = local.task_family\n  cluster         = aws_ecs_cluster.this.id\n  task_definition = aws_ecs_task_definition.this.arn\n  desired_count   = 1\n\n  capacity_provider_strategy {\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\n    weight            = 100\n    base              = 0\n  }\n\n  lifecycle {\n    ignore_changes = [desired_count]\n  }\n}\n</code></pre>\n<p>If you don't provide <code>launch_type</code> or <code>capacity_provider_strategy</code>, it's supposed to use the cluster's default strategy (and it does), but Terraform shows a perpetual difference.</p>\n<p>After this change, everything started scaling properly!</p>\n", "OwnerUserId": "612580", "LastActivityDate": "2022-07-05T15:52:10.640", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "273611662", "PostHistoryTypeId": "2", "PostId": "72872305", "RevisionGUID": "392040c4-0609-4c48-9c1d-3c9bb3817922", "CreationDate": "2022-07-05T15:52:10.640", "UserId": "612580", "Text": "I found the issue:\r\n\r\n```\r\nresource \"aws_ecs_service\" \"this\" {\r\n...\r\n  launch_type     = \"EC2\"\r\n...\r\n}\r\n```\r\n\r\nIf you specify a launch type, it will override the cluster's default capacity provider strategy, and it won't use the managed EC2 autoscaling. The correct approach is:\r\n\r\n```\r\nresource \"aws_ecs_service\" \"this\" {\r\n  name            = local.task_family\r\n  cluster         = aws_ecs_cluster.this.id\r\n  task_definition = aws_ecs_task_definition.this.arn\r\n  desired_count   = 1\r\n\r\n  capacity_provider_strategy {\r\n    capacity_provider = aws_ecs_capacity_provider.ec2.name\r\n    weight            = 100\r\n    base              = 0\r\n  }\r\n\r\n  lifecycle {\r\n    ignore_changes = [desired_count]\r\n  }\r\n}\r\n```\r\n\r\nIf you don't provide `launch_type` or `capacity_provider_strategy`, it's supposed to use the cluster's default strategy (and it does), but Terraform shows a perpetual difference.\r\n\r\nAfter this change, everything started scaling properly!", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "If you specify a launch type, it will override the cluster's default capacity provider strategy, and it won't use the managed EC2 autoscaling. ", "keywords": ["provider", "cluster"]}, {"source": "Text", "text": "The correct approach is: ``` resource \"aws_ecs_service\" \"this\" { name = local.task_family cluster = aws_ecs_cluster.this.id task_definition = aws_ecs_task_definition.this.arn desired_count = 1 capacity_provider_strategy { capacity_provider = aws_ecs_capacity_provider.ec2.name weight = 100 base = 0 } lifecycle { ignore_changes = [desired_count] } } ``` ", "keywords": ["cluster"]}, {"source": "Text", "text": "If you don't provide `launch_type` or `capacity_provider_strategy`, it's supposed to use the cluster's default strategy (and it does), but Terraform shows a perpetual difference", "keywords": ["cluster"]}, {"source": "Text", "text": "After this change, everything started scaling properly!", "keywords": ["change"]}]}], "filtered-sentences": [{"source": "Body", "text": "I found the issue: If you specify a launch type, it will override the cluster's default capacity provider strategy, and it won't use the managed EC2 autoscaling. ", "keywords": ["provider", "cluster"]}, {"source": "Body", "text": "The correct approach is: If you don't provide launch_type or capacity_provider_strategy, it's supposed to use the cluster's default strategy (and it does), but Terraform shows a perpetual difference. ", "keywords": ["cluster"]}, {"source": "Body", "text": "After this change, everything started scaling properly!", "keywords": ["change"]}]}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "I have a Dockerized application with the following requirements: Very low CPU usage (~256 CPU) ", "keywords": ["cpu"]}, {"source": "Body", "text": "Fargate is not an option due to the cost, so we're looking at EC2-based solutions. ", "keywords": ["cost"]}, {"source": "Body", "text": "Since the CPU and memory usage are low, and I need a unique public IP address for each container, the best option for an ECS capacity provider seems to be an EC2 auto-scaling group using the smallest instances (t4g.nano, t3a.nano, etc.), and either the host or bridge networking mode (either mode will limit to a single container per host if I explicitly specify a static host/container port mapping). ", "keywords": ["networking", "cpu", "provider", "billing mode"]}, {"source": "Body", "text": "The issue is, how do I set up ECS cluster-managed autoscaling for this? ", "keywords": ["cluster"]}, {"source": "Body", "text": "I've configured an EC2 auto-scaling group (Terraform): I've configured the auto-scaling group as an ECS Capacity Provider with Managed Scaling: I've configured this capacity provider as the one and only provider for the ECS cluster: I've set up an ECS service: I've set up an App Autoscaling Target for the ECS service: And I've set up an App Autoscaling Policy for that target: This \"works\" in the sense that it deploys, the service runs, and my application is functional. ", "keywords": ["provider", "policy", "cluster"]}, {"source": "Body", "text": "As you can see in the aws_autoscaling_group, I've set the minimum to 1 instance and the maximum to 20 instances. ", "keywords": ["instance"]}, {"source": "Body", "text": "In the aws_appautoscaling_target, I have a minimum of 5 (would be 1 in production, but 5 for testing) and a maximum of 20 (maximum matches the max number of instances since it's 1-to-1). ", "keywords": ["test"]}, {"source": "Body", "text": "When I deploy this, the ECS service in the AWS console shows: Desired count: 5 Pending count: 0 Running count: 1 And in the events log, it says: service my-service was unable to place a task because no container instance met all of its requirements. ", "keywords": ["instance"]}, {"source": "Body", "text": "The closest matching container-instance xyzabc1234 has insufficient memory available. ", "keywords": ["instance"]}, {"source": "Body", "text": "When there are running instances with no tasks, the Auto Scaling group scales-in by terminating an instance with no running tasks. ", "keywords": ["instance"]}]}