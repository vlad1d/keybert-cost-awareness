{"Id": "76755447", "PostTypeId": "1", "CreationDate": "2023-07-24T14:28:43.173", "Score": "0", "ViewCount": "75", "Body": "<p>Before I used the resource <code>aws_s3_object</code> for syncing local files to S3 bucket. Back then updates in S3 triggered updating the connected distribution in CloudFront.</p>\n<p>Now I replaced only the resource <code>aws_s3_object</code> mentioned above by <code>null_resource</code> / <code>provisioner &quot;local-exec&quot;</code> in the project. Then <code>terraform apply</code> only detected changes for the S3 bucket and no longer triggered updates for CloudFront.</p>\n<p>What I did wrong / was missing here?</p>\n<p>The related code:</p>\n<p><strong>Before</strong> (CloudFront is updated when S3 is updated):</p>\n<pre><code>resource &quot;aws_s3_object&quot; &quot;site&quot; {\n  for_each     = fileset(&quot;./site/&quot;, &quot;*&quot;)\n  bucket       = xyz.id\n  key          = each.value\n  source       = &quot;./site/${each.value}&quot;\n  etag         = filemd5(&quot;./site/${each.value}&quot;)\n  content_type = &quot;text/html;charset=UTF-8&quot;\n}\n</code></pre>\n<p><strong>After</strong> (only S3 is updated, CloudFront is not updated):</p>\n<pre><code>resource &quot;null_resource&quot; &quot;remove_and_upload_to_s3&quot; {\n  triggers = {\n    always_run = &quot;${timestamp()}&quot;\n  }\n  provisioner &quot;local-exec&quot; {\n    command = &quot;aws s3 sync ${path.module}/site s3://${aws_s3_bucket.xyz.id}&quot;\n  }\n}\n</code></pre>\n", "OwnerUserId": "3168315", "LastEditorUserId": "3168315", "LastEditDate": "2023-07-25T13:20:00.863", "LastActivityDate": "2023-07-25T19:56:09.807", "Title": "terraform null_resource does not trigger S3 bucket update's chained action update CloudFront distribution", "Tags": "<amazon-web-services><amazon-s3><terraform><amazon-cloudfront>", "AnswerCount": "1", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "295789952", "PostHistoryTypeId": "2", "PostId": "76755447", "RevisionGUID": "2e3e3c4d-659e-4bda-bc94-9e345e73ed4f", "CreationDate": "2023-07-24T14:28:43.173", "UserId": "3168315", "Text": "Before I used the resource `aws_s3_object` for syncing local files to S3 bucket. Back then updates in S3 triggered updating the connected distribution in CloudFront.\r\n\r\nNow I replaced only the resource `aws_s3_object` mentioned above by `null_resource` / `provisioner \"local-exec\"` in the project. Then `terraform apply` only detected changes for the S3 bucket and no longer triggered updates for CloudFront.\r\n\r\nWhat I did wrong / was missing here?\r\n\r\nThe related code:\r\n\r\n**Before** (CloudFront is updated when S3 is updated):\r\n```\r\nresource \"aws_s3_object\" \"site\" {\r\n  for_each     = fileset(\"./site/\", \"*\")\r\n  bucket       = xyz.id\r\n  key          = each.value\r\n  source       = \"./site/${each.value}\"\r\n  etag         = filemd5(\"./site/${each.value}\")\r\n  content_type = \"text/html;charset=UTF-8\"\r\n}\r\n```\r\n**After** (only S3 is updated, CloudFront is not updated):\r\n```\r\nresource \"null_resource\" \"remove_and_upload_to_s3\" {\r\n  provisioner \"local-exec\" {\r\n    command = \"aws s3 sync ${path.module}/site s3://${aws_s3_bucket.xyz.id}\"\r\n  }\r\n}\r\n```", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Then `terraform apply` only detected changes for the S3 bucket and no longer triggered updates for CloudFront. ", "keywords": ["change"]}]}, {"Id": "295789954", "PostHistoryTypeId": "1", "PostId": "76755447", "RevisionGUID": "2e3e3c4d-659e-4bda-bc94-9e345e73ed4f", "CreationDate": "2023-07-24T14:28:43.173", "UserId": "3168315", "Text": "terraform null_resource does not trigger S3 bucket update's chained action update CloudFront distribution", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "295789955", "PostHistoryTypeId": "3", "PostId": "76755447", "RevisionGUID": "2e3e3c4d-659e-4bda-bc94-9e345e73ed4f", "CreationDate": "2023-07-24T14:28:43.173", "UserId": "3168315", "Text": "<amazon-web-services><amazon-s3><terraform><amazon-cloudfront>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "295833017", "PostHistoryTypeId": "5", "PostId": "76755447", "RevisionGUID": "902d286e-9c31-4ea6-802d-5b4b396e78bf", "CreationDate": "2023-07-25T13:20:00.863", "UserId": "3168315", "Comment": "I added the missing triggers.always_run to the resource null_resource.remove_and_update_to_s3.", "Text": "Before I used the resource `aws_s3_object` for syncing local files to S3 bucket. Back then updates in S3 triggered updating the connected distribution in CloudFront.\r\n\r\nNow I replaced only the resource `aws_s3_object` mentioned above by `null_resource` / `provisioner \"local-exec\"` in the project. Then `terraform apply` only detected changes for the S3 bucket and no longer triggered updates for CloudFront.\r\n\r\nWhat I did wrong / was missing here?\r\n\r\nThe related code:\r\n\r\n**Before** (CloudFront is updated when S3 is updated):\r\n```\r\nresource \"aws_s3_object\" \"site\" {\r\n  for_each     = fileset(\"./site/\", \"*\")\r\n  bucket       = xyz.id\r\n  key          = each.value\r\n  source       = \"./site/${each.value}\"\r\n  etag         = filemd5(\"./site/${each.value}\")\r\n  content_type = \"text/html;charset=UTF-8\"\r\n}\r\n```\r\n**After** (only S3 is updated, CloudFront is not updated):\r\n```\r\nresource \"null_resource\" \"remove_and_upload_to_s3\" {\r\n  triggers = {\r\n    always_run = \"${timestamp()}\"\r\n  }\r\n  provisioner \"local-exec\" {\r\n    command = \"aws s3 sync ${path.module}/site s3://${aws_s3_bucket.xyz.id}\"\r\n  }\r\n}\r\n```", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Then `terraform apply` only detected changes for the S3 bucket and no longer triggered updates for CloudFront. ", "keywords": ["change"]}]}], "answers": [{"Id": "76755637", "PostTypeId": "2", "ParentId": "76755447", "CreationDate": "2023-07-24T14:51:25.567", "Score": "2", "Body": "<p>Since the issue is that the objects are kept the same even after the objects get updated, it seems that the problem with CloudFront is that the cache TTL is not set. There are <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html\" rel=\"nofollow noreferrer\">multiple ways</a> to do this:</p>\n<blockquote>\n<p>By default, each file automatically expires after 24 hours, but you can change the default behavior in different ways:</p>\n</blockquote>\n<blockquote>\n<p>To change the cache duration for all files that match the same path pattern, you can change the CloudFront settings for Minimum TTL, Maximum TTL, and Default TTL for a cache behavior. For information about the individual settings, see Minimum TTL, Maximum TTL, and Default TTL in Values that you specify when you create or update a distribution.</p>\n</blockquote>\n<blockquote>\n<p>To change the cache duration for an individual file, you can configure your origin to add a <code>Cache-Control</code> header with the <code>max-age</code> or <code>s-maxage</code> directive, or an <code>Expires</code> header to the file.</p>\n</blockquote>\n<p>Another option to do this (which can be very expensive depending on the number of objects, so be careful) is to invalidate the CloudFront cache each time you update the objects, using the <code>terraform_data</code> source:</p>\n<pre><code>resource &quot;terraform_data&quot; &quot;remove_and_upload_to_s3&quot; {\n  for_each     = aws_s3_object.site\n  triggers_replace = [\n    each.value.etag\n  ]\n\n  provisioner &quot;local-exec&quot; {\n    command = &quot;aws cloudfront create-invalidation --distribution-id &lt;your CF distribution id&gt; --paths &quot;/example-path/${each.value.key}&quot;\n  }\n}\n</code></pre>\n<p>Note that you can also specify multiple paths if needed. Additionally, this will work only if the objects have the new objects have the same name as the old ones.</p>\n", "OwnerUserId": "8343484", "LastEditorUserId": "8343484", "LastEditDate": "2023-07-25T19:56:09.807", "LastActivityDate": "2023-07-25T19:56:09.807", "CommentCount": "5", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "135330593", "PostId": "76755637", "Score": "0", "Text": "The reason why I replaced my resource aws_s3_object.site with null_resource.remove_and_upload_to_s3 in the first place is my site started having nested directories.", "CreationDate": "2023-07-25T13:25:36.467", "UserId": "3168315", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "135330764", "PostId": "76755637", "Score": "0", "Text": "Ah, wait, so the S3 bucket does get updated, right? So the issue is that the CloudFront distribution is still showing the old version of the object?", "CreationDate": "2023-07-25T13:36:12.510", "UserId": "8343484", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "135331541", "PostId": "76755637", "Score": "0", "Text": "Yes, it was my situation.", "CreationDate": "2023-07-25T14:25:29.997", "UserId": "3168315", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "135335624", "PostId": "76755637", "Score": "0", "Text": "@Mako I've updated the answer as it seems it's more relevant to the problem you have.", "CreationDate": "2023-07-25T19:57:05.583", "UserId": "8343484", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "135486160", "PostId": "76755637", "Score": "0", "Text": "Thanks for your update to the answer. The CloudFront cache update did happened after 24 hours. But I / users of my site wouldn't want to wait that long to see site updates. Please correct me if I am wrong. I believe cache control settings are for caching performance and can't be really utilized to immediately update edge distributions. I didn't try your suggestion of terraform resource above because in my project the distribution id is not known beforehand, but is created though: resource \"aws_cloudfront_distribution\" { origin { s3 ...}}", "CreationDate": "2023-08-07T15:33:05.153", "UserId": "3168315", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "history": [{"Id": "295791076", "PostHistoryTypeId": "2", "PostId": "76755637", "RevisionGUID": "480b3e4f-592a-4623-8970-0314ac3dec7f", "CreationDate": "2023-07-24T14:51:25.567", "UserId": "8343484", "Text": "I would probably go for the new resource `terraform_data` and then use the `for_each` with `aws s3 cp` instead of sync:\r\n\r\n```hcl\r\nresource \"terraform_data\" \"remove_and_upload_to_s3\" {\r\n  for_each     = aws_s3_object.site\r\n  triggers_replace = [\r\n    each.value.etag\r\n  ]\r\n\r\n  provisioner \"local-exec\" {\r\n    command = \"aws s3 cp ${path.module}/site/${each.value.source} s3://${aws_s3_bucket.xyz.id}\"\r\n  }\r\n}\r\n```", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "295849777", "PostHistoryTypeId": "5", "PostId": "76755637", "RevisionGUID": "a53dee6d-2e05-4a23-a656-c08faa011d90", "CreationDate": "2023-07-25T19:56:09.807", "UserId": "8343484", "Comment": "remove the wrong answer", "Text": "Since the issue is that the objects are kept the same even after the objects get updated, it seems that the problem with CloudFront is that the cache TTL is not set. There are [multiple ways][1] to do this:\r\n\r\n> By default, each file automatically expires after 24 hours, but you can change the default behavior in different ways:\r\n\r\n> To change the cache duration for all files that match the same path pattern, you can change the CloudFront settings for Minimum TTL, Maximum TTL, and Default TTL for a cache behavior. For information about the individual settings, see Minimum TTL, Maximum TTL, and Default TTL in Values that you specify when you create or update a distribution.\r\n\r\n> To change the cache duration for an individual file, you can configure your origin to add a `Cache-Control` header with the `max-age` or `s-maxage` directive, or an `Expires` header to the file.\r\n\r\nAnother option to do this (which can be very expensive depending on the number of objects, so be careful) is to invalidate the CloudFront cache each time you update the objects, using the `terraform_data` source:\r\n\r\n```hcl\r\nresource \"terraform_data\" \"remove_and_upload_to_s3\" {\r\n  for_each     = aws_s3_object.site\r\n  triggers_replace = [\r\n    each.value.etag\r\n  ]\r\n\r\n  provisioner \"local-exec\" {\r\n    command = \"aws cloudfront create-invalidation --distribution-id <your CF distribution id> --paths \"/example-path/${each.value.key}\"\r\n  }\r\n}\r\n```\r\n\r\nNote that you can also specify multiple paths if needed. Additionally, this will work only if the objects have the new objects have the same name as the old ones.\r\n\r\n  [1]: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "There are [multiple ways][1] to do this: > By default, each file automatically expires after 24 hours, but you can change the default behavior in different ways: > To change the cache duration for all files that match the same path pattern, you can change the CloudFront settings for Minimum TTL, Maximum TTL, and Default TTL for a cache behavior. ", "keywords": ["change"]}, {"source": "Text", "text": "> To change the cache duration for an individual file, you can configure your origin to add a `Cache-Control` header with the `max-age` or `s-maxage` directive, or an `Expires` header to the file. ", "keywords": ["change"]}, {"source": "Text", "text": "Another option to do this (which can be very expensive depending on the number of objects, so be careful) is to invalidate the CloudFront cache each time you update the objects, using the `terraform_data` source: ```hcl resource \"terraform_data\" \"remove_and_upload_to_s3\" { for_each = aws_s3_object.site triggers_replace = [ each.value.etag ] provisioner \"local-exec\" { command = \"aws cloudfront create-invalidation --distribution-id --paths \"/example-path/${each.value.key}\" } } ``` ", "keywords": ["expense"]}]}], "filtered-sentences": [{"source": "Body", "text": "By default, each file automatically expires after 24 hours, but you can change the default behavior in different ways: ", "keywords": ["change"]}, {"source": "Body", "text": "To change the cache duration for all files that match the same path pattern, you can change the CloudFront settings for Minimum TTL, Maximum TTL, and Default TTL for a cache behavior. ", "keywords": ["change"]}, {"source": "Body", "text": "To change the cache duration for an individual file, you can configure your origin to add a Cache-Control header with the max-age or s-maxage directive, or an Expires header to the file. ", "keywords": ["change"]}, {"source": "Body", "text": "Another option to do this (which can be very expensive depending on the number of objects, so be careful) is to invalidate the CloudFront cache each time you update the objects, using the terraform_data source: Note that you can also specify multiple paths if needed. ", "keywords": ["expense"]}]}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "Then terraform apply only detected changes for the S3 bucket and no longer triggered updates for CloudFront. ", "keywords": ["change"]}]}