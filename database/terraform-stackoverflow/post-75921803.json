{"Id": "75921803", "PostTypeId": "1", "AcceptedAnswerId": "75922607", "CreationDate": "2023-04-03T16:38:40.207", "Score": "0", "ViewCount": "78", "Body": "<p>I have a Terraform step that calls out to a bash script and creates a directory as part of a pipeline, inserts some files in that directory, and successfully uploads that material to AWS but only the first time.</p>\n<pre class=\"lang-bash prettyprint-override\"><code>#!/bin/bash\n\necho &quot;Executing create_pkg.sh ...&quot;\n\ncd $path_cwd\ndir_name=python_dependencies_folder/python\nmkdir -p $dir_name\n\n# Put some files in this directory\n</code></pre>\n<p>It is called from this section of Terraform:</p>\n<pre class=\"lang-hcl prettyprint-override\"><code>resource &quot;null_resource&quot; &quot;install_python_dependencies&quot; {\n   provisioner &quot;local-exec&quot; {\n      command = &quot;cd scripts &amp;&amp; chmod +x ./create_pkg.sh &amp;&amp; ./create_pkg.sh&quot;\n      interpreter = [&quot;bash&quot;, &quot;-c&quot;]\n      working_dir = path.module\n\n      environment = {\n          path_module = path.module\n          path_cwd    = path.cwd\n      }\n   }\n}\n</code></pre>\n<p>It is zipped up through this data section:</p>\n<pre class=\"lang-hcl prettyprint-override\"><code>data &quot;archive_file&quot; &quot;zip_creation&quot; {\n    depends_on  = [null_resource.install_python_dependencies]\n    type        = &quot;zip&quot;\n    source_dir  = &quot;${path.cwd}/python_dependencies_folder&quot;\n    output_path = var.output_path\n}\n</code></pre>\n<p>The first time this process runs, everything executes correctly.  However, if the same process is executed a second time, I see the following in the job logs:</p>\n<p>module.aws_lambda_function.null_resource.python_dependencies_folder[0]: Refreshing state... [id=63624526464556]\nmodule.data.archive_file.zip_creation[0]: Reading ...</p>\n<blockquote>\n<p>Error: Archive creation error</p>\n<blockquote>\n<p>with module.data.archive_file.zip_creation[0]\non .terraform/modules/aws_lambda_function/main.tf line 98, in data &quot;archive_file&quot; &quot;zip_creation&quot;:\n98: data &quot;archive_file&quot; &quot;zip_creation&quot; {</p>\n<p>error creating archive: error archiving directory: could not archive\nmissing directory:\n.terraform/modules/aws_lambda_function/python_dependencies_folder</p>\n</blockquote>\n</blockquote>\n<p>As I stated, when the same pipeline runs a second time, it is almost like TF is skipping the execution of &quot;null_resource&quot; due to some entry in the tfstate file.</p>\n<p>Thoughts on how I indicate to Terraform that the &quot;null_resource&quot; must be run each time and ignore what it finds in tfstate?</p>\n", "OwnerUserId": "768419", "LastActivityDate": "2023-04-03T18:22:18.467", "Title": "Terraform seems to bypass script execution", "Tags": "<terraform>", "AnswerCount": "1", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "290814039", "PostHistoryTypeId": "2", "PostId": "75921803", "RevisionGUID": "7926a1fa-51e0-4636-9cdc-f894d84ed424", "CreationDate": "2023-04-03T16:38:40.207", "UserId": "768419", "Text": "I have a Terraform step that calls out to a bash script and creates a directory as part of a pipeline, inserts some files in that directory, and successfully uploads that material to AWS but only the first time.\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\necho \"Executing create_pkg.sh ...\"\r\n\r\ncd $path_cwd\r\ndir_name=python_dependencies_folder/python\r\nmkdir -p $dir_name\r\n\r\n# Put some files in this directory\r\n```\r\n\r\nIt is called from this section of Terraform:\r\n\r\n```lang-hcl\r\nresource \"null_resource\" \"install_python_dependencies\" {\r\n   provisioner \"local-exec\" {\r\n      command = \"cd scripts && chmod +x ./create_pkg.sh && ./create_pkg.sh\"\r\n      interpreter = [\"bash\", \"-c\"]\r\n      working_dir = path.module\r\n\r\n      environment = {\r\n          path_module = path.module\r\n          path_cwd    = path.cwd\r\n      }\r\n   }\r\n}\r\n```\r\n\r\nIt is zipped up through this data section:\r\n\r\n```lang-hcl\r\ndata \"archive_file\" \"zip_creation\" {\r\n    depends_on  = [null_resource.install_python_dependencies]\r\n    type        = \"zip\"\r\n    source_dir  = \"${path.cwd}/python_dependencies_folder\"\r\n    output_path = var.output_path\r\n}\r\n```\r\n\r\nThe first time this process runs, everything executes correctly.  However, if the same process is executed a second time, I see the following in the job logs:\r\n\r\nmodule.aws_lambda_function.null_resource.python_dependencies_folder[0]: Refreshing state... [id=63624526464556]\r\nmodule.data.archive_file.zip_creation[0]: Reading ...\r\n\r\n>  Error: Archive creation error \r\n>>   with module.data.archive_file.zip_creation[0]\r\n>>   on .terraform/modules/aws_lambda_function/main.tf line 98, in data \"archive_file\" \"zip_creation\":\r\n>>   98: data \"archive_file\" \"zip_creation\" {\r\n>> \r\n>>  error creating archive: error archiving directory: could not archive\r\n>>  missing directory:\r\n>>  .terraform/modules/aws_lambda_function/python_dependencies_folder\r\n\r\nAs I stated, when the same pipeline runs a second time, it is almost like TF is skipping the execution of \"null_resource\" due to some entry in the tfstate file.\r\n\r\nThoughts on how I indicate to Terraform that the \"null_resource\" must be run each time and ignore what it finds in tfstate? ", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "290814041", "PostHistoryTypeId": "1", "PostId": "75921803", "RevisionGUID": "7926a1fa-51e0-4636-9cdc-f894d84ed424", "CreationDate": "2023-04-03T16:38:40.207", "UserId": "768419", "Text": "Terraform seems to bypass script execution", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "290814042", "PostHistoryTypeId": "3", "PostId": "75921803", "RevisionGUID": "7926a1fa-51e0-4636-9cdc-f894d84ed424", "CreationDate": "2023-04-03T16:38:40.207", "UserId": "768419", "Text": "<terraform>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "answers": [{"Id": "75922607", "PostTypeId": "2", "ParentId": "75921803", "CreationDate": "2023-04-03T18:22:18.467", "Score": "1", "Body": "<p><code>null_resource</code> operates the standard resource lifecycle. as documented in the <a href=\"https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource\" rel=\"nofollow noreferrer\">provider</a></p>\n<blockquote>\n<p>The null_resource resource implements the standard resource lifecycle but takes no further action.\nThe triggers argument allows specifying an arbitrary set of values that, when changed, will cause the resource to be replaced.</p>\n</blockquote>\n<p>That is to say when your first run TF the resource will be executed and its resource state persisted. So when you run a second time the null resource wont be executed cause as far as it knows nothing has changed with the resource so it wont run it again.</p>\n<p>your <code>archive_file</code> data object will be run on every execution. However on your second execution it fails since your null resource didn't run again. I am making an assumption here that you are running this each time in either docker or some sort of ephemeral environment where the artifact produced by your null resource is not persisted and available on each run of your terraform.</p>\n<p>You can add a <code>triggers</code> argument to your null resource to tell terraform when it needs to rerun this null resource. In this case if you need the null resource to run every time you can add a triggers tag using the timestamp which will be different on every run so will trigger the resource every run. However personally that feels a bit wrong to me and will result in your TF output always saying it will destroy and add the null resource every time.</p>\n<pre><code>resource &quot;null_resource&quot; &quot;install_python_dependencies&quot; {\n   provisioner &quot;local-exec&quot; {\n      command = &quot;cd scripts &amp;&amp; chmod +x ./create_pkg.sh &amp;&amp; ./create_pkg.sh&quot;\n      interpreter = [&quot;bash&quot;, &quot;-c&quot;]\n      working_dir = path.module\n\n      environment = {\n          path_module = path.module\n          path_cwd    = path.cwd\n      }\n   }\n  triggers = {\n    ts = timestamp()\n  }\n}\n</code></pre>\n<p>In reality it sounds like your zip file should be created as an artifact and persisted and pulled from an artifact repository our created outside of TF its self. However I fell this pain as I have experienced this exact same issue when packaging a python lambda for AWS and uploading via TF and trying to do it all in TF. In reality TF is not the solution to everything. I would really recommend making the zip file an artifact outside of the TF process.</p>\n", "OwnerUserId": "1212401", "LastActivityDate": "2023-04-03T18:22:18.467", "CommentCount": "1", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "133914756", "PostId": "75922607", "Score": "1", "Text": "Thanks for the information, that was my issue.\n\nWhen you say \"In reality TF is not the solution to everything. I would really recommend making the zip file an artifact outside of the TF process.\", I would love to but those decisions are above my pay grade.", "CreationDate": "2023-04-03T19:54:15.870", "UserId": "768419", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "I would really recommend making the zip file an artifact outside of the TF process.\", I would love to but those decisions are above my pay grade.", "keywords": ["pay"]}]}], "history": [{"Id": "290818615", "PostHistoryTypeId": "2", "PostId": "75922607", "RevisionGUID": "0355fc29-6078-42a2-a0ef-4147a92c6f8d", "CreationDate": "2023-04-03T18:22:18.467", "UserId": "1212401", "Text": "`null_resource` operates the standard resource lifecycle. as documented in the [provider][1]\r\n\r\n> The null_resource resource implements the standard resource lifecycle but takes no further action.\r\n> The triggers argument allows specifying an arbitrary set of values that, when changed, will cause the resource to be replaced.\r\n\r\nThat is to say when your first run TF the resource will be executed and its resource state persisted. So when you run a second time the null resource wont be executed cause as far as it knows nothing has changed with the resource so it wont run it again. \r\n\r\nyour `archive_file` data object will be run on every execution. However on your second execution it fails since your null resource didn't run again. I am making an assumption here that you are running this each time in either docker or some sort of ephemeral environment where the artifact produced by your null resource is not persisted and available on each run of your terraform. \r\n\r\nYou can add a `triggers` argument to your null resource to tell terraform when it needs to rerun this null resource. In this case if you need the null resource to run every time you can add a triggers tag using the timestamp which will be different on every run so will trigger the resource every run. However personally that feels a bit wrong to me and will result in your TF output always saying it will destroy and add the null resource every time. \r\n\r\n```hcl \r\nresource \"null_resource\" \"install_python_dependencies\" {\r\n   provisioner \"local-exec\" {\r\n      command = \"cd scripts && chmod +x ./create_pkg.sh && ./create_pkg.sh\"\r\n      interpreter = [\"bash\", \"-c\"]\r\n      working_dir = path.module\r\n\r\n      environment = {\r\n          path_module = path.module\r\n          path_cwd    = path.cwd\r\n      }\r\n   }\r\n  triggers = {\r\n    ts = timestamp()\r\n  }\r\n}\r\n```\r\n\r\nIn reality it sounds like your zip file should be created as an artifact and persisted and pulled from an artifact repository our created outside of TF its self. However I fell this pain as I have experienced this exact same issue when packaging a python lambda for AWS and uploading via TF and trying to do it all in TF. In reality TF is not the solution to everything. I would really recommend making the zip file an artifact outside of the TF process.\r\n\r\n\r\n  [1]: https://registry.terraform.io/providers/hashicorp/null/latest/docs/resources/resource", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "as documented in the [provider][1] > The null_resource resource implements the standard resource lifecycle but takes no further action. ", "keywords": ["provider"]}, {"source": "Text", "text": "> The triggers argument allows specifying an arbitrary set of values that, when changed, will cause the resource to be replaced. ", "keywords": ["change"]}, {"source": "Text", "text": "So when you run a second time the null resource wont be executed cause as far as it knows nothing has changed with the resource so it wont run it again. ", "keywords": ["change"]}]}], "filtered-sentences": [{"source": "Body", "text": "null_resource operates the standard resource lifecycle. as documented in the provider ", "keywords": ["provider"]}, {"source": "Body", "text": "The triggers argument allows specifying an arbitrary set of values that, when changed, will cause the resource to be replaced. ", "keywords": ["change"]}, {"source": "Body", "text": "So when you run a second time the null resource wont be executed cause as far as it knows nothing has changed with the resource so it wont run it again. ", "keywords": ["change"]}]}], "contains-topic": true, "filtered-sentences": []}