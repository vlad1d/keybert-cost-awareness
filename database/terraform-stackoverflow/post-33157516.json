{"Id": "33157516", "PostTypeId": "1", "AcceptedAnswerId": "33628841", "CreationDate": "2015-10-15T20:03:53.277", "Score": "134", "ViewCount": "44289", "Body": "<p>I'm in the process of swapping over our infrastructure into terraform.\nWhat's the best practice for actually managing the terraform files and state?\nI realize it's infrastructure as code, and i'll commit my .tf files into git, but do I commit tfstate as well? Should that reside somewhere like S3 ? I would like eventually for CI to manage all of this, but that's far stretched and requires me to figure out the moving pieces for the files.</p>\n\n<p>I'm really just looking to see how people out there actually utilize this type of stuff in production</p>\n", "OwnerUserId": "1200057", "LastEditorUserId": "213269", "LastEditDate": "2020-12-10T16:56:15.243", "LastActivityDate": "2020-12-10T16:56:15.243", "Title": "Best practices when using Terraform", "Tags": "<continuous-integration><terraform>", "AnswerCount": "12", "CommentCount": "0", "FavoriteCount": "0", "ClosedDate": "2020-05-29T00:07:16.690", "ContentLicense": "CC BY-SA 3.0", "links": [{"Id": "1229389770", "CreationDate": "2016-08-03T16:52:56.250", "PostId": "33157516", "RelatedPostId": "38486335", "LinkTypeId": "1"}], "history": [{"Id": "101922816", "PostHistoryTypeId": "2", "PostId": "33157516", "RevisionGUID": "730e5e01-6c2e-4d74-88f4-cc3e4addf90e", "CreationDate": "2015-10-15T20:03:53.277", "UserId": "1200057", "Text": "I'm in the process of swapping over our infrastructure into terraform.\r\nWhat's the best practice for actually managing the terraform files and state?\r\nI realize it's infrastructure as code, and i'll commit my .tf files into git, but do I commit tfstate as well? Should that reside somewhere like S3 ? I would like eventually for CI to manage all of this, but that's far stretched and requires me to figure out the moving pieces for the files.\r\n\r\nI'm really just looking to see how people out there actually utilize this type of stuff in production", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "101922817", "PostHistoryTypeId": "1", "PostId": "33157516", "RevisionGUID": "730e5e01-6c2e-4d74-88f4-cc3e4addf90e", "CreationDate": "2015-10-15T20:03:53.277", "UserId": "1200057", "Text": "Best practices when using", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "101922818", "PostHistoryTypeId": "3", "PostId": "33157516", "RevisionGUID": "730e5e01-6c2e-4d74-88f4-cc3e4addf90e", "CreationDate": "2015-10-15T20:03:53.277", "UserId": "1200057", "Text": "<devops><terraform>", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "122464254", "PostHistoryTypeId": "4", "PostId": "33157516", "RevisionGUID": "5ea36860-9b3b-4783-80bf-97a5ff0c1dc6", "CreationDate": "2016-07-12T14:24:36.423", "UserId": "13800", "Comment": "both question title and url were lacking the most important word, Terraform", "Text": "Best practices when using Terraform", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "222796727", "PostHistoryTypeId": "10", "PostId": "33157516", "RevisionGUID": "ff033774-59e0-468e-b49f-08c4d224a292", "CreationDate": "2020-05-29T00:07:16.690", "UserId": "-1", "Comment": "105", "Text": "{\"Voters\":[{\"Id\":1324,\"DisplayName\":\"Paul Roub\"},{\"Id\":441757,\"DisplayName\":\"sideshowbarker\"},{\"Id\":6461462,\"DisplayName\":\"M--\"}]}", "filtered-sentences": []}, {"Id": "236656478", "PostHistoryTypeId": "6", "PostId": "33157516", "RevisionGUID": "ef1335c5-d609-45bf-9500-8fe1696625d0", "CreationDate": "2020-12-10T16:56:15.243", "UserId": "213269", "Comment": "edited tags", "Text": "<continuous-integration><terraform>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "answers": [{"Id": "62072646", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2020-05-28T19:07:53.757", "Score": "-1", "Body": "<p>Use terraform cloud for manage and save states, together with advises above.</p>\n", "OwnerUserId": "10133603", "LastActivityDate": "2020-05-28T19:07:53.757", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "222781216", "PostHistoryTypeId": "2", "PostId": "62072646", "RevisionGUID": "422e24d0-6f0a-44d9-b675-74d1fcb0171d", "CreationDate": "2020-05-28T19:07:53.757", "UserId": "10133603", "Text": "Use terraform cloud for manage and save states, together with advises above.", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}, {"Id": "38284959", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2016-07-09T18:25:30.853", "Score": "10", "Body": "<p>Previously <code>remote config</code> allowed this but now has been replaced by \"<a href=\"https://github.com/hashicorp/terraform/pull/11286\" rel=\"nofollow noreferrer\">backends</a>\", so terraform remote is not anymore available.</p>\n\n<pre class=\"lang-bash prettyprint-override\"><code>terraform remote config -backend-config=\"bucket=&lt;s3_bucket_to_store_tfstate&gt;\" -backend-config=\"key=terraform.tfstate\" -backend=s3\nterraform remote pull\nterraform apply\nterraform remote push\n</code></pre>\n\n<p>See the <a href=\"https://www.terraform.io/docs/commands/remote-config.html\" rel=\"nofollow noreferrer\">docs</a> for details.</p>\n", "OwnerUserId": "1094109", "LastEditorUserId": "1092815", "LastEditDate": "2019-02-27T14:26:14.600", "LastActivityDate": "2019-02-27T14:26:14.600", "CommentCount": "1", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "71415310", "PostId": "38284959", "Score": "0", "Text": "Does the remote source need to be reconfigured each time you want to work on a different terraform component/environment/module/whatever?", "CreationDate": "2017-02-08T21:07:11.040", "UserId": "926190", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}], "history": [{"Id": "122280652", "PostHistoryTypeId": "2", "PostId": "38284959", "RevisionGUID": "8e2020cf-ef53-4ee7-a1db-9d4746462c02", "CreationDate": "2016-07-09T18:25:30.853", "UserId": "1094109", "Text": "With `remote config`, this has now become much simpler:\r\n\r\n    terraform remote config -backend-config=\"bucket=<s3_bucket_to_store_tfstate>\" -backend-config=\"key=terraform.tfstate\" -backend=s3\r\n    terraform remote pull\r\n    terraform apply\r\n    terraform remote push\r\n\r\nSee the [docs](https://www.terraform.io/docs/commands/remote-config.html) for details.\r\n", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "192514224", "PostHistoryTypeId": "5", "PostId": "38284959", "RevisionGUID": "65466e55-b6a6-4379-ac8c-3c46ae5eeb8e", "CreationDate": "2019-02-27T07:41:01.917", "UserId": "-1", "Comment": "terraform remote not anymore available.", "Text": "Previously  `remote config` allowed this but now has been replaced by \"[backends][1]\", so terraform remote is not anymore available.\r\n\r\n\r\n    terraform remote config -backend-config=\"bucket=<s3_bucket_to_store_tfstate>\" -backend-config=\"key=terraform.tfstate\" -backend=s3\r\n    terraform remote pull\r\n    terraform apply\r\n    terraform remote push\r\n\r\nSee the [docs](https://www.terraform.io/docs/commands/remote-config.html) for details.\r\n\r\n\r\n  [1]: https://github.com/hashicorp/terraform/pull/11286", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "192514225", "PostHistoryTypeId": "24", "PostId": "38284959", "RevisionGUID": "65466e55-b6a6-4379-ac8c-3c46ae5eeb8e", "CreationDate": "2019-02-27T07:41:01.917", "Comment": "Proposed by anonymous approved by 10195153, 2791574 edit id of 4162684", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "192543747", "PostHistoryTypeId": "5", "PostId": "38284959", "RevisionGUID": "030c7f32-4b74-430e-ba33-fb4d12e3db0e", "CreationDate": "2019-02-27T14:26:14.600", "UserId": "1092815", "Comment": "syntax highlighting", "Text": "Previously `remote config` allowed this but now has been replaced by \"[backends][1]\", so terraform remote is not anymore available.\r\n\r\n<!-- language: lang-bash -->\r\n\r\n    terraform remote config -backend-config=\"bucket=<s3_bucket_to_store_tfstate>\" -backend-config=\"key=terraform.tfstate\" -backend=s3\r\n    terraform remote pull\r\n    terraform apply\r\n    terraform remote push\r\n\r\nSee the [docs](https://www.terraform.io/docs/commands/remote-config.html) for details.\r\n\r\n\r\n  [1]: https://github.com/hashicorp/terraform/pull/11286", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}, {"Id": "38749508", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2016-08-03T16:52:56.250", "Score": "93", "Body": "<p>We use Terraform heavily and our recommended setup is as follows:</p>\n<h1>File layout</h1>\n<p>We highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate <code>.tfstate</code> files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See <a href=\"https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/\" rel=\"noreferrer\">Terraform, VPC, and why you want a tfstate file per env</a> for a colorful discussion of why.</p>\n<p>Therefore, our typical file layout looks like this:</p>\n<pre><code>stage\n  \u2514 main.tf\n  \u2514 vars.tf\n  \u2514 outputs.tf\nprod\n  \u2514 main.tf\n  \u2514 vars.tf\n  \u2514 outputs.tf\nglobal\n  \u2514 main.tf\n  \u2514 vars.tf\n  \u2514 outputs.tf\n</code></pre>\n<p>All the Terraform code for the stage VPC goes into the <code>stage</code> folder, all the code for the prod VPC goes into the <code>prod</code> folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the <code>global</code> folder.</p>\n<p>Note that, by convention, we typically break our Terraform code down into 3 files:</p>\n<ul>\n<li><code>vars.tf</code>: Input variables.</li>\n<li><code>outputs.tf</code>: Output variables.</li>\n<li><code>main.tf</code>: The actual resources.</li>\n</ul>\n<h1>Modules</h1>\n<p>Typically, we define our infrastructure in two folders:</p>\n<ol>\n<li><code>infrastructure-modules</code>: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.</li>\n<li><code>infrastructure-live</code>: This folder contains the actual live, running infrastructure, which it creates by combining the modules in <code>infrastructure-modules</code>. Think of the code in this folder as the actual houses you built from your blueprints.</li>\n</ol>\n<p>A <a href=\"https://www.terraform.io/intro/getting-started/modules.html\" rel=\"noreferrer\">Terraform module</a> is just any set of Terraform templates in a folder. For example, we might have a folder called <code>vpc</code> in <code>infrastructure-modules</code> that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:</p>\n<pre><code>infrastructure-modules\n  \u2514 vpc\n    \u2514 main.tf\n    \u2514 vars.tf\n    \u2514 outputs.tf\n</code></pre>\n<p>We can then use that module in <code>infrastructure-live/stage</code> and <code>infrastructure-live/prod</code> to create the stage and prod VPCs. For example, here is what <code>infrastructure-live/stage/main.tf</code> might look like:</p>\n<pre class=\"lang-hcl prettyprint-override\"><code>module &quot;stage_vpc&quot; {\n  source = &quot;git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4&quot;\n\n  vpc_name         = &quot;stage&quot;\n  aws_region       = &quot;us-east-1&quot;\n  num_nat_gateways = 3\n  cidr_block       = &quot;10.2.0.0/18&quot;\n}\n</code></pre>\n<p>To use a module, you use the <code>module</code> resource and point its <code>source</code> field to either a local path on your hard drive (e.g. <code>source = &quot;../infrastructure-modules/vpc&quot;</code>) or, as in the example above, a Git URL (see <a href=\"https://www.terraform.io/docs/modules/sources.html\" rel=\"noreferrer\">module sources</a>). The advantage of the Git URL is that we can specify a specific git sha1 or tag (<code>ref=v0.0.4</code>). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.</p>\n<p>We've created a number of reusable, tested, and documented <a href=\"http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do\" rel=\"noreferrer\">Infrastructure Packages</a> for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.</p>\n<h1>State</h1>\n<p>When you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a <code>.tfstate</code> file. To make changes to those resources, everyone on your team needs access to this same <code>.tfstate</code> file, but you should NOT check it into Git (see <a href=\"https://stackoverflow.com/a/38748987/483528\">here for an explanation why</a>).</p>\n<p>Instead, we recommend storing <code>.tfstate</code> files in S3 by enabling <a href=\"https://www.terraform.io/docs/state/remote/s3.html\" rel=\"noreferrer\">Terraform Remote State</a>, which will automatically push/pull the latest files every time you run Terraform. Make sure to <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html\" rel=\"noreferrer\">enable versioning</a> in your S3 bucket so you can roll back to older <code>.tfstate</code> files in case you somehow corrupt the latest version. <strike>However, an important note: <strong>Terraform doesn't provide locking</strong>. So if two team members run <code>terraform apply</code> at the same time on the same <code>.tfstate</code> file, they may end up overwriting each other's changes.</strike></p>\n<p><strong>Edit 2020</strong>: Terraform now supports locking: <a href=\"https://www.terraform.io/docs/state/locking.html\" rel=\"noreferrer\">https://www.terraform.io/docs/state/locking.html</a></p>\n<p>To solve this problem, we created an open source tool called <a href=\"https://github.com/gruntwork-io/terragrunt\" rel=\"noreferrer\">Terragrunt</a>, which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out <a href=\"https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d\" rel=\"noreferrer\">Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt</a> for more info.</p>\n<h1>Further reading</h1>\n<p>We've just started a series of blog posts called <a href=\"https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca\" rel=\"noreferrer\">A Comprehensive Guide to Terraform</a> that describes in detail all the best practices we've learned for using Terraform in the real world.</p>\n<p><em>Update: the Comprehensive Guide to Terraform blog post series got so popular that we expanded it into a book called <a href=\"http://www.terraformupandrunning.com/\" rel=\"noreferrer\">Terraform: Up &amp; Running</a></em>!</p>\n", "OwnerUserId": "483528", "LastEditorUserId": "11573541", "LastEditDate": "2020-10-24T20:10:38.327", "LastActivityDate": "2020-10-24T20:10:38.327", "CommentCount": "7", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "65209838", "PostId": "38749508", "Score": "0", "Text": "I think this is the correct answer. Use modules, version them, and keep environments separate.", "CreationDate": "2016-08-12T21:04:42.940", "UserId": "628652", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "71426339", "PostId": "38749508", "Score": "0", "Text": "Does the remote config step need to be rerun each time you want to work on a different terraform component/environment/module/whatever if not using terragrunt or some other wrapper?", "CreationDate": "2017-02-09T06:23:32.227", "UserId": "926190", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "71440539", "PostId": "38749508", "Score": "0", "Text": "@jmreicha: You need to run `remote config` if you just checked out your Terraform configurations or if you want to change a previous remote configuration. Terraform 0.9 will introduce the concept of `backends`, which will simplify a lot of this. See [this PR](https://github.com/hashicorp/terraform/pull/11286) for more details.", "CreationDate": "2017-02-09T12:52:23.153", "UserId": "483528", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "You need to run `remote config` if you just checked out your Terraform configurations or if you want to change a previous remote configuration. ", "keywords": ["change"]}]}, {"Id": "71455340", "PostId": "38749508", "Score": "0", "Text": "Just so that I understand - I am working on an environment 'stage' but then start working on 'prod'.  I will need to rerun the `remote config` command to point at the prod state.  Assuming different state per environment.  Is that right?  I look forward to v0.9.", "CreationDate": "2017-02-09T18:47:16.543", "UserId": "926190", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "71462294", "PostId": "38749508", "Score": "0", "Text": "If you were going to deploy the exact same set of `.tf` files to two different environments, yes, you'd need to run `remote config` each time you switched. This is obviously very error prone, so I don't recommend actually using this technique. Instead, check out the [recommended Terraform file layout in this blog post](https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa) along with [how to use Terraform modules in this blog post](https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d).", "CreationDate": "2017-02-09T22:18:17.633", "UserId": "483528", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "71498114", "PostId": "38749508", "Score": "0", "Text": "That helps.  Thanks.", "CreationDate": "2017-02-10T18:51:07.170", "UserId": "926190", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "77178516", "PostId": "38749508", "Score": "0", "Text": "I started to use `inputs.tf` for input variables. But yeah, nice to have consistency in a project so when you jump between modules you know what they get in and what they expose out.", "CreationDate": "2017-07-14T13:05:08.680", "UserId": "455642", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}], "history": [{"Id": "124119589", "PostHistoryTypeId": "2", "PostId": "38749508", "RevisionGUID": "de1d9bfe-fa6d-498d-8b57-ab7d3674a075", "CreationDate": "2016-08-03T16:52:56.250", "UserId": "483528", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name = \"stage\"\r\n      aws_region = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "125061344", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "a3b8bf04-f4a0-4794-8a9f-aae572a72a14", "CreationDate": "2016-08-16T23:09:40.447", "UserId": "483528", "Comment": "added 211 characters in body", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name = \"stage\"\r\n      aws_region = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "127973314", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "e7db762b-d10c-4906-a539-7a16abe92e61", "CreationDate": "2016-09-26T22:07:49.093", "UserId": "483528", "Comment": "added 252 characters in body", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name = \"stage\"\r\n      aws_region = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.\r\n\r\n# Further reading\r\n\r\nWe've just started a series of blog posts called [A Comprehensive Guide to Terraform](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca) that describes in detail all the best practices we've learned for using Terraform in the real world.", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "131811011", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "3987c211-0f83-4aa7-ae31-7b91099aa1c9", "CreationDate": "2016-11-17T18:06:45.613", "UserId": "483528", "Comment": "added 187 characters in body", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name = \"stage\"\r\n      aws_region = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.\r\n\r\n# Further reading\r\n\r\nWe've just started a series of blog posts called [A Comprehensive Guide to Terraform](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca) that describes in detail all the best practices we've learned for using Terraform in the real world.\r\n\r\n*Update: the Comprehensive Guide to Terraform blog post series got so popular that we expanded it into a book called [Terraform: Up & Running](http://www.terraformupandrunning.com/)*!", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](http://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "147703220", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "a4e4171c-0176-4b59-a7ea-389068845866", "CreationDate": "2017-05-23T12:34:33.157", "UserDisplayName": "URL Rewriter Bot", "Comment": "replaced http://stackoverflow.com/ with https://stackoverflow.com/", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name = \"stage\"\r\n      aws_region = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.\r\n\r\n# Further reading\r\n\r\nWe've just started a series of blog posts called [A Comprehensive Guide to Terraform](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca) that describes in detail all the best practices we've learned for using Terraform in the real world.\r\n\r\n*Update: the Comprehensive Guide to Terraform blog post series got so popular that we expanded it into a book called [Terraform: Up & Running](http://www.terraformupandrunning.com/)*!", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "192544088", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "d4edfee3-b107-48a5-b878-4125878f727b", "CreationDate": "2019-02-27T14:30:30.370", "UserId": "1092815", "Comment": "syntax highlighting", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n<!-- language: lang-hcl -->\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name         = \"stage\"\r\n      aws_region       = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block       = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.\r\n\r\n# Further reading\r\n\r\nWe've just started a series of blog posts called [A Comprehensive Guide to Terraform](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca) that describes in detail all the best practices we've learned for using Terraform in the real world.\r\n\r\n*Update: the Comprehensive Guide to Terraform blog post series got so popular that we expanded it into a book called [Terraform: Up & Running](http://www.terraformupandrunning.com/)*!", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "233526675", "PostHistoryTypeId": "5", "PostId": "38749508", "RevisionGUID": "ad62682b-e3d7-4db8-9a3a-69aa3ee246b5", "CreationDate": "2020-10-24T20:10:38.327", "UserId": "11573541", "Comment": "terraform state lock support", "Text": "We use Terraform heavily and our recommended setup is as follows:\r\n\r\n# File layout\r\n\r\nWe highly recommend storing the Terraform code for each of your environments (e.g. stage, prod, qa) in separate sets of templates (and therefore, separate `.tfstate` files). This is important so that your separate environments are actually isolated from each other while making changes. Otherwise, while messing around with some code in staging, it's too easy to blow up something in prod too. See [Terraform, VPC, and why you want a tfstate file per env](https://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/) for a colorful discussion of why.\r\n\r\nTherefore, our typical file layout looks like this:\r\n\r\n    stage\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    prod\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n    global\r\n      \u2514 main.tf\r\n      \u2514 vars.tf\r\n      \u2514 outputs.tf\r\n\r\nAll the Terraform code for the stage VPC goes into the `stage` folder, all the code for the prod VPC goes into the `prod` folder, and all the code that lives outside of a VPC (e.g. IAM users, SNS topics, S3 buckets) goes into the `global` folder.\r\n\r\nNote that, by convention, we typically break our Terraform code down into 3 files:\r\n\r\n* `vars.tf`: Input variables.\r\n* `outputs.tf`: Output variables.\r\n* `main.tf`: The actual resources.\r\n\r\n# Modules\r\n\r\nTypically, we define our infrastructure in two folders: \r\n\r\n1. `infrastructure-modules`: This folder contains small, reusable, versioned modules. Think of each module as a blueprint for how to create a single piece of infrastructure, such as a VPC or a database.\r\n1. `infrastructure-live`: This folder contains the actual live, running infrastructure, which it creates by combining the modules in `infrastructure-modules`. Think of the code in this folder as the actual houses you built from your blueprints.\r\n\r\nA [Terraform module](https://www.terraform.io/intro/getting-started/modules.html) is just any set of Terraform templates in a folder. For example, we might have a folder called `vpc` in `infrastructure-modules` that defines all the route tables, subnets, gateways, ACLs, etc for a single VPC:\r\n\r\n    infrastructure-modules\r\n      \u2514 vpc\r\n        \u2514 main.tf\r\n        \u2514 vars.tf\r\n        \u2514 outputs.tf\r\n\r\nWe can then use that module in `infrastructure-live/stage` and `infrastructure-live/prod` to create the stage and prod VPCs. For example, here is what `infrastructure-live/stage/main.tf` might look like:\r\n\r\n<!-- language: lang-hcl -->\r\n\r\n    module \"stage_vpc\" {\r\n      source = \"git::git@github.com:gruntwork-io/module-vpc.git//modules/vpc-app?ref=v0.0.4\"\r\n\r\n      vpc_name         = \"stage\"\r\n      aws_region       = \"us-east-1\"\r\n      num_nat_gateways = 3\r\n      cidr_block       = \"10.2.0.0/18\"\r\n    }\r\n\r\nTo use a module, you use the `module` resource and point its `source` field to either a local path on your hard drive (e.g. `source = \"../infrastructure-modules/vpc\"`) or, as in the example above, a Git URL (see [module sources](https://www.terraform.io/docs/modules/sources.html)). The advantage of the Git URL is that we can specify a specific git sha1 or tag (`ref=v0.0.4`). Now, not only do we define our infrastructure as a bunch of small modules, but we can version those modules and carefully update or rollback as needed.\r\n\r\nWe've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules.\r\n\r\n# State\r\n\r\nWhen you use Terraform to create resources (e.g. EC2 instances, databases, VPCs), it records information on what it created in a `.tfstate` file. To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). \r\n\r\nInstead, we recommend storing `.tfstate` files in S3 by enabling [Terraform Remote State](https://www.terraform.io/docs/state/remote/s3.html), which will automatically push/pull the latest files every time you run Terraform. Make sure to [enable versioning](https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html) in your S3 bucket so you can roll back to older `.tfstate` files in case you somehow corrupt the latest version. <strike>However, an important note: **Terraform doesn't provide locking**. So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes.</strike>\r\n\r\n**Edit 2020**: Terraform now supports locking: https://www.terraform.io/docs/state/locking.html\r\n\r\nTo solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). Check out [Add Automatic Remote State Locking and Configuration to Terraform with Terragrunt](https://blog.gruntwork.io/add-automatic-remote-state-locking-and-configuration-to-terraform-with-terragrunt-656a57565a4d) for more info.\r\n\r\n# Further reading\r\n\r\nWe've just started a series of blog posts called [A Comprehensive Guide to Terraform](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca) that describes in detail all the best practices we've learned for using Terraform in the real world.\r\n\r\n*Update: the Comprehensive Guide to Terraform blog post series got so popular that we expanded it into a book called [Terraform: Up & Running](http://www.terraformupandrunning.com/)*!", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Text", "text": "We've created a number of reusable, tested, and documented [Infrastructure Packages](http://www.gruntwork.io/?ref=medium-gruntwork-packages#what-we-do) for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Text", "text": "To make changes to those resources, everyone on your team needs access to this same `.tfstate` file, but you should NOT check it into Git (see [here for an explanation why](https://stackoverflow.com/a/38748987/483528)). ", "keywords": ["change"]}, {"source": "Text", "text": "So if two team members run `terraform apply` at the same time on the same `.tfstate` file, they may end up overwriting each other's changes. **Edit 2020**: Terraform now supports locking: https://www.terraform.io/docs/state/locking.html To solve this problem, we created an open source tool called [Terragrunt](https://github.com/gruntwork-io/terragrunt), which is a thin wrapper for Terraform that uses Amazon DynamoDB to provide locking (which should be completely free for most teams). ", "keywords": ["change"]}]}, {"Id": "233526676", "PostHistoryTypeId": "24", "PostId": "38749508", "RevisionGUID": "ad62682b-e3d7-4db8-9a3a-69aa3ee246b5", "CreationDate": "2020-10-24T20:10:38.327", "Comment": "Proposed by 11573541 approved by 483528 edit id of 4989243", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": [{"source": "Body", "text": "This is important so that your separate environments are actually isolated from each other while making changes. ", "keywords": ["change"]}, {"source": "Body", "text": "We've created a number of reusable, tested, and documented Infrastructure Packages for creating VPCs, Docker clusters, databases, and so on, and under the hood, most of them are just versioned Terraform modules. ", "keywords": ["test"]}, {"source": "Body", "text": "To make changes to those resources, everyone on your team needs access to this same .tfstate file, but you should NOT check it into Git (see here for an explanation why). ", "keywords": ["change"]}, {"source": "Body", "text": "So if two team members run terraform apply at the same time on the same .tfstate file, they may end up overwriting each other's changes. ", "keywords": ["change"]}]}, {"Id": "60525690", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2020-03-04T12:06:27.237", "Score": "0", "Body": "<p>I'd like to contribute to this thread. </p>\n\n<ul>\n<li>This will most likely be AWS S3+DynamoDB unless you are using Terraform Cloud. </li>\n<li>Separate infrastructure (network + RBAC) of production and non-prod backends.  </li>\n<li>Plan to disable access to state files (network access and RBAC) from outside of a designated network (e.g. deployment agent pool). </li>\n<li>Do not keep Terraform backend infrastructure with the run-time environment. Use separate\naccount. </li>\n<li>Enable object versioning on your Terraform backends to avoid losing changes and state-files, and in order to maintain Terraform state history.</li>\n</ul>\n\n<p>In some special cases, manual access to Terraform state files will be required. Things like refactoring, breaking changes or fixing defects will require running Terraform state operations by operations personnel. For such occasions, plan extraordinary controlled access to the Terraform state using bastion host, VPN etc.</p>\n\n<p>Check a <a href=\"https://blog.gft.com/pl/2020/03/04/secure-terraform-delivery-pipeline-best-practices-part-1-2/\" rel=\"nofollow noreferrer\">longer best practices blog</a> that covers this in details including guidelines for CI/CD pipelines.</p>\n", "OwnerUserId": "221951", "LastActivityDate": "2020-03-04T12:06:27.237", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "216255557", "PostHistoryTypeId": "2", "PostId": "60525690", "RevisionGUID": "861e563f-23f2-49b1-b925-752b032c5bd3", "CreationDate": "2020-03-04T12:06:27.237", "UserId": "221951", "Text": "I'd like to contribute to this thread. \r\n\r\n- This will most likely be AWS S3+DynamoDB unless you are using Terraform Cloud. \r\n- Separate infrastructure (network + RBAC) of production and non-prod backends.  \r\n- Plan to disable access to state files (network access and RBAC) from outside of a designated network (e.g. deployment agent pool). \r\n- Do not keep Terraform backend infrastructure with the run-time environment. Use separate\r\n   account. \r\n- Enable object versioning on your Terraform backends to avoid losing changes and state-files, and in order to maintain Terraform state history.\r\n\r\nIn some special cases, manual access to Terraform state files will be required. Things like refactoring, breaking changes or fixing defects will require running Terraform state operations by operations personnel. For such occasions, plan extraordinary controlled access to the Terraform state using bastion host, VPN etc.\r\n\r\nCheck a [longer best practices blog][1] that covers this in details including guidelines for CI/CD pipelines.\r\n\r\n\r\n  [1]: https://blog.gft.com/pl/2020/03/04/secure-terraform-delivery-pipeline-best-practices-part-1-2/", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "- Enable object versioning on your Terraform backends to avoid losing changes and state-files, and in order to maintain Terraform state history. ", "keywords": ["change"]}, {"source": "Text", "text": "Things like refactoring, breaking changes or fixing defects will require running Terraform state operations by operations personnel. ", "keywords": ["change"]}, {"source": "Text", "text": "For such occasions, plan extraordinary controlled access to the Terraform state using bastion host, VPN etc. Check a [longer best practices blog][1] that covers this in details including guidelines for CI/CD pipelines. ", "keywords": ["vpn"]}]}], "filtered-sentences": [{"source": "Body", "text": "Enable object versioning on your Terraform backends to avoid losing changes and state-files, and in order to maintain Terraform state history. ", "keywords": ["change"]}, {"source": "Body", "text": "Things like refactoring, breaking changes or fixing defects will require running Terraform state operations by operations personnel. ", "keywords": ["change"]}, {"source": "Body", "text": "For such occasions, plan extraordinary controlled access to the Terraform state using bastion host, VPN etc. ", "keywords": ["vpn"]}]}, {"Id": "56820116", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2019-06-29T18:57:59.900", "Score": "0", "Body": "<blockquote>\n  <p>Before answers have been very solid and informative, I will try to add\n  my 2 cents here</p>\n</blockquote>\n\n<h2>Common recommendations for structuring code</h2>\n\n<ol>\n<li><p>It is easier and faster to work with smaller number of resources:</p>\n\n<ul>\n<li>Cmds<code>terraform plan</code> and <code>terraform</code> apply both make cloud API calls to verify the status of resources.</li>\n<li>If you have your entire infrastructure in a single composition this can take many minutes (even if you have several files in the same folder).</li>\n</ul></li>\n<li><p>Blast radius is smaller with fewer resources:</p>\n\n<ul>\n<li>Insulating unrelated resources from each other by placing them in separate compositions (folders) reduces the risk if something goes wrong.</li>\n</ul></li>\n<li><p>Start your project using remote state:</p>\n\n<ul>\n<li>Your laptop is no place for your infrastructure source of truth.</li>\n<li>Managing a <code>tfstate</code> file in git is a nightmare.</li>\n<li>Later when infrastructure layers starts to grow in any direction (number of dependencies or resources).</li>\n<li>example module: <a href=\"https://github.com/cloudposse/terraform-aws-tfstate-backend\" rel=\"nofollow noreferrer\">https://github.com/cloudposse/terraform-aws-tfstate-backend</a></li>\n<li>ref tool: <a href=\"https://github.com/camptocamp/terraboard\" rel=\"nofollow noreferrer\">https://github.com/camptocamp/terraboard</a></li>\n</ul></li>\n<li><p>Try to practice a consistent structure and naming convention:</p>\n\n<ul>\n<li>Like procedural code, <strong>Terraform</strong> code should be written for people to read first, consistency will help when changes happen six months from now.</li>\n<li>It is possible to move resources in <strong>Terraform state file</strong> but it may be harder to do if you have inconsistent structure and naming.</li>\n</ul></li>\n<li><p>Keep resource modules as plain as possible.</p></li>\n<li><p>Don't <strong>hard-code</strong> values which can be passed as variables or discovered using data sources.</p></li>\n<li><p>Use <code>data</code> sources and <code>terraform_remote_state</code> specifically as a glue between infrastructure modules within composition.</p></li>\n</ol>\n\n<p>(<strong>ref article:</strong> <a href=\"https://www.terraform-best-practices.com/code-structure\" rel=\"nofollow noreferrer\">https://www.terraform-best-practices.com/code-structure</a>)</p>\n\n<hr>\n\n<p><strong>Example:</strong> </p>\n\n<blockquote>\n  <p>It is easier and faster to work with smaller number of resources so\n  below we present a recommended code layout. </p>\n</blockquote>\n\n<p><em>NOTE: just as reference not to be strictly follow since each project has it's own specific characteristics</em></p>\n\n<pre><code>.\n\u251c\u2500\u2500 1_tf-backend #remote AWS S3 + Dynamo Lock tfstate \n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 2_secrets\n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 3_identities\n\u2502   \u251c\u2500\u2500 account.tf\n\u2502   \u251c\u2500\u2500 roles.tf\n\u2502   \u251c\u2500\u2500 group.tf\n\u2502   \u251c\u2500\u2500 users.tf\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 4_security\n\u2502   \u251c\u2500\u2500 awscloudtrail.tf\n\u2502   \u251c\u2500\u2500 awsconfig.tf\n\u2502   \u251c\u2500\u2500 awsinspector.tf\n\u2502   \u251c\u2500\u2500 awsguarduty.tf\n\u2502   \u251c\u2500\u2500 awswaf.tf\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 5_network\n\u2502   \u251c\u2500\u2500 account.tf\n\u2502   \u251c\u2500\u2500 dns_remote_zone_auth.tf\n\u2502   \u251c\u2500\u2500 dns.tf\n\u2502   \u251c\u2500\u2500 network.tf\n\u2502   \u251c\u2500\u2500 network_vpc_peering_dev.tf\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 6_notifications\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 7_containers\n\u2502   \u251c\u2500\u2500 account.tf\n\u2502   \u251c\u2500\u2500 container_registry.tf\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 config\n\u2502   \u251c\u2500\u2500 backend.config\n\u2502   \u2514\u2500\u2500 main.config\n\u2514\u2500\u2500 readme.md\n</code></pre>\n", "OwnerUserId": "2033312", "LastEditorUserId": "2033312", "LastEditDate": "2019-06-29T19:13:56.497", "LastActivityDate": "2019-06-29T19:13:56.497", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "200621332", "PostHistoryTypeId": "2", "PostId": "56820116", "RevisionGUID": "fac8cfda-6d8c-4822-a7ec-96241c2e664a", "CreationDate": "2019-06-29T18:57:59.900", "UserId": "2033312", "Text": "## Common recommendations for structuring code\r\n\r\n1. It is easier and faster to work with smaller number of resources:\r\n  * Cmds`terraform plan` and `terraform` apply both make cloud API calls to verify the status of resources.\r\n  - If you have your entire infrastructure in a single composition this can take many minutes (even if you have several files in the same folder).\r\n\r\n2. Blast radius is smaller with fewer resources:\r\n  - Insulating unrelated resources from each other by placing them in separate compositions (folders) reduces the risk if something goes wrong.\r\n\r\n3. Start your project using remote state:\r\n  - Your laptop is no place for your infrastructure source of truth.\r\n  - Managing a `tfstate` file in git is a nightmare.\r\n  - Later when infrastructure layers starts to grow in any direction (number of dependencies or resources).\r\n  - example module: https://github.com/cloudposse/terraform-aws-tfstate-backend\r\n  - ref tool: https://github.com/camptocamp/terraboard\r\n\r\n4. Try to practice a consistent structure and naming convention:\r\n  - Like procedural code, **Terraform** code should be written for people to read first, consistency will help when changes happen six months from now.\r\n  - It is possible to move resources in **Terraform state file** but it may be harder to do if you have inconsistent structure and naming.\r\n\r\n5. Keep resource modules as plain as possible.\r\n\r\n6. Don't **hard-code** values which can be passed as variables or discovered using data sources.\r\n\r\n7. Use `data` sources and `terraform_remote_state` specifically as a glue between infrastructure modules within composition.\r\n\r\n(**ref article:** https://www.terraform-best-practices.com/code-structure)\r\n\r\n**Example:** (It is easier and faster to work with smaller number of resources so below we present a recommended code layout. *NOTE: just as reference not to be strictly follow since each project has it's own specific characteristics*)\r\n\r\n```\r\n.\r\n\u251c\u2500\u2500 1_tf-backend #remote AWS S3 + Dynamo Lock tfstate \r\n\u2502   \u251c\u2500\u2500 main.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 2_secrets\r\n\u2502   \u251c\u2500\u2500 main.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 3_identities\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 roles.tf\r\n\u2502   \u251c\u2500\u2500 group.tf\r\n\u2502   \u251c\u2500\u2500 users.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 4_security\r\n\u2502   \u251c\u2500\u2500 awscloudtrail.tf\r\n\u2502   \u251c\u2500\u2500 awsconfig.tf\r\n\u2502   \u251c\u2500\u2500 awsinspector.tf\r\n\u2502   \u251c\u2500\u2500 awsguarduty.tf\r\n\u2502   \u251c\u2500\u2500 awswaf.tf\r\n\u2502   \u2514\u2500\u2500 ...\r\n\u251c\u2500\u2500 5_network\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 dns_remote_zone_auth.tf\r\n\u2502   \u251c\u2500\u2500 dns.tf\r\n\u2502   \u251c\u2500\u2500 network.tf\r\n\u2502   \u251c\u2500\u2500 network_vpc_peering_dev.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 6_notifications\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 7_containers\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 container_registry.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 config\r\n\u2502   \u251c\u2500\u2500 backend.config\r\n\u2502   \u2514\u2500\u2500 main.config\r\n\u2514\u2500\u2500 readme.md\r\n```", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Try to practice a consistent structure and naming convention: - Like procedural code, **Terraform** code should be written for people to read first, consistency will help when changes happen six months from now. ", "keywords": ["change"]}]}, {"Id": "200621896", "PostHistoryTypeId": "5", "PostId": "56820116", "RevisionGUID": "f1adecd3-695e-4400-8057-6a84446d3fab", "CreationDate": "2019-06-29T19:13:56.497", "UserId": "2033312", "Comment": "added 111 characters in body", "Text": "> Before answers have been very solid and informative, I will try to add\r\n> my 2 cents here\r\n\r\n## Common recommendations for structuring code\r\n\r\n1. It is easier and faster to work with smaller number of resources:\r\n  * Cmds`terraform plan` and `terraform` apply both make cloud API calls to verify the status of resources.\r\n  - If you have your entire infrastructure in a single composition this can take many minutes (even if you have several files in the same folder).\r\n\r\n2. Blast radius is smaller with fewer resources:\r\n  - Insulating unrelated resources from each other by placing them in separate compositions (folders) reduces the risk if something goes wrong.\r\n\r\n3. Start your project using remote state:\r\n  - Your laptop is no place for your infrastructure source of truth.\r\n  - Managing a `tfstate` file in git is a nightmare.\r\n  - Later when infrastructure layers starts to grow in any direction (number of dependencies or resources).\r\n  - example module: https://github.com/cloudposse/terraform-aws-tfstate-backend\r\n  - ref tool: https://github.com/camptocamp/terraboard\r\n\r\n4. Try to practice a consistent structure and naming convention:\r\n  - Like procedural code, **Terraform** code should be written for people to read first, consistency will help when changes happen six months from now.\r\n  - It is possible to move resources in **Terraform state file** but it may be harder to do if you have inconsistent structure and naming.\r\n\r\n5. Keep resource modules as plain as possible.\r\n\r\n6. Don't **hard-code** values which can be passed as variables or discovered using data sources.\r\n\r\n7. Use `data` sources and `terraform_remote_state` specifically as a glue between infrastructure modules within composition.\r\n\r\n(**ref article:** https://www.terraform-best-practices.com/code-structure)\r\n\r\n---\r\n\r\n**Example:** \r\n> It is easier and faster to work with smaller number of resources so\r\n> below we present a recommended code layout. \r\n\r\n*NOTE: just as reference not to be strictly follow since each project has it's own specific characteristics*\r\n\r\n```\r\n.\r\n\u251c\u2500\u2500 1_tf-backend #remote AWS S3 + Dynamo Lock tfstate \r\n\u2502   \u251c\u2500\u2500 main.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 2_secrets\r\n\u2502   \u251c\u2500\u2500 main.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 3_identities\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 roles.tf\r\n\u2502   \u251c\u2500\u2500 group.tf\r\n\u2502   \u251c\u2500\u2500 users.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 4_security\r\n\u2502   \u251c\u2500\u2500 awscloudtrail.tf\r\n\u2502   \u251c\u2500\u2500 awsconfig.tf\r\n\u2502   \u251c\u2500\u2500 awsinspector.tf\r\n\u2502   \u251c\u2500\u2500 awsguarduty.tf\r\n\u2502   \u251c\u2500\u2500 awswaf.tf\r\n\u2502   \u2514\u2500\u2500 ...\r\n\u251c\u2500\u2500 5_network\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 dns_remote_zone_auth.tf\r\n\u2502   \u251c\u2500\u2500 dns.tf\r\n\u2502   \u251c\u2500\u2500 network.tf\r\n\u2502   \u251c\u2500\u2500 network_vpc_peering_dev.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 6_notifications\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 7_containers\r\n\u2502   \u251c\u2500\u2500 account.tf\r\n\u2502   \u251c\u2500\u2500 container_registry.tf\r\n\u2502   \u251c\u2500\u2500 ...\r\n\u251c\u2500\u2500 config\r\n\u2502   \u251c\u2500\u2500 backend.config\r\n\u2502   \u2514\u2500\u2500 main.config\r\n\u2514\u2500\u2500 readme.md\r\n```", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Try to practice a consistent structure and naming convention: - Like procedural code, **Terraform** code should be written for people to read first, consistency will help when changes happen six months from now. ", "keywords": ["change"]}]}], "filtered-sentences": [{"source": "Body", "text": "Try to practice a consistent structure and naming convention: Like procedural code, Terraform code should be written for people to read first, consistency will help when changes happen six months from now. ", "keywords": ["change"]}]}, {"Id": "33628841", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2015-11-10T11:22:29.450", "Score": "108", "Body": "<p>I am also in a state of migrating existing AWS infrastructure to Terraform so shall aim to update the answer as I develop. </p>\n\n<p>I have been relying heavily on the official Terraform <a href=\"https://github.com/hashicorp/terraform/tree/master/examples\" rel=\"noreferrer\">examples</a> and multiple trial and error to flesh out areas that I have been uncertain in.</p>\n\n<p><strong><code>.tfstate</code> files</strong></p>\n\n<p>Terraform config can be used to provision many boxes on different infrastructure, each of which could have a different state. As it can also be run by multiple people this state should be in a centralised location (like S3) but <em>not</em> git. </p>\n\n<p>This can be confirmed looking at the Terraform <a href=\"https://github.com/hashicorp/terraform/blob/347f9c0bea68722a85a1e453c69e6a756043f6b8/.gitignore\" rel=\"noreferrer\"><code>.gitignore</code></a>.</p>\n\n<p><strong>Developer control</strong></p>\n\n<p>Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). With that in mind the new infrastructure workflow I am aiming towards is:</p>\n\n<ol>\n<li>Base foundation of common AMI's that include reusable modules e.g. puppet.</li>\n<li>Core infrastructure provisioned by DevOps using Terraform.</li>\n<li>Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc).</li>\n<li>Git configuration pushed and a pull request submitted to be sanity checked by a member of DevOps squad.</li>\n<li>If approved, calls webhook to CI to build and deploy (unsure how to partition multiple environments at this time)</li>\n</ol>\n\n<p><strong>Edit 1 - Update on current state</strong></p>\n\n<p>Since starting this answer I have written a lot of TF code and feel more comfortable in our state of affairs. We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software.</p>\n\n<p><strong>Layout</strong></p>\n\n<p>We have a complicated AWS infrastructure with multiple VPC's each with multiple subnets. Key to easily managing this was to define a flexible taxonomy that encompasses region, environment, service and owner which we can use to organise our infrastructure code (both terraform and puppet). </p>\n\n<p><strong>Modules</strong></p>\n\n<p>Next step was to create a single git repository to store our terraform modules. Our top level dir structure for the modules looks like this:</p>\n\n<pre class=\"lang-bash prettyprint-override\"><code>tree -L 1 .\n</code></pre>\n\n<p>Result:</p>\n\n<pre><code>\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 aws-asg\n\u251c\u2500\u2500 aws-ec2\n\u251c\u2500\u2500 aws-elb\n\u251c\u2500\u2500 aws-rds\n\u251c\u2500\u2500 aws-sg\n\u251c\u2500\u2500 aws-vpc\n\u2514\u2500\u2500 templates\n</code></pre>\n\n<p>Each one sets some sane defaults but exposes them as variables that can be overwritten by our \"glue\".</p>\n\n<p><strong>Glue</strong></p>\n\n<p>We have a second repository with our <code>glue</code> that makes use of the modules mentioned above. It is laid out in line with our taxonomy document:</p>\n\n<pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 clientA\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dev\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 us-east-1\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 dev\n\u251c\u2500\u2500 clientB\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam.tf\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 terraform.tfstate\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate.backup\n\u2514\u2500\u2500 clientC\n    \u251c\u2500\u2500 eu-west-1\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 aws.tf\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-roles.tf\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 stg\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\n    \u2514\u2500\u2500 iam.tf\n</code></pre>\n\n<p>Inside the client level we have AWS account specific <code>.tf</code> files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (<code>dev</code>, <code>stg</code>, <code>prod</code> etc) are our VPC setups, instance creation and peering connections etc. are stored. </p>\n\n<p><em>Side Note:</em> As you can see I'm going against my own advice above keeping <code>terraform.tfstate</code> in git. This is a temporary measure until I move to S3 but suits me as I'm currently the only developer.</p>\n\n<p><strong>Next Steps</strong></p>\n\n<p>This is still a manual process and not in Jenkins yet but we're porting a rather large, complicated infrastructure and so far so good. Like I said, few bugs but going well! </p>\n\n<p><strong>Edit 2 - Changes</strong></p>\n\n<p>It's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. I am now at a new position using Terraform to manage an Azure cluster and Terraform is now <code>v0.10.7</code>.</p>\n\n<p><strong>State</strong></p>\n\n<p>People have repeatedly told me state should <em>not</em> go in Git - and they are correct. We used this as an interim measure with a two person team that relied on developer communication and discipline. With a larger, distributed team we are now fully leveraging remote state in S3 with <a href=\"https://www.terraform.io/docs/state/locking.html\" rel=\"noreferrer\">locking</a> provided by DynamoDB. Ideally this will be migrated to consul now it is v1.0 to cut cross cloud providers. </p>\n\n<p><strong>Modules</strong></p>\n\n<p>Previously we created and used internal modules. This is still the case but with the advent and growth of the <a href=\"https://registry.terraform.io/\" rel=\"noreferrer\">Terraform registry</a> we try to use these as at least a base. </p>\n\n<p><strong>File structure</strong></p>\n\n<p>The new position has a much simpler taxonomy with only two infx environments - <code>dev</code> and <code>prod</code>. Each has their own variables and outputs, reusing our modules created above. The <a href=\"https://www.terraform.io/docs/providers/terraform/d/remote_state.html\" rel=\"noreferrer\"><code>remote_state</code></a> provider also helps in sharing outputs of created resources between environments. Our scenario is subdomains in different Azure resource groups to a globally managed TLD.</p>\n\n<pre><code>\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 dev\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 main.tf\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 output.tf\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 variables.tf\n\u2514\u2500\u2500 prod\n    \u251c\u2500\u2500 main.tf\n    \u251c\u2500\u2500 output.tf\n    \u2514\u2500\u2500 variables.tf\n</code></pre>\n\n<p><strong>Planning</strong></p>\n\n<p>Again with extra challenges of a distributed team, we now always save our output of the <code>terraform plan</code> command. We can inspect and know what will be run without the risk of some changes between the <code>plan</code> and <code>apply</code> stage (although locking helps with this). Remember to delete this plan file as it could potentially contain plain text \"secret\" variables. </p>\n\n<p>Overall we are very happy with Terraform and continue to learn and improve with the new features added.</p>\n", "OwnerUserId": "1401034", "LastEditorUserId": "1092815", "LastEditDate": "2019-02-27T14:29:49.257", "LastActivityDate": "2019-02-27T14:29:49.257", "CommentCount": "15", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "55999463", "PostId": "33628841", "Score": "0", "Text": "Have you had any luck/issues since this answer? Yours seems very much like what I'm aiming to do, but you might be further along than me.", "CreationDate": "2015-12-07T02:18:45.877", "UserId": "1200057", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "56167532", "PostId": "33628841", "Score": "0", "Text": "nice! I'm still not able to implement on my side, we're clearing up some other stuff but it's awesome to know some things to do/avoid.", "CreationDate": "2015-12-10T21:01:56.173", "UserId": "1200057", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "56894750", "PostId": "33628841", "Score": "4", "Text": "I'm curious as to why you think tfstate files should not be stored in git? Is it simply because the old state is not worth saving, or are there other issues?", "CreationDate": "2016-01-03T09:29:17.963", "UserId": "3353794", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "56896171", "PostId": "33628841", "Score": "5", "Text": "@agbodike - When working as a single developer or part of a very small team tfstate can be kept in git as long as it is regularly committed and pushed to avoid conflicts. My next step is to set this up as per their [remote state](https://terraform.io/docs/state/remote.html) docs in S3 (which also say: \"it makes working with Terraform in a team complicated since it is a frequent source of merge conflicts. Remote state helps alleviate these issues.\" ). As with most things though good team communication can help alleviate most/all issues irregardless of tactic to hold state :-)", "CreationDate": "2016-01-03T10:57:59.960", "UserId": "1401034", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "63303718", "PostId": "33628841", "Score": "0", "Text": "if you had a git repo you could share that would be marvelous! thanks for this post.", "CreationDate": "2016-06-20T15:41:49.140", "UserId": "13800", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "63310456", "PostId": "33628841", "Score": "1", "Text": "@the0ther - I'm afraid my main repository is proprietary however I am currently working on a personal one I will make publicly available in the very near future.", "CreationDate": "2016-06-20T18:58:08.587", "UserId": "1401034", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "64579030", "PostId": "33628841", "Score": "2", "Text": "Any luck on a Git repo @Ewan? I'd love to see what you're doing.", "CreationDate": "2016-07-26T16:44:13.613", "UserId": "1076683", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "80529602", "PostId": "33628841", "Score": "0", "Text": "Adding `.tfstate`-files is a very bad idea, and should be avoided. You can mess up your whole infrastructure by deploying and forgetting to check in your `.tfstate`-file.\nYour statefile should be either stored in S3 or some other form of backend described in the official documentation.", "CreationDate": "2017-10-17T13:39:23.410", "UserId": "273715", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "80532618", "PostId": "33628841", "Score": "0", "Text": "Thanks @jottr - yes agreed. It was a temporary measure with a small team but we have now transitioned to remote storage especially with the new locking mechanism in newer terraform to prevent double writes. I will try to find time to add a second edit to my answer.", "CreationDate": "2017-10-17T14:49:37.257", "UserId": "1401034", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "It was a temporary measure with a small team but we have now transitioned to remote storage especially with the new locking mechanism in newer terraform to prevent double writes. ", "keywords": ["storage"]}]}, {"Id": "95246432", "PostId": "33628841", "Score": "0", "Text": "i put the following 2 entries in my .gitignore file: terraform.tfstate*\n.terraform", "CreationDate": "2019-01-16T03:53:08.977", "UserId": "4053049", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95246495", "PostId": "33628841", "Score": "0", "Text": "@agbodike tfstate files will show the aws account number in the arn created which poses a security risk.", "CreationDate": "2019-01-16T03:57:52.717", "UserId": "4053049", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "96578869", "PostId": "33628841", "Score": "0", "Text": "@tkjef your account number is secret? Are you sure? The major problem with terraform state it that it contains all the secrets defined via terraform.", "CreationDate": "2019-02-27T12:52:21.247", "UserId": "400222", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "99308728", "PostId": "33628841", "Score": "0", "Text": "What advantage do you get from splitting out variables.tf and output.tf? I mean, Terraform concats all tf files in the directory anyways. Why not keep them all in one file, separated by some newlines?", "CreationDate": "2019-05-29T01:35:52.760", "UserId": "2445864", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "99317716", "PostId": "33628841", "Score": "0", "Text": "@HubertGrzeskowiak biggest advantage is separation of concerns so other developers can find what they're looking for - it's not for `terraform` but rather for people. Side-note: Go (which Terraform is written in) recommends this exact best practice to avoid very large files (in this case over thousands of lines of code) https://talks.golang.org/2013/bestpractices.slide#17", "CreationDate": "2019-05-29T09:06:17.130", "UserId": "1401034", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "99317788", "PostId": "33628841", "Score": "0", "Text": "I don't see how splitting one large file into multiple files that are all evaluated in the same scope makes things easier. You just need to search for strings in multiple files instead of one. Imagine Java asked you to define your function's parameters in one place, the return value in another, oh and the logic of your function goes in yet another file. Or imagine Python asking you to declare your imports in a separate file. If these things were independent, I'd see the reason, but they are all concatenated anyways.", "CreationDate": "2019-05-29T09:08:35.130", "UserId": "2445864", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "history": [{"Id": "103795186", "PostHistoryTypeId": "2", "PostId": "33628841", "RevisionGUID": "cde085e8-7572-40bc-a457-cf7bc2c87085", "CreationDate": "2015-11-10T11:22:29.450", "UserId": "1401034", "Text": "I am also in a state of migrating existing AWS infrastructure to Terraform so shall aim to update the answer as I develop. \r\n\r\nI have been relying heavily on the official Terraform [examples](https://github.com/hashicorp/terraform/tree/master/examples) and multiple trial and error to flesh out areas that I have been uncertain in.\r\n\r\n**.tfstate files**\r\n\r\nTerraform config can be used to provision many boxes on different infrastructure, each of which could have a different state. As it can also be run by multiple people this state should be in a centralised location (like S3) but _not_ git. \r\n\r\nThis can be confirmed looking at the Terraform [`.gitignore`](https://github.com/hashicorp/terraform/blob/347f9c0bea68722a85a1e453c69e6a756043f6b8/.gitignore).\r\n\r\n**Developer control**\r\n\r\nOur aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). With that in mind the new infrastructure workflow I am aiming towards is:\r\n\r\n 1. Base foundation of common AMI's that include reusable modules e.g. puppet.\r\n 2. Core infrastructure provisioned by DevOps using Terraform.\r\n 3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc).\r\n 4. Git configuration pushed and a pull request submitted to be sanity checked by a member of DevOps squad.\r\n 5. If approved, calls webhook to CI to build and deploy (unsure how to partition multiple environments at this time)", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). ", "keywords": ["change"]}, {"source": "Text", "text": "3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc). ", "keywords": ["change"]}]}, {"Id": "106073508", "PostHistoryTypeId": "5", "PostId": "33628841", "RevisionGUID": "e1257536-b081-4c6f-97e6-2a6584c3c837", "CreationDate": "2015-12-10T10:27:00.550", "UserId": "1401034", "Comment": "added 2348 characters in body", "Text": "I am also in a state of migrating existing AWS infrastructure to Terraform so shall aim to update the answer as I develop. \r\n\r\nI have been relying heavily on the official Terraform [examples](https://github.com/hashicorp/terraform/tree/master/examples) and multiple trial and error to flesh out areas that I have been uncertain in.\r\n\r\n**.tfstate files**\r\n\r\nTerraform config can be used to provision many boxes on different infrastructure, each of which could have a different state. As it can also be run by multiple people this state should be in a centralised location (like S3) but _not_ git. \r\n\r\nThis can be confirmed looking at the Terraform [`.gitignore`](https://github.com/hashicorp/terraform/blob/347f9c0bea68722a85a1e453c69e6a756043f6b8/.gitignore).\r\n\r\n**Developer control**\r\n\r\nOur aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). With that in mind the new infrastructure workflow I am aiming towards is:\r\n\r\n 1. Base foundation of common AMI's that include reusable modules e.g. puppet.\r\n 2. Core infrastructure provisioned by DevOps using Terraform.\r\n 3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc).\r\n 4. Git configuration pushed and a pull request submitted to be sanity checked by a member of DevOps squad.\r\n 5. If approved, calls webhook to CI to build and deploy (unsure how to partition multiple environments at this time)\r\n\r\n**Edit 1 - Update on current state**\r\n\r\nSince starting this answer I have written a lot of TF code and feel more comfortable in our state of affairs. We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software.\r\n\r\n**Layout**\r\n\r\nWe have a complicated AWS infrastructure with multiple VPC's each with multiple subnets. Key to easily managing this was to define a flexible taxonomy that encompasses region, environment, service and owner which we can use to organise our infrastructure code (both terraform and puppet). \r\n\r\n**Modules**\r\n\r\nNext step was to create a single git repository to store our terraform modules. Our top level dir structure for the modules looks like this:\r\n\r\n```tree -L 1 .\r\n.\r\n\u251c\u2500\u2500 README.md\r\n\u251c\u2500\u2500 aws-asg\r\n\u251c\u2500\u2500 aws-ec2\r\n\u251c\u2500\u2500 aws-elb\r\n\u251c\u2500\u2500 aws-rds\r\n\u251c\u2500\u2500 aws-sg\r\n\u251c\u2500\u2500 aws-vpc\r\n\u2514\u2500\u2500 templates```\r\n\r\nEach one sets some sane defaults but exposes them as variables that can be overwritten by our \"glue\".\r\n\r\n**Glue**\r\n\r\nWe have a second repository with our `glue` that makes use of the modules mentioned above. It is laid out in line with our taxonomy document:\r\n\r\n```.\r\n\u251c\u2500\u2500 README.md\r\n\u251c\u2500\u2500 clientA\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dev\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 us-east-1\r\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 dev\r\n\u251c\u2500\u2500 clientB\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam.tf\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 terraform.tfstate\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate.backup\r\n\u2514\u2500\u2500 clientC\r\n    \u251c\u2500\u2500 eu-west-1\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 aws.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-roles.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 stg\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n    \u2514\u2500\u2500 iam.tf```\r\n\r\nInside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. \r\n\r\n*Side Note:* As you can see I'm going against my own advice above keeping `terraform.tfstate` in git. This is a temporary measure until I move to S3 but suits me as I'm currently the only developer.\r\n\r\n**Next Steps**\r\n\r\nThis is still a manual process and not in Jenkins yet but we're porting a rather large, complicated infrastructure and so far so good. Like I said, few bugs but going well! ", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). ", "keywords": ["change"]}, {"source": "Text", "text": "3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc). ", "keywords": ["change"]}, {"source": "Text", "text": "We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software. ", "keywords": ["change"]}, {"source": "Text", "text": "Inside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. ", "keywords": ["instance"]}]}, {"Id": "158537687", "PostHistoryTypeId": "5", "PostId": "33628841", "RevisionGUID": "890896d6-97b1-4a1a-b8b8-2874c16fb71b", "CreationDate": "2017-10-17T15:19:13.933", "UserId": "1401034", "Comment": "added 2052 characters in body", "Text": "I am also in a state of migrating existing AWS infrastructure to Terraform so shall aim to update the answer as I develop. \r\n\r\nI have been relying heavily on the official Terraform [examples](https://github.com/hashicorp/terraform/tree/master/examples) and multiple trial and error to flesh out areas that I have been uncertain in.\r\n\r\n**.tfstate files**\r\n\r\nTerraform config can be used to provision many boxes on different infrastructure, each of which could have a different state. As it can also be run by multiple people this state should be in a centralised location (like S3) but _not_ git. \r\n\r\nThis can be confirmed looking at the Terraform [`.gitignore`](https://github.com/hashicorp/terraform/blob/347f9c0bea68722a85a1e453c69e6a756043f6b8/.gitignore).\r\n\r\n**Developer control**\r\n\r\nOur aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). With that in mind the new infrastructure workflow I am aiming towards is:\r\n\r\n 1. Base foundation of common AMI's that include reusable modules e.g. puppet.\r\n 2. Core infrastructure provisioned by DevOps using Terraform.\r\n 3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc).\r\n 4. Git configuration pushed and a pull request submitted to be sanity checked by a member of DevOps squad.\r\n 5. If approved, calls webhook to CI to build and deploy (unsure how to partition multiple environments at this time)\r\n\r\n**Edit 1 - Update on current state**\r\n\r\nSince starting this answer I have written a lot of TF code and feel more comfortable in our state of affairs. We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software.\r\n\r\n**Layout**\r\n\r\nWe have a complicated AWS infrastructure with multiple VPC's each with multiple subnets. Key to easily managing this was to define a flexible taxonomy that encompasses region, environment, service and owner which we can use to organise our infrastructure code (both terraform and puppet). \r\n\r\n**Modules**\r\n\r\nNext step was to create a single git repository to store our terraform modules. Our top level dir structure for the modules looks like this:\r\n\r\n```tree -L 1 .\r\n.\r\n\u251c\u2500\u2500 README.md\r\n\u251c\u2500\u2500 aws-asg\r\n\u251c\u2500\u2500 aws-ec2\r\n\u251c\u2500\u2500 aws-elb\r\n\u251c\u2500\u2500 aws-rds\r\n\u251c\u2500\u2500 aws-sg\r\n\u251c\u2500\u2500 aws-vpc\r\n\u2514\u2500\u2500 templates```\r\n\r\nEach one sets some sane defaults but exposes them as variables that can be overwritten by our \"glue\".\r\n\r\n**Glue**\r\n\r\nWe have a second repository with our `glue` that makes use of the modules mentioned above. It is laid out in line with our taxonomy document:\r\n\r\n```.\r\n\u251c\u2500\u2500 README.md\r\n\u251c\u2500\u2500 clientA\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dev\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 us-east-1\r\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 dev\r\n\u251c\u2500\u2500 clientB\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam.tf\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 terraform.tfstate\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate.backup\r\n\u2514\u2500\u2500 clientC\r\n    \u251c\u2500\u2500 eu-west-1\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 aws.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-roles.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 stg\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n    \u2514\u2500\u2500 iam.tf```\r\n\r\nInside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. \r\n\r\n*Side Note:* As you can see I'm going against my own advice above keeping `terraform.tfstate` in git. This is a temporary measure until I move to S3 but suits me as I'm currently the only developer.\r\n\r\n**Next Steps**\r\n\r\nThis is still a manual process and not in Jenkins yet but we're porting a rather large, complicated infrastructure and so far so good. Like I said, few bugs but going well! \r\n\r\n**Edit 2 - Changes**\r\n\r\nIt's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. I am now at a new position using Terraform to manage an Azure cluster and Terraform is now `v0.10.7`.\r\n\r\n**State**\r\n\r\nPeople have repeatedly told me state should *not* go in Git - and they are correct. We used this as an interim measure with a two person team that relied on developer communication and discipline. With a larger, distributed team we are now fully leveraging remote state in S3 with [locking](https://www.terraform.io/docs/state/locking.html) provided by DynamoDB. Ideally this will be migrated to consul now it is v1.0 to cut cross cloud providers. \r\n\r\n**Modules**\r\n\r\nPreviously we created and used internal modules. This is still the case but with the advent and growth of the [Terraform registry](https://registry.terraform.io/) we try to use these as at least a base. \r\n\r\n**File structure**\r\n\r\nThe new position has a much simpler taxonomy with only two infx environments - `dev` and `prod`. Each has their own variables and outputs, reusing our modules created above. The [`remote_state`](https://www.terraform.io/docs/providers/terraform/d/remote_state.html) provider also helps in sharing outputs of created resources between environments. Our scenario is subdomains in different Azure resource groups to a globally managed TLD.\r\n\r\n```\r\n\u251c\u2500\u2500 main.tf\r\n\u251c\u2500\u2500 dev\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 main.tf\r\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 output.tf\r\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 variables.tf\r\n\u2514\u2500\u2500 prod\r\n    \u251c\u2500\u2500 main.tf\r\n    \u251c\u2500\u2500 output.tf\r\n    \u2514\u2500\u2500 variables.tf\r\n```\r\n\r\n**Planning**\r\n\r\nAgain with extra challenges of a distributed team, we now always save our output of the `terraform plan` command. We can inspect and know what will be run without the risk of some changes between the `plan` and `apply` stage (although locking helps with this). Remember to delete this plan file as it could potentially contain plain text \"secret\" variables. \r\n\r\nOverall we are very happy with Terraform and continue to learn and improve with the new features added.", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": [{"source": "Text", "text": "Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). ", "keywords": ["change"]}, {"source": "Text", "text": "3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc). ", "keywords": ["change"]}, {"source": "Text", "text": "We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software. ", "keywords": ["change"]}, {"source": "Text", "text": "Inside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. ", "keywords": ["instance"]}, {"source": "Text", "text": "**Edit 2 - Changes** ", "keywords": ["change"]}, {"source": "Text", "text": "It's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. ", "keywords": ["change"]}, {"source": "Text", "text": "I am now at a new position using Terraform to manage an Azure cluster and Terraform is now `v0.10.7`. ", "keywords": ["cluster"]}, {"source": "Text", "text": "The [`remote_state`](https://www.terraform.io/docs/providers/terraform/d/remote_state.html) provider also helps in sharing outputs of created resources between environments. ", "keywords": ["provider"]}, {"source": "Text", "text": "We can inspect and know what will be run without the risk of some changes between the `plan` and `apply` stage (although locking helps with this). ", "keywords": ["change"]}]}, {"Id": "192544010", "PostHistoryTypeId": "5", "PostId": "33628841", "RevisionGUID": "44f9f3e1-2939-49cc-9a18-fb3c321c4042", "CreationDate": "2019-02-27T14:29:49.257", "UserId": "1092815", "Comment": "syntax highlighting", "Text": "I am also in a state of migrating existing AWS infrastructure to Terraform so shall aim to update the answer as I develop. \r\n\r\nI have been relying heavily on the official Terraform [examples](https://github.com/hashicorp/terraform/tree/master/examples) and multiple trial and error to flesh out areas that I have been uncertain in.\r\n\r\n**`.tfstate` files**\r\n\r\nTerraform config can be used to provision many boxes on different infrastructure, each of which could have a different state. As it can also be run by multiple people this state should be in a centralised location (like S3) but _not_ git. \r\n\r\nThis can be confirmed looking at the Terraform [`.gitignore`](https://github.com/hashicorp/terraform/blob/347f9c0bea68722a85a1e453c69e6a756043f6b8/.gitignore).\r\n\r\n**Developer control**\r\n\r\nOur aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). With that in mind the new infrastructure workflow I am aiming towards is:\r\n\r\n 1. Base foundation of common AMI's that include reusable modules e.g. puppet.\r\n 2. Core infrastructure provisioned by DevOps using Terraform.\r\n 3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc).\r\n 4. Git configuration pushed and a pull request submitted to be sanity checked by a member of DevOps squad.\r\n 5. If approved, calls webhook to CI to build and deploy (unsure how to partition multiple environments at this time)\r\n\r\n**Edit 1 - Update on current state**\r\n\r\nSince starting this answer I have written a lot of TF code and feel more comfortable in our state of affairs. We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software.\r\n\r\n**Layout**\r\n\r\nWe have a complicated AWS infrastructure with multiple VPC's each with multiple subnets. Key to easily managing this was to define a flexible taxonomy that encompasses region, environment, service and owner which we can use to organise our infrastructure code (both terraform and puppet). \r\n\r\n**Modules**\r\n\r\nNext step was to create a single git repository to store our terraform modules. Our top level dir structure for the modules looks like this:\r\n\r\n<!-- language: lang-bash -->\r\n\r\n    tree -L 1 .\r\n\r\nResult:\r\n\r\n    \u251c\u2500\u2500 README.md\r\n    \u251c\u2500\u2500 aws-asg\r\n    \u251c\u2500\u2500 aws-ec2\r\n    \u251c\u2500\u2500 aws-elb\r\n    \u251c\u2500\u2500 aws-rds\r\n    \u251c\u2500\u2500 aws-sg\r\n    \u251c\u2500\u2500 aws-vpc\r\n    \u2514\u2500\u2500 templates\r\n\r\nEach one sets some sane defaults but exposes them as variables that can be overwritten by our \"glue\".\r\n\r\n**Glue**\r\n\r\nWe have a second repository with our `glue` that makes use of the modules mentioned above. It is laid out in line with our taxonomy document:\r\n\r\n    .\r\n    \u251c\u2500\u2500 README.md\r\n    \u251c\u2500\u2500 clientA\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dev\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 us-east-1\r\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 dev\r\n    \u251c\u2500\u2500 clientB\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 eu-west-1\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 iam.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 terraform.tfstate\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate.backup\r\n    \u2514\u2500\u2500 clientC\r\n        \u251c\u2500\u2500 eu-west-1\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 aws.tf\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-roles.tf\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-keys.tf\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 prod\r\n        \u2502\u00a0\u00a0 \u251c\u2500\u2500 stg\r\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 terraform.tfstate\r\n        \u2514\u2500\u2500 iam.tf\r\n\r\nInside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. \r\n\r\n*Side Note:* As you can see I'm going against my own advice above keeping `terraform.tfstate` in git. This is a temporary measure until I move to S3 but suits me as I'm currently the only developer.\r\n\r\n**Next Steps**\r\n\r\nThis is still a manual process and not in Jenkins yet but we're porting a rather large, complicated infrastructure and so far so good. Like I said, few bugs but going well! \r\n\r\n**Edit 2 - Changes**\r\n\r\nIt's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. I am now at a new position using Terraform to manage an Azure cluster and Terraform is now `v0.10.7`.\r\n\r\n**State**\r\n\r\nPeople have repeatedly told me state should *not* go in Git - and they are correct. We used this as an interim measure with a two person team that relied on developer communication and discipline. With a larger, distributed team we are now fully leveraging remote state in S3 with [locking](https://www.terraform.io/docs/state/locking.html) provided by DynamoDB. Ideally this will be migrated to consul now it is v1.0 to cut cross cloud providers. \r\n\r\n**Modules**\r\n\r\nPreviously we created and used internal modules. This is still the case but with the advent and growth of the [Terraform registry](https://registry.terraform.io/) we try to use these as at least a base. \r\n\r\n**File structure**\r\n\r\nThe new position has a much simpler taxonomy with only two infx environments - `dev` and `prod`. Each has their own variables and outputs, reusing our modules created above. The [`remote_state`](https://www.terraform.io/docs/providers/terraform/d/remote_state.html) provider also helps in sharing outputs of created resources between environments. Our scenario is subdomains in different Azure resource groups to a globally managed TLD.\r\n\r\n    \u251c\u2500\u2500 main.tf\r\n    \u251c\u2500\u2500 dev\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 main.tf\r\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 output.tf\r\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 variables.tf\r\n    \u2514\u2500\u2500 prod\r\n        \u251c\u2500\u2500 main.tf\r\n        \u251c\u2500\u2500 output.tf\r\n        \u2514\u2500\u2500 variables.tf\r\n\r\n**Planning**\r\n\r\nAgain with extra challenges of a distributed team, we now always save our output of the `terraform plan` command. We can inspect and know what will be run without the risk of some changes between the `plan` and `apply` stage (although locking helps with this). Remember to delete this plan file as it could potentially contain plain text \"secret\" variables. \r\n\r\nOverall we are very happy with Terraform and continue to learn and improve with the new features added.", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). ", "keywords": ["change"]}, {"source": "Text", "text": "3. Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc). ", "keywords": ["change"]}, {"source": "Text", "text": "We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software. ", "keywords": ["change"]}, {"source": "Text", "text": "\u251c\u2500\u2500 README.md \u251c\u2500\u2500 clientA \u2502 \u251c\u2500\u2500 eu-west-1 \u2502 \u2502 \u2514\u2500\u2500 dev \u2502 \u2514\u2500\u2500 us-east-1 \u2502 \u2514\u2500\u2500 dev \u251c\u2500\u2500 clientB \u2502 \u251c\u2500\u2500 eu-west-1 \u2502 \u2502 \u251c\u2500\u2500 dev \u2502 \u2502 \u251c\u2500\u2500 ec2-keys.tf \u2502 \u2502 \u251c\u2500\u2500 prod \u2502 \u2502 \u2514\u2500\u2500 terraform.tfstate \u2502 \u251c\u2500\u2500 iam.tf \u2502 \u251c\u2500\u2500 terraform.tfstate \u2502 \u2514\u2500\u2500 terraform.tfstate.backup \u2514\u2500\u2500 clientC \u251c\u2500\u2500 eu-west-1 \u2502 \u251c\u2500\u2500 aws.tf \u2502 \u251c\u2500\u2500 dev \u2502 \u251c\u2500\u2500 iam-roles.tf \u2502 \u251c\u2500\u2500 ec2-keys.tf \u2502 \u251c\u2500\u2500 prod \u2502 \u251c\u2500\u2500 stg \u2502 \u2514\u2500\u2500 terraform.tfstate \u2514\u2500\u2500 iam.tf Inside the client level we have AWS account specific `.tf` files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (`dev`, `stg`, `prod` etc) are our VPC setups, instance creation and peering connections etc. are stored. ", "keywords": ["instance"]}, {"source": "Text", "text": "**Edit 2 - Changes** ", "keywords": ["change"]}, {"source": "Text", "text": "It's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. ", "keywords": ["change"]}, {"source": "Text", "text": "I am now at a new position using Terraform to manage an Azure cluster and Terraform is now `v0.10.7`. ", "keywords": ["cluster"]}, {"source": "Text", "text": "The [`remote_state`](https://www.terraform.io/docs/providers/terraform/d/remote_state.html) provider also helps in sharing outputs of created resources between environments. ", "keywords": ["provider"]}, {"source": "Text", "text": "We can inspect and know what will be run without the risk of some changes between the `plan` and `apply` stage (although locking helps with this). ", "keywords": ["change"]}]}], "filtered-sentences": [{"source": "Body", "text": "Our aim is to provide more control of the infrastructure to developers whilst maintaining a full audit (git log) and the ability to sanity check changes (pull requests). ", "keywords": ["change"]}, {"source": "Body", "text": "Developers change Terraform configuration in Git as needed (number of instances; new VPC; addition of region/availability zone etc). ", "keywords": ["change"]}, {"source": "Body", "text": "We have hit bugs and restrictions along the way but I accept this is a characteristic of using new, rapidly changing software. ", "keywords": ["change"]}, {"source": "Body", "text": "It is laid out in line with our taxonomy document: Inside the client level we have AWS account specific .tf files that provision global resources (like IAM roles); next is region level with EC2 SSH public keys; Finally in our environment (dev, stg, prod etc) are our VPC setups, instance creation and peering connections etc. are stored. ", "keywords": ["instance"]}, {"source": "Body", "text": "Edit 2 - Changes ", "keywords": ["change"]}, {"source": "Body", "text": "It's been almost a year since I wrote this initial answer and the state of both Terraform and myself have changed significantly. ", "keywords": ["change"]}, {"source": "Body", "text": "I am now at a new position using Terraform to manage an Azure cluster and Terraform is now v0.10.7. ", "keywords": ["cluster"]}, {"source": "Body", "text": "The remote_state provider also helps in sharing outputs of created resources between environments. ", "keywords": ["provider"]}, {"source": "Body", "text": "We can inspect and know what will be run without the risk of some changes between the plan and apply stage (although locking helps with this). ", "keywords": ["change"]}]}, {"Id": "52938377", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2018-10-22T22:03:52.860", "Score": "-1", "Body": "<p>If you are still looking for the better solution, take a look at workspaces which can replace maintaining different environment folder structure can have workspace specific variables.</p>\n\n<p>As <a href=\"https://stackoverflow.com/users/483528/yevgeniy-brikman\">Yevgeniy Brikman</a> <a href=\"https://stackoverflow.com/a/38749508/359532\">mentioned</a> it's better to have a modules structure.</p>\n", "OwnerUserId": "10443947", "LastEditorUserId": "958373", "LastEditDate": "2018-12-29T12:36:30.850", "LastActivityDate": "2018-12-29T12:36:30.850", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "184301488", "PostHistoryTypeId": "2", "PostId": "52938377", "RevisionGUID": "0547f865-9ffd-436e-a1cf-c14e6ce8e2e2", "CreationDate": "2018-10-22T22:03:52.860", "UserId": "10443947", "Text": "If you are still looking for the better solution, take a look at workspaces which can replace maintaining different environment folder structure can have workspace specific variables.\r\n\r\n\r\nas @Yevgeniy Brikman mentioned its better to have a modules structure.", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "185086211", "PostHistoryTypeId": "5", "PostId": "52938377", "RevisionGUID": "3e8eb46c-b939-4542-a603-89b7ba2a257f", "CreationDate": "2018-11-03T05:01:50.723", "UserId": "359532", "Comment": "Added links to the references", "Text": "If you are still looking for the better solution, take a look at workspaces which can replace maintaining different environment folder structure can have workspace specific variables.\r\n\r\n\r\nas [Yevgeniy Brikman][1] [mentioned][2] its better to have a modules structure.\r\n\r\n\r\n  [1]: https://stackoverflow.com/users/483528/yevgeniy-brikman\r\n  [2]: https://stackoverflow.com/a/38749508/359532", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "185086212", "PostHistoryTypeId": "24", "PostId": "52938377", "RevisionGUID": "3e8eb46c-b939-4542-a603-89b7ba2a257f", "CreationDate": "2018-11-03T05:01:50.723", "Comment": "Proposed by 359532 approved by 1277259, 7584231 edit id of 3991533", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "188633515", "PostHistoryTypeId": "5", "PostId": "52938377", "RevisionGUID": "f0c60046-ff77-4b9f-a57b-966c3e80d0cc", "CreationDate": "2018-12-29T12:36:30.850", "UserId": "958373", "Comment": "added 1 character in body", "Text": "If you are still looking for the better solution, take a look at workspaces which can replace maintaining different environment folder structure can have workspace specific variables.\r\n\r\n\r\nAs [Yevgeniy Brikman][1] [mentioned][2] it's better to have a modules structure.\r\n\r\n\r\n  [1]: https://stackoverflow.com/users/483528/yevgeniy-brikman\r\n  [2]: https://stackoverflow.com/a/38749508/359532", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}, {"Id": "59734057", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2020-01-14T12:45:01.807", "Score": "0", "Body": "<p>Some Terraform Best Practices to Follow:</p>\n\n<ol>\n<li><p>Avoid hard coding:\nSometimes developers manually created resources directly. You need to mark these resource and use terraform import to include them in codes.\nA sample:</p>\n\n<p>account_number=\u201c123456789012\"\naccount_alias=\"mycompany\"</p></li>\n<li><p>Run Terraform from a docker container:\nTerraform releases an official Docker container that allows you to easily control which version you can run.</p></li>\n</ol>\n\n<p>It is recommended to run the Terraform Docker container when you set your build job in the CI/CD pipeline.</p>\n\n<pre><code>TERRAFORM_IMAGE=hashicorp/terraform:0.11.7\nTERRAFORM_CMD=\"docker run -ti --rm -w /app -v ${HOME}/.aws:/root/.aws -v ${HOME}/.ssh:/root/.ssh -v `pwd`:/app $TERRAFORM_IMAGE\"\n</code></pre>\n\n<p>For more, please refer to my blog: <a href=\"https://medium.com/tech-darwinbox/how-darwinbox-manages-infrastructure-at-scale-with-terraform-371e2c5f04d3\" rel=\"nofollow noreferrer\">https://medium.com/tech-darwinbox/how-darwinbox-manages-infrastructure-at-scale-with-terraform-371e2c5f04d3</a></p>\n", "OwnerUserId": "12710911", "LastActivityDate": "2020-01-14T12:45:01.807", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "212920791", "PostHistoryTypeId": "2", "PostId": "59734057", "RevisionGUID": "87a9a1f3-b296-403d-b7a3-a66a5e3495c2", "CreationDate": "2020-01-14T12:45:01.807", "UserId": "12710911", "Text": "Some Terraform Best Practices to Follow:\r\n\r\n1. Avoid hard coding:\r\nSometimes developers manually created resources directly. You need to mark these resource and use terraform import to include them in codes.\r\nA sample:\r\n\r\n    account_number=\u201c123456789012\"\r\n    account_alias=\"mycompany\"\r\n\r\n2. Run Terraform from a docker container:\r\nTerraform releases an official Docker container that allows you to easily control which version you can run.\r\n\r\nIt is recommended to run the Terraform Docker container when you set your build job in the CI/CD pipeline.\r\n\r\n    TERRAFORM_IMAGE=hashicorp/terraform:0.11.7\r\n    TERRAFORM_CMD=\"docker run -ti --rm -w /app -v ${HOME}/.aws:/root/.aws -v ${HOME}/.ssh:/root/.ssh -v `pwd`:/app $TERRAFORM_IMAGE\"\r\n\r\nFor more, please refer to my blog: [https://medium.com/tech-darwinbox/how-darwinbox-manages-infrastructure-at-scale-with-terraform-371e2c5f04d3][1]\r\n\r\n\r\n  [1]: https://medium.com/tech-darwinbox/how-darwinbox-manages-infrastructure-at-scale-with-terraform-371e2c5f04d3", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}, {"Id": "52458277", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2018-09-22T15:45:52.877", "Score": "3", "Body": "<p>I know there\u2019s a lot of answers here but my approach is quite different. </p>\n\n<pre><code>\u2043   Modules\n\u2043   Environment management \n\u2043   Separation of duties\n</code></pre>\n\n<p><strong>Modules</strong></p>\n\n<ol>\n<li>Create modules for logical collections of resources. \nExample: If your goal is to deploy an API, which requires a DB, HA VMs, autoscaling, DNS, PubSub and object storage then all of these resources should be templated in a single module. </li>\n<li>Avoid creating modules that utilise a single resource. This can and has been done and a lot of the modules in the registry do this but it\u2019s a practice that helps with resource accessibility rather than infrastructure orchestration. \nExample: A module for AWS EC2 helps the user access the EC2 by making complex configurations more simple to invoke but a module like the example in 1. assists the user when orchestrating application, component or service driven infrastructure. \n\n<ol start=\"3\">\n<li>Avoid resource declarations in your workspace. This is more about keeping your code tidy and organised. As modules are easily versioned, you have more control over your releases. </li>\n</ol></li>\n</ol>\n\n<p><strong>Environment management</strong></p>\n\n<p>IaC has made SDLC process relevant to infrastructure management and it\u2019s not normal to expect to have development infrastructure as well as development application environments. </p>\n\n<ol>\n<li>Don\u2019t use folders to manage your IaC environments. This leads to drift as there\u2019s no common template for your infrastructure. </li>\n<li>Do use a single workspace and variables to control environment specifications. \nExample: Write your modules so that when you change the environment variable (var.stage is popular) the plan alters to fit your requirements. Typically the environments should vary as little as possible with quantity, exposure and capacity usually being the variable configurations. Dev might deploy 1 VM with 1 core and 1GB RAM in private topology but production may be 3 VMs with 2 cores and 4GB RAM with additional public topology. You can of course have more variation: dev may run database process on the same server as the application to save cost but production may have a dedicated DB instance. All of this can be managed by changing a single variable, ternary statements and interpolation. </li>\n</ol>\n\n<p><strong>Separation of duties</strong></p>\n\n<p>If you\u2019re in a small organisation or running personal infrastructure this doesn\u2019t really apply but it will help you manage your operations. </p>\n\n<ol>\n<li>Break down your infrastructure by duties, responsibilities or teams. \nExample: Central IT control underlying shared services (virtual networks, subnets, public IP addresses, log groups, governance resources, multi tenanted DBs, shared keys, etc.) whilst the API team only control the resources needed for their service (VMs, LBs, PubSub etc) and consume Central ITs services through data source and remote state lookups. \n\n<ol start=\"2\">\n<li>Govern team access. \nExample: Central IT may have admin rights but the API team only have access to a restricted set of public cloud APIs. </li>\n</ol></li>\n</ol>\n\n<p>This also helps with release concerns as you will find some resources rarely change whilst others change all the time. Separation removes risk and complexity. </p>\n\n<p>This strategy draws parallels with AWS\u2019 multi account strategy. Have a read for more info.</p>\n\n<p><strong>CI/CD</strong></p>\n\n<p>This is a topic of its own but Terraform works very well within a good pipeline. The most common error here is to treat CI as a silver bullet. Technically Terraform should only be provisioning infrastructure during stages of an assembly pipeline. This would be separate to what happens in CI stages where one typically validates and tests the templates. </p>\n\n<p>N.B. Written on mobile so please excuse any errors. </p>\n", "OwnerUserId": "6229946", "LastActivityDate": "2018-09-22T15:45:52.877", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "182304243", "PostHistoryTypeId": "2", "PostId": "52458277", "RevisionGUID": "d89aa612-bb96-4bd1-ac4f-231ccd607633", "CreationDate": "2018-09-22T15:45:52.877", "UserId": "6229946", "Text": "I know there\u2019s a lot of answers here but my approach is quite different. \n\n \u2043 Modules\n \u2043 Environment management \n \u2043 Separation of duties\n\n**Modules**\n\n 1. Create modules for logical collections of resources. \nExample: If your goal is to deploy an API, which requires a DB, HA VMs, autoscaling, DNS, PubSub and object storage then all of these resources should be templated in a single module. \n 2. Avoid creating modules that utilise a single resource. This can and has been done and a lot of the modules in the registry do this but it\u2019s a practice that helps with resource accessibility rather than infrastructure orchestration. \nExample: A module for AWS EC2 helps the user access the EC2 by making complex configurations more simple to invoke but a module like the example in 1. assists the user when orchestrating application, component or service driven infrastructure. \n3. Avoid resource declarations in your workspace. This is more about keeping your code tidy and organised. As modules are easily versioned, you have more control over your releases. \n\n**Environment management**\n\nIaC has made SDLC process relevant to infrastructure management and it\u2019s not normal to expect to have development infrastructure as well as development application environments. \n\n1. Don\u2019t use folders to manage your IaC environments. This leads to drift as there\u2019s no common template for your infrastructure. \n2. Do use a single workspace and variables to control environment specifications. \nExample: Write your modules so that when you change the environment variable (var.stage is popular) the plan alters to fit your requirements. Typically the environments should vary as little as possible with quantity, exposure and capacity usually being the variable configurations. Dev might deploy 1 VM with 1 core and 1GB RAM in private topology but production may be 3 VMs with 2 cores and 4GB RAM with additional public topology. You can of course have more variation: dev may run database process on the same server as the application to save cost but production may have a dedicated DB instance. All of this can be managed by changing a single variable, ternary statements and interpolation. \n\n**Separation of duties**\n\nIf you\u2019re in a small organisation or running personal infrastructure this doesn\u2019t really apply but it will help you manage your operations. \n\n 1. Break down your infrastructure by duties, responsibilities or teams. \nExample: Central IT control underlying shared services (virtual networks, subnets, public IP addresses, log groups, governance resources, multi tenanted DBs, shared keys, etc.) whilst the API team only control the resources needed for their service (VMs, LBs, PubSub etc) and consume Central ITs services through data source and remote state lookups. \n 2. Govern team access. \nExample: Central IT may have admin rights but the API team only have access to a restricted set of public cloud APIs. \n\nThis also helps with release concerns as you will find some resources rarely change whilst others change all the time. Separation removes risk and complexity. \n\nThis strategy draws parallels with AWS\u2019 multi account strategy. Have a read for more info.\n\n**CI/CD**\n\nThis is a topic of its own but Terraform works very well within a good pipeline. The most common error here is to treat CI as a silver bullet. Technically Terraform should only be provisioning infrastructure during stages of an assembly pipeline. This would be separate to what happens in CI stages where one typically validates and tests the templates. \n\n\nN.B. Written on mobile so please excuse any errors. ", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Example: If your goal is to deploy an API, which requires a DB, HA VMs, autoscaling, DNS, PubSub and object storage then all of these resources should be templated in a single module. ", "keywords": ["storage"]}, {"source": "Text", "text": "Example: Write your modules so that when you change the environment variable (var.stage is popular) the plan alters to fit your requirements. ", "keywords": ["change"]}, {"source": "Text", "text": "Dev might deploy 1 VM with 1 core and 1GB RAM in private topology but production may be 3 VMs with 2 cores and 4GB RAM with additional public topology. ", "keywords": ["ram"]}, {"source": "Text", "text": "You can of course have more variation: dev may run database process on the same server as the application to save cost but production may have a dedicated DB instance. ", "keywords": ["cost", "instance"]}, {"source": "Text", "text": "All of this can be managed by changing a single variable, ternary statements and interpolation. ", "keywords": ["change"]}, {"source": "Text", "text": "This also helps with release concerns as you will find some resources rarely change whilst others change all the time. ", "keywords": ["change"]}, {"source": "Text", "text": "This would be separate to what happens in CI stages where one typically validates and tests the templates. ", "keywords": ["test"]}]}], "filtered-sentences": [{"source": "Body", "text": "Example: If your goal is to deploy an API, which requires a DB, HA VMs, autoscaling, DNS, PubSub and object storage then all of these resources should be templated in a single module. ", "keywords": ["storage"]}, {"source": "Body", "text": "Example: Write your modules so that when you change the environment variable (var.stage is popular) the plan alters to fit your requirements. ", "keywords": ["change"]}, {"source": "Body", "text": "Dev might deploy 1 VM with 1 core and 1GB RAM in private topology but production may be 3 VMs with 2 cores and 4GB RAM with additional public topology. ", "keywords": ["ram"]}, {"source": "Body", "text": "You can of course have more variation: dev may run database process on the same server as the application to save cost but production may have a dedicated DB instance. ", "keywords": ["cost", "instance"]}, {"source": "Body", "text": "All of this can be managed by changing a single variable, ternary statements and interpolation. ", "keywords": ["change"]}, {"source": "Body", "text": "This also helps with release concerns as you will find some resources rarely change whilst others change all the time. ", "keywords": ["change"]}, {"source": "Body", "text": "This would be separate to what happens in CI stages where one typically validates and tests the templates. ", "keywords": ["test"]}]}, {"Id": "57886642", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2019-09-11T09:58:23.697", "Score": "0", "Body": "<p>I believe there are few best practices need to follow while using terraform for orchestrating the infrastructure</p>\n\n<blockquote>\n  <ol>\n  <li>Don't write the same code again ( Reusability)</li>\n  <li>Keep environment configuration separate to maintain it easily.</li>\n  <li>Use remote backend s3(encrypted) and dynamo DB to handle the concurrency locking</li>\n  <li>Create a module and use that module in main infrastructure multiple time, its like a reusable function which can be called multiple time by passing different parameter.</li>\n  </ol>\n</blockquote>\n\n<p><strong>Handle multiple environments</strong></p>\n\n<p>Most of the time recommended way is to use terraform 'workspace' to handle the multiple environments but I believe the usage of workspace could vary based on way of work in an organization.\nOther is storing the Terraform code for each of your environments (e.g. stage, prod, QA) to separate the environment states. However, in this case we are just copying the same code at many places.</p>\n\n<pre><code>\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 dev\n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 output.tf\n\u2502   \u2514\u2500\u2500 variables.tf\n\u2514\u2500\u2500 prod\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 output.tf\n\u2514\u2500\u2500 variables.tf\n</code></pre>\n\n<p>I followed some different approach to handle and avoid the duplication of the same terraform code by keeping in each environment folder since I believe most of the time all environment would be 90% same.</p>\n\n<pre><code>\u251c\u2500\u2500 deployment\n\u2502 \u251c\u2500\u2500 01-network.tf\n\u2502 \u251c\u2500\u2500 02-ecs_cluster.tf\n\u2502 \u251c\u2500\u2500 03-ecs_service.tf\n\u2502 \u251c\u2500\u2500 04-eks_infra.tf\n\u2502 \u251c\u2500\u2500 05-db_infra.tf\n\u2502 \u251c\u2500\u2500 06-codebuild-k8s.tf\n\u2502 \u251c\u2500\u2500 07-aws-secret.tf\n\u2502 \u251c\u2500\u2500 backend.tf\n\u2502 \u251c\u2500\u2500 provider.tf\n\u2502 \u2514\u2500\u2500 variables.tf\n\u251c\u2500\u2500 env\n\u2502 \u251c\u2500\u2500 dev\n\u2502 \u2502 \u251c\u2500\u2500 dev.backend.tfvar\n\u2502 \u2502 \u2514\u2500\u2500 dev.variables.tfvar\n\u2502 \u2514\u2500\u2500 prod\n\u2502 \u251c\u2500\u2500 prod.backend.tfvar\n\u2502 \u2514\u2500\u2500 prod.variables.tfvar\n\u251c\u2500\u2500 modules\n\u2502 \u2514\u2500\u2500 aws\n\u2502 \u251c\u2500\u2500 compute\n\u2502 \u2502 \u251c\u2500\u2500 alb_loadbalancer\n\u2502 \u2502 \u251c\u2500\u2500 alb_target_grp\n\u2502 \u2502 \u251c\u2500\u2500 ecs_cluster\n\u2502 \u2502 \u251c\u2500\u2500 ecs_service\n\u2502 \u2502 \u2514\u2500\u2500 launch_configuration\n\u2502 \u251c\u2500\u2500 database\n\u2502 \u2502 \u251c\u2500\u2500 db_main\n\u2502 \u2502 \u251c\u2500\u2500 db_option_group\n\u2502 \u2502 \u251c\u2500\u2500 db_parameter_group\n\u2502 \u2502 \u2514\u2500\u2500 db_subnet_group\n\u2502 \u251c\u2500\u2500 developertools\n\u2502 \u251c\u2500\u2500 network\n\u2502 \u2502 \u251c\u2500\u2500 internet_gateway\n\u2502 \u2502 \u251c\u2500\u2500 nat_gateway\n\u2502 \u2502 \u251c\u2500\u2500 route_table\n\u2502 \u2502 \u251c\u2500\u2500 security_group\n\u2502 \u2502 \u251c\u2500\u2500 subnet\n\u2502 \u2502 \u251c\u2500\u2500 vpc\n\u2502 \u2514\u2500\u2500 security\n\u2502 \u251c\u2500\u2500 iam_role\n\u2502 \u2514\u2500\u2500 secret-manager\n\u2514\u2500\u2500 templates\n</code></pre>\n\n<p><strong>Configuration related to environments</strong></p>\n\n<p>Keep environment related configuration and parameters separate in a variable file and pass that value to configure the infrastructure. e.g as below</p>\n\n<ul>\n<li><p>dev.backend.tfvar</p>\n\n<pre><code>  region = \"ap-southeast-2\"\n  bucket = \"dev-samplebackendterraform\"\n  key = \"dev/state.tfstate\"\n  dynamo_db_lock = \"dev-terraform-state-lock\"\n</code></pre></li>\n<li><p>dev.variable.tfvar</p>\n\n<pre><code>environment                     =   \"dev\"\nvpc_name                        =   \"demo\"\nvpc_cidr_block                  =   \"10.20.0.0/19\"\nprivate_subnet_1a_cidr_block    =   \"10.20.0.0/21\"\nprivate_subnet_1b_cidr_block    =   \"10.20.8.0/21\"\npublic_subnet_1a_cidr_block     =   \"10.20.16.0/21\"\npublic_subnet_1b_cidr_block     =   \"10.20.24.0/21\"\n</code></pre></li>\n</ul>\n\n<p><strong>Conditional skipping of infrastructure part</strong></p>\n\n<p>Create a configuration in env specific variable file and based on that variable decide to create or skipping that part. In this way based on need the specific part of the infrastructure can be skipped.</p>\n\n<pre><code>variable vpc_create {\n   default = \"true\"\n}\n\nmodule \"vpc\" {\n  source = \"../modules/aws/network/vpc\"\n  enable = \"${var.vpc_create}\"\n  vpc_cidr_block = \"${var.vpc_cidr_block}\"\n  name = \"${var.vpc_name}\"\n }\n\n resource \"aws_vpc\" \"vpc\" {\n    count                = \"${var.enable == \"true\" ? 1 : 0}\"\n    cidr_block           = \"${var.vpc_cidr_block}\"\n    enable_dns_support   = \"true\"\n   enable_dns_hostnames = \"true\"\n}\n</code></pre>\n\n<p>below command is required to initialize and execute the infra changes for each environment, cd to the required environment folder.</p>\n\n<pre><code>  terraform init -var-file=dev.variables.tfvar -backend-config=dev.backend.tfvar ../../deployment/\n\n  terraform apply -var-file=dev.variables.tfvar ../../deployment\n</code></pre>\n\n<blockquote>\n  <p>For reference: <a href=\"https://github.com/mattyait/devops_terraform\" rel=\"nofollow noreferrer\">https://github.com/mattyait/devops_terraform</a></p>\n</blockquote>\n", "OwnerUserId": "3057843", "LastActivityDate": "2019-09-11T09:58:23.697", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "205143721", "PostHistoryTypeId": "2", "PostId": "57886642", "RevisionGUID": "d4930bf9-9bb2-49ac-9fcd-0cfc0b4a97ea", "CreationDate": "2019-09-11T09:58:23.697", "UserId": "3057843", "Text": "I believe there are few best practices need to follow while using terraform for orchestrating the infrastructure\r\n\r\n> 1. Don't write the same code again ( Reusability)\r\n2. Keep environment configuration separate to maintain it easily.\r\n3. Use remote backend s3(encrypted) and dynamo DB to handle the concurrency locking\r\n4. Create a module and use that module in main infrastructure multiple time, its like a reusable function which can be called multiple time by passing different parameter.\r\n\r\n**Handle multiple environments**\r\n\r\nMost of the time recommended way is to use terraform 'workspace' to handle the multiple environments but I believe the usage of workspace could vary based on way of work in an organization.\r\nOther is storing the Terraform code for each of your environments (e.g. stage, prod, QA) to separate the environment states. However, in this case we are just copying the same code at many places.\r\n\r\n    \u251c\u2500\u2500 main.tf\r\n    \u251c\u2500\u2500 dev\r\n    \u2502   \u251c\u2500\u2500 main.tf\r\n    \u2502   \u251c\u2500\u2500 output.tf\r\n    \u2502   \u2514\u2500\u2500 variables.tf\r\n    \u2514\u2500\u2500 prod\r\n    \u251c\u2500\u2500 main.tf\r\n    \u251c\u2500\u2500 output.tf\r\n    \u2514\u2500\u2500 variables.tf\r\n\r\nI followed some different approach to handle and avoid the duplication of the same terraform code by keeping in each environment folder since I believe most of the time all environment would be 90% same.\r\n\r\n    \u251c\u2500\u2500 deployment\r\n    \u2502 \u251c\u2500\u2500 01-network.tf\r\n    \u2502 \u251c\u2500\u2500 02-ecs_cluster.tf\r\n    \u2502 \u251c\u2500\u2500 03-ecs_service.tf\r\n    \u2502 \u251c\u2500\u2500 04-eks_infra.tf\r\n    \u2502 \u251c\u2500\u2500 05-db_infra.tf\r\n    \u2502 \u251c\u2500\u2500 06-codebuild-k8s.tf\r\n    \u2502 \u251c\u2500\u2500 07-aws-secret.tf\r\n    \u2502 \u251c\u2500\u2500 backend.tf\r\n    \u2502 \u251c\u2500\u2500 provider.tf\r\n    \u2502 \u2514\u2500\u2500 variables.tf\r\n    \u251c\u2500\u2500 env\r\n    \u2502 \u251c\u2500\u2500 dev\r\n    \u2502 \u2502 \u251c\u2500\u2500 dev.backend.tfvar\r\n    \u2502 \u2502 \u2514\u2500\u2500 dev.variables.tfvar\r\n    \u2502 \u2514\u2500\u2500 prod\r\n    \u2502 \u251c\u2500\u2500 prod.backend.tfvar\r\n    \u2502 \u2514\u2500\u2500 prod.variables.tfvar\r\n    \u251c\u2500\u2500 modules\r\n    \u2502 \u2514\u2500\u2500 aws\r\n    \u2502 \u251c\u2500\u2500 compute\r\n    \u2502 \u2502 \u251c\u2500\u2500 alb_loadbalancer\r\n    \u2502 \u2502 \u251c\u2500\u2500 alb_target_grp\r\n    \u2502 \u2502 \u251c\u2500\u2500 ecs_cluster\r\n    \u2502 \u2502 \u251c\u2500\u2500 ecs_service\r\n    \u2502 \u2502 \u2514\u2500\u2500 launch_configuration\r\n    \u2502 \u251c\u2500\u2500 database\r\n    \u2502 \u2502 \u251c\u2500\u2500 db_main\r\n    \u2502 \u2502 \u251c\u2500\u2500 db_option_group\r\n    \u2502 \u2502 \u251c\u2500\u2500 db_parameter_group\r\n    \u2502 \u2502 \u2514\u2500\u2500 db_subnet_group\r\n    \u2502 \u251c\u2500\u2500 developertools\r\n    \u2502 \u251c\u2500\u2500 network\r\n    \u2502 \u2502 \u251c\u2500\u2500 internet_gateway\r\n    \u2502 \u2502 \u251c\u2500\u2500 nat_gateway\r\n    \u2502 \u2502 \u251c\u2500\u2500 route_table\r\n    \u2502 \u2502 \u251c\u2500\u2500 security_group\r\n    \u2502 \u2502 \u251c\u2500\u2500 subnet\r\n    \u2502 \u2502 \u251c\u2500\u2500 vpc\r\n    \u2502 \u2514\u2500\u2500 security\r\n    \u2502 \u251c\u2500\u2500 iam_role\r\n    \u2502 \u2514\u2500\u2500 secret-manager\r\n    \u2514\u2500\u2500 templates\r\n\r\n**Configuration related to environments**\r\n\r\nKeep environment related configuration and parameters separate in a variable file and pass that value to configure the infrastructure. e.g as below\r\n\r\n - dev.backend.tfvar\r\n\r\n          region = \"ap-southeast-2\"\r\n          bucket = \"dev-samplebackendterraform\"\r\n          key = \"dev/state.tfstate\"\r\n          dynamo_db_lock = \"dev-terraform-state-lock\"\r\n\r\n - dev.variable.tfvar\r\n\r\n        environment                     =   \"dev\"\r\n        vpc_name                        =   \"demo\"\r\n        vpc_cidr_block                  =   \"10.20.0.0/19\"\r\n        private_subnet_1a_cidr_block    =   \"10.20.0.0/21\"\r\n        private_subnet_1b_cidr_block    =   \"10.20.8.0/21\"\r\n        public_subnet_1a_cidr_block     =   \"10.20.16.0/21\"\r\n        public_subnet_1b_cidr_block     =   \"10.20.24.0/21\"\r\n\r\n\r\n\r\n**Conditional skipping of infrastructure part**\r\n\r\nCreate a configuration in env specific variable file and based on that variable decide to create or skipping that part. In this way based on need the specific part of the infrastructure can be skipped.\r\n\r\n    variable vpc_create {\r\n       default = \"true\"\r\n    }\r\n\r\n    module \"vpc\" {\r\n      source = \"../modules/aws/network/vpc\"\r\n      enable = \"${var.vpc_create}\"\r\n      vpc_cidr_block = \"${var.vpc_cidr_block}\"\r\n      name = \"${var.vpc_name}\"\r\n     }\r\n\r\n     resource \"aws_vpc\" \"vpc\" {\r\n        count                = \"${var.enable == \"true\" ? 1 : 0}\"\r\n        cidr_block           = \"${var.vpc_cidr_block}\"\r\n        enable_dns_support   = \"true\"\r\n       enable_dns_hostnames = \"true\"\r\n    }\r\n\r\nbelow command is required to initialize and execute the infra changes for each environment, cd to the required environment folder.\r\n\r\n      terraform init -var-file=dev.variables.tfvar -backend-config=dev.backend.tfvar ../../deployment/\r\n\r\n      terraform apply -var-file=dev.variables.tfvar ../../deployment\r\n\r\n> For reference: https://github.com/mattyait/devops_terraform\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "\u251c\u2500\u2500 deployment \u2502 \u251c\u2500\u2500 01-network.tf \u2502 \u251c\u2500\u2500 02-ecs_cluster.tf \u2502 \u251c\u2500\u2500 03-ecs_service.tf \u2502 \u251c\u2500\u2500 04-eks_infra.tf \u2502 \u251c\u2500\u2500 05-db_infra.tf \u2502 \u251c\u2500\u2500 06-codebuild-k8s.tf \u2502 \u251c\u2500\u2500 07-aws-secret.tf \u2502 \u251c\u2500\u2500 backend.tf \u2502 \u251c\u2500\u2500 provider.tf \u2502 \u2514\u2500\u2500 variables.tf \u251c\u2500\u2500 env \u2502 \u251c\u2500\u2500 dev \u2502 \u2502 \u251c\u2500\u2500 dev.backend.tfvar \u2502 \u2502 \u2514\u2500\u2500 dev.variables.tfvar \u2502 \u2514\u2500\u2500 prod \u2502 \u251c\u2500\u2500 prod.backend.tfvar \u2502 \u2514\u2500\u2500 prod.variables.tfvar \u251c\u2500\u2500 modules \u2502 \u2514\u2500\u2500 aws \u2502 \u251c\u2500\u2500 compute \u2502 \u2502 \u251c\u2500\u2500 alb_loadbalancer \u2502 \u2502 \u251c\u2500\u2500 alb_target_grp \u2502 \u2502 \u251c\u2500\u2500 ecs_cluster \u2502 \u2502 \u251c\u2500\u2500 ecs_service \u2502 \u2502 \u2514\u2500\u2500 launch_configuration \u2502 \u251c\u2500\u2500 database \u2502 \u2502 \u251c\u2500\u2500 db_main \u2502 \u2502 \u251c\u2500\u2500 db_option_group \u2502 \u2502 \u251c\u2500\u2500 db_parameter_group \u2502 \u2502 \u2514\u2500\u2500 db_subnet_group \u2502 \u251c\u2500\u2500 developertools \u2502 \u251c\u2500\u2500 network \u2502 \u2502 \u251c\u2500\u2500 internet_gateway \u2502 \u2502 \u251c\u2500\u2500 nat_gateway \u2502 \u2502 \u251c\u2500\u2500 route_table \u2502 \u2502 \u251c\u2500\u2500 security_group \u2502 \u2502 \u251c\u2500\u2500 subnet \u2502 \u2502 \u251c\u2500\u2500 vpc \u2502 \u2514\u2500\u2500 security \u2502 \u251c\u2500\u2500 iam_role \u2502 \u2514\u2500\u2500 secret-manager \u2514\u2500\u2500 templates **Configuration related to environments** Keep environment related configuration and parameters separate in a variable file and pass that value to configure the infrastructure. ", "keywords": ["provider"]}, {"source": "Text", "text": "} below command is required to initialize and execute the infra changes for each environment, cd to the required environment folder. terraform init -var-file=dev.variables.tfvar -backend-config=dev.backend.tfvar ../../deployment/ terraform apply -var-file=dev.variables.tfvar ../", "keywords": ["change"]}]}], "filtered-sentences": [{"source": "Body", "text": "below command is required to initialize and execute the infra changes for each environment, cd to the required environment folder. ", "keywords": ["change"]}]}, {"Id": "58993664", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2019-11-22T11:48:28.507", "Score": "0", "Body": "<p>I don't like the idea of subfolders because this will result in different sources per environment and this tends to drift. </p>\n\n<p>The better approach is to have a single stack for all environments (lets say dev, preprod and prod). To work on a single environment use <code>terraform workspace</code>. </p>\n\n<pre><code>terraform workspace new dev\n</code></pre>\n\n<p>This creates a new workspace. This includs a dedicated state file and the variable <code>terraform.workspace</code> you can use in your code. </p>\n\n<pre><code>resource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"my-tf-test-bucket-${terraform.workspace}\"\n}\n</code></pre>\n\n<p>In this way you will get buckets called</p>\n\n<ul>\n<li>my-tf-test-bucket-dev</li>\n<li>my-tf-test-bucket-preprod</li>\n<li>my-tf-test-bucket-prod</li>\n</ul>\n\n<p>after applying to the workspaces above (use <code>terraform workspace select &lt;WORKSPACE&gt;</code> to change environments). \nTo make the code even multi-region-proof do it like this:</p>\n\n<pre><code>data \"aws_region\" \"current\" {}\n\nresource \"aws_s3_bucket\" \"bucket\" {\n  bucket = \"my-tf-test-bucket-${data.aws_region.current.name}-${terraform.workspace}\"\n}\n</code></pre>\n\n<p>to get (for us-east-1 region)</p>\n\n<ul>\n<li>my-tf-test-bucket-us-east-1-dev</li>\n<li>my-tf-test-bucket-us-east-1-preprod</li>\n<li>my-tf-test-bucket-us-east-1-prod</li>\n</ul>\n", "OwnerUserId": "1464434", "LastActivityDate": "2019-11-22T11:48:28.507", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "209760171", "PostHistoryTypeId": "2", "PostId": "58993664", "RevisionGUID": "7d32602d-b7aa-4853-a5c8-63df6774899b", "CreationDate": "2019-11-22T11:48:28.507", "UserId": "1464434", "Text": "I don't like the idea of subfolders because this will result in different sources per environment and this tends to drift. \r\n\r\nThe better approach is to have a single stack for all environments (lets say dev, preprod and prod). To work on a single environment use ```terraform workspace```. \r\n\r\n    terraform workspace new dev\r\n\r\nThis creates a new workspace. This includs a dedicated state file and the variable ```terraform.workspace``` you can use in your code. \r\n\r\n    resource \"aws_s3_bucket\" \"bucket\" {\r\n      bucket = \"my-tf-test-bucket-${terraform.workspace}\"\r\n    }\r\n\r\nIn this way you will get buckets called\r\n\r\n - my-tf-test-bucket-dev\r\n - my-tf-test-bucket-preprod\r\n - my-tf-test-bucket-prod\r\n\r\nafter applying to the workspaces above (use ```terraform workspace select <WORKSPACE>``` to change environments). \r\nTo make the code even multi-region-proof do it like this:\r\n\r\n    data \"aws_region\" \"current\" {}\r\n    \r\n    resource \"aws_s3_bucket\" \"bucket\" {\r\n      bucket = \"my-tf-test-bucket-${data.aws_region.current.name}-${terraform.workspace}\"\r\n    }\r\n\r\nto get (for us-east-1 region)\r\n\r\n - my-tf-test-bucket-us-east-1-dev\r\n - my-tf-test-bucket-us-east-1-preprod\r\n - my-tf-test-bucket-us-east-1-prod", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "This includs a dedicated state file and the variable ```terraform.workspace``` you can use in your code. resource \"aws_s3_bucket\" \"bucket\" { bucket = \"my-tf-test-bucket-${terraform.workspace}\" } ", "keywords": ["test"]}, {"source": "Text", "text": "In this way you will get buckets called - my-tf-test-bucket-dev - my-tf-test-bucket-preprod - my-tf-test-bucket-prod after applying to the workspaces above (use ```terraform workspace select ``` to change environments). ", "keywords": ["change", "test"]}, {"source": "Text", "text": "To make the code even multi-region-proof do it like this: data \"aws_region\" \"current\" {} resource \"aws_s3_bucket\" \"bucket\" { bucket = \"my-tf-test-bucket-${data.aws_region.current.name}-${terraform.workspace}\" } to get (for us-east-1 region) - my-tf-test-bucket-us-east-1-dev - my-tf-test-bucket-us-east-1-preprod - my-tf-test-bucket-us-east-1-prod", "keywords": ["test"]}]}], "filtered-sentences": [{"source": "Body", "text": "In this way you will get buckets called my-tf-test-bucket-dev my-tf-test-bucket-preprod my-tf-test-bucket-prod after applying to the workspaces above (use terraform workspace select <WORKSPACE> to change environments). ", "keywords": ["change", "test"]}, {"source": "Body", "text": "To make the code even multi-region-proof do it like this: to get (for us-east-1 region) my-tf-test-bucket-us-east-1-dev my-tf-test-bucket-us-east-1-preprod my-tf-test-bucket-us-east-1-prod", "keywords": ["test"]}]}, {"Id": "44628512", "PostTypeId": "2", "ParentId": "33157516", "CreationDate": "2017-06-19T10:47:06.207", "Score": "6", "Body": "<p>Covered in more depth by @Yevgeny Brikman but specifically answering the OP's questions:</p>\n\n<blockquote>\n  <p>What's the best practice for actually managing the terraform files and state?</p>\n</blockquote>\n\n<p>Use git for TF files. But don't check State files in (i.e. tfstate). Instead use <code>Terragrunt</code> for sync / locking of state files to S3.</p>\n\n<blockquote>\n  <p>but do I commit tfstate as well? </p>\n</blockquote>\n\n<p>No. </p>\n\n<blockquote>\n  <p>Should that reside somewhere like S3?</p>\n</blockquote>\n\n<p>Yes</p>\n", "OwnerUserId": "343204", "LastEditorUserId": "1092815", "LastEditDate": "2019-02-27T14:26:30.800", "LastActivityDate": "2019-02-27T14:26:30.800", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "149688525", "PostHistoryTypeId": "2", "PostId": "44628512", "RevisionGUID": "a8f901ca-4863-44ce-be22-eece78c082f0", "CreationDate": "2017-06-19T10:47:06.207", "UserId": "343204", "Text": "Covered in more depth by @Yevgeny Brikman but specifically answering the OP's questions:\r\n\r\n    What's the best practice for actually managing the terraform files and state?\r\n\r\nUse git for TF files. But don't check State files in (i.e. tfstate). Instead use `Terragrunt` for sync / locking of state files to S3.\r\n\r\n    but do I commit tfstate as well? \r\n\r\nNo. \r\n\r\n    Should that reside somewhere like S3?\r\n\r\nYes", "ContentLicense": "CC BY-SA 3.0", "filtered-sentences": []}, {"Id": "192543759", "PostHistoryTypeId": "5", "PostId": "44628512", "RevisionGUID": "8cd7cc65-bf1f-4892-9b88-8a86aad619be", "CreationDate": "2019-02-27T14:26:30.800", "UserId": "1092815", "Comment": "syntax highlighting", "Text": "Covered in more depth by @Yevgeny Brikman but specifically answering the OP's questions:\r\n\r\n> What's the best practice for actually managing the terraform files and state?\r\n\r\nUse git for TF files. But don't check State files in (i.e. tfstate). Instead use `Terragrunt` for sync / locking of state files to S3.\r\n\r\n> but do I commit tfstate as well? \r\n\r\nNo. \r\n\r\n> Should that reside somewhere like S3?\r\n\r\nYes", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}], "contains-topic": true, "filtered-sentences": []}