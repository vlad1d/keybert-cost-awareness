{"Id": "54132293", "PostTypeId": "1", "CreationDate": "2019-01-10T15:49:18.547", "Score": "1", "ViewCount": "272", "Body": "<p>AWS Lambda uploading requires the generation of a zip archive of required source code and libraries. For use of NodeJS as the language for Lambda, it may be more typically the case that you want a source file and the node_modules directory to be included in the zip archive. The Terraform archive provider gives a file_archive resource which works well when it can be used. It can't be used when you want more than just 1 file or 1 directory. See <a href=\"https://github.com/terraform-providers/terraform-provider-archive/issues/37\" rel=\"nofollow noreferrer\">feature request</a> . To work around this, I came up with this code below. It executes steps but not in the required sequence. Run it once and it updates the zip file, but doesn't upload it to AWS. I run it again and it uploads to AWS. </p>\n\n<pre class=\"lang-tf prettyprint-override\"><code># This resource checks the state of the node_modules directory, hoping to determine,\n# most of the time, when there was a change in that directory. Output\n# is a 'mark' file with that data in it. That file can be hashed to\n# trigger updates to zip file creation.\nresource \"null_resource\" \"get_directory_mark\" {\n    provisioner \"local-exec\" {\n        command     = \"ls -l node_modules &gt; node_modules.mark; find node_modules -type d -ls &gt;&gt; node_modules.mark\"\n        interpreter = [\"bash\", \"-lc\"]\n    }\n\n    triggers = {\n        always = \"${timestamp()}\" # will trigger each run - small cost.\n    }\n}\n\nresource \"null_resource\" \"make_zip\" {\n    depends_on = [\"null_resource.get_directory_mark\"]\n\n    provisioner \"local-exec\" {\n        command     = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\"\n        interpreter = [\"bash\", \"-lc\"]\n    }\n\n    triggers = {\n        source_hash  = \"${sha1(\"${file(\"lambda_process_firewall_updates.js\")}\")}\"\n        node_modules = \"${sha1(\"${file(\"node_modules.mark\")}\")}\"                  # see above\n    }\n}\n\nresource \"aws_lambda_function\" \"lambda_process\" {\n    depends_on       = [\"null_resource.make_zip\"]\n    filename         = \"${var.lambda_zip}\"\n    function_name    = \"${var.lambda_function_name}\"\n    description      = \"process items\"\n    role             = \"${aws_iam_role.lambda_process.arn}\"\n    handler          = \"${var.lambda_function_name}.handler\"\n    runtime          = \"nodejs8.10\"\n    memory_size      = \"128\"\n    timeout          = \"60\"\n    source_code_hash = \"${base64sha256(file(\"lambda_process.zip\"))}\"\n}\n</code></pre>\n\n<p>Other related discussion includes: <a href=\"https://stackoverflow.com/questions/52662244/terraform-lambda-source-code-hash-update-with-same-code/54119203#54119203\">this question on code hashing</a>, (see my answer) and <a href=\"https://github.com/hashicorp/terraform/issues/8344\" rel=\"nofollow noreferrer\">this GitHub issue</a>.</p>\n", "OwnerUserId": "238074", "LastEditorUserId": "2965993", "LastEditDate": "2019-01-11T03:35:48.437", "LastActivityDate": "2019-01-11T03:35:48.437", "Title": "Terraform: Why doesn't this attempt to link resources work?", "Tags": "<aws-lambda><zip><terraform>", "AnswerCount": "0", "CommentCount": "13", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "95097723", "PostId": "54132293", "Score": "0", "Text": "Run the local-exec provisioner at the  beginning of the aws_lambda_function resource one after another - they will run in sequence.", "CreationDate": "2019-01-10T16:38:30.590", "UserId": "5660156", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95109137", "PostId": "54132293", "Score": "0", "Text": "Why can't you zip up the entire directory contents? Why does your `source_code_hash` not use `var.lambda_zip` like your `command` does in your second `null_resource`? It would also help if you could show us the `tree` output of your directory.", "CreationDate": "2019-01-11T00:28:39.453", "UserId": "2965993", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95109305", "PostId": "54132293", "Score": "0", "Text": "did you try the new feature in lambda, layers? so maintenant some layers with the proper version of node_modules packages, then you can directly deploy your nodejs codes easily", "CreationDate": "2019-01-11T00:40:40.160", "UserId": "498256", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "did you try the new feature in lambda, layers? ", "keywords": ["feature"]}]}, {"Id": "95131948", "PostId": "54132293", "Score": "0", "Text": "@victor m - no, they don't run in sequence. Terraform doesn't process sequentially.", "CreationDate": "2019-01-11T16:27:27.387", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95131961", "PostId": "54132293", "Score": "0", "Text": "@SomeGuyOnAComputer, Yes, that would be a way to work around what I did. I have other files there, like terraform files. I could move the code to a subdirectory or make a copy when I run TF. However, I just wanted to stick with what I have. My real question, the title of my question, is not how can I solve my problem another way, but why didn't my original code function with proper ordering?", "CreationDate": "2019-01-11T16:27:57.117", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95132101", "PostId": "54132293", "Score": "0", "Text": "@BMW - thanks for that idea. As I commented with SomeGuyOnAComputer, my question is really why my code does not work as expected.", "CreationDate": "2019-01-11T16:32:38.810", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95138098", "PostId": "54132293", "Score": "0", "Text": "@KevinBuchs \nMultiple provisioners can be specified within a resource. Multiple provisioners are executed in the order they're defined in the configuration file see https://www.terraform.io/docs/provisioners/index.html", "CreationDate": "2019-01-11T20:23:06.840", "UserId": "5660156", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95138261", "PostId": "54132293", "Score": "0", "Text": "To answer your question - I think your code fails because of the null -resource trigger. If the lambda function files don't change, the null-resource triggers will not fire and lambda resource will fail.", "CreationDate": "2019-01-11T20:30:26.140", "UserId": "5660156", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "If the lambda function files don't change, the null-resource triggers will not fire and lambda resource will fail.", "keywords": ["change"]}]}, {"Id": "95243183", "PostId": "54132293", "Score": "0", "Text": "@victorm Thanks. I now understand your point about multiple provisioners and sequencing. This was something new for me.\n\nAlso, you mention that if the code doesn't change no zip file will be generated. Now, I guess there is the assumption that the file will always be there and it is just a matter of determining when it needs to be updated. If the file exists, then the lambda resource always works fine. This is as expected.\n... continued", "CreationDate": "2019-01-15T23:24:56.933", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Also, you mention that if the code doesn't change no zip file will be generated. ", "keywords": ["change"]}]}, {"Id": "95243184", "PostId": "54132293", "Score": "0", "Text": "The problem here is that the behavior was: change the source, tf apply and the zip file was not updated, but the existing zip file is uploaded to lambda. That file then had not changed since the last time. If I change nothing further but run tf apply again, then the zip file is updated, however, that updated zip file is not uploaded to lambda. If I change nothing but run tf apply again, then the updated zip file is uploaded to lambda. So, it takes 3 passes to get things right.", "CreationDate": "2019-01-15T23:25:03.120", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The problem here is that the behavior was: change the source, tf apply and the zip file was not updated, but the existing zip file is uploaded to lambda. ", "keywords": ["change"]}, {"source": "Text", "text": "That file then had not changed since the last time. ", "keywords": ["change"]}, {"source": "Text", "text": "If I change nothing further but run tf apply again, then the zip file is updated, however, that updated zip file is not uploaded to lambda. ", "keywords": ["change"]}, {"source": "Text", "text": "If I change nothing but run tf apply again, then the updated zip file is uploaded to lambda. ", "keywords": ["change"]}]}, {"Id": "95247458", "PostId": "54132293", "Score": "0", "Text": "try this: resource \"null_resource\" \"make_zip\" {\n    provisioner \"local-exec\" {\n        command     = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\"\n    }\n\n    triggers = {\n        source_hash  = \"${base64sha256(file(var.lambda_zip))}\"\n    }\n}", "CreationDate": "2019-01-16T05:05:53.587", "UserId": "5660156", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "95381149", "PostId": "54132293", "Score": "0", "Text": "@victorm It would be better to use the [`archive_file`](https://www.terraform.io/docs/providers/archive/d/archive_file.html) data source to zip the contents on the fly. It will also not trigger an update if the code hasn't changed.", "CreationDate": "2019-01-20T18:35:18.253", "UserId": "2965993", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "It will also not trigger an update if the code hasn't changed.", "keywords": ["change"]}]}, {"Id": "95415922", "PostId": "54132293", "Score": "0", "Text": "@SomeGuyOnAComputer - I explain why this alternative doesn't work in my original question. And, my question is not seeking an alternative, but asking why what I presented as a solution was not working properly.", "CreationDate": "2019-01-21T21:06:35.897", "UserId": "238074", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "links": [{"Id": "1640529944", "CreationDate": "2019-01-10T15:49:18.547", "PostId": "54132293", "RelatedPostId": "52662244", "LinkTypeId": "1"}], "history": [{"Id": "189310579", "PostHistoryTypeId": "2", "PostId": "54132293", "RevisionGUID": "7b0ff726-67be-468e-a644-7ad2f8331572", "CreationDate": "2019-01-10T15:49:18.547", "UserId": "238074", "Text": "AWS Lambda uploading requires the generation of a zip archive of required source code and libraries. For use of NodeJS as the language for Lambda, it may be more typically the case that you want a source file and the node_modules directory to be included in the zip archive. The Terraform archive provider gives a file_archive resource which works well when it can be used. It can't be used when you want more than just 1 file or 1 directory. See [feature request][1] . To work around this, I came up with this code below. It executes steps but not in the required sequence. Run it once and it updates the zip file, but doesn't upload it to AWS. I run it again and it uploads to AWS. \r\n\r\n    # This resource checks the state of the node_modules directory, hoping to determine,\r\n    # most of the time, when there was a change in that directory. Output\r\n    # is a 'mark' file with that data in it. That file can be hashed to\r\n    # trigger updates to zip file creation.\r\n    resource \"null_resource\" \"get_directory_mark\" {\r\n      provisioner \"local-exec\" {\r\n        command     = \"ls -l node_modules > node_modules.mark; find node_modules -type d -ls >> node_modules.mark\"\r\n        interpreter = [\"bash\", \"-lc\"]\r\n      }\r\n    \r\n      triggers = {\r\n        always = \"${timestamp()}\" # will trigger each run - small cost.\r\n      }\r\n    }\r\n    \r\n    resource \"null_resource\" \"make_zip\" {\r\n      depends_on = [\"null_resource.get_directory_mark\"]\r\n    \r\n      provisioner \"local-exec\" {\r\n        command     = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\"\r\n        interpreter = [\"bash\", \"-lc\"]\r\n      }\r\n    \r\n      triggers = {\r\n        source_hash  = \"${sha1(\"${file(\"lambda_process_firewall_updates.js\")}\")}\"\r\n        node_modules = \"${sha1(\"${file(\"node_modules.mark\")}\")}\"                  # see above\r\n      }\r\n    }\r\n    \r\n    resource \"aws_lambda_function\" \"lambda_process\" {\r\n      depends_on       = [\"null_resource.make_zip\"]\r\n      filename         = \"${var.lambda_zip}\"\r\n      function_name    = \"${var.lambda_function_name}\"\r\n      description      = \"process items\"\r\n      role             = \"${aws_iam_role.lambda_process.arn}\"\r\n      handler          = \"${var.lambda_function_name}.handler\"\r\n      runtime          = \"nodejs8.10\"\r\n      memory_size      = \"128\"\r\n      timeout          = \"60\"\r\n      source_code_hash = \"${base64sha256(file(\"lambda_process.zip\"))}\"\r\n    }\r\n\r\nOther related discussion includes: [this question on code hashing][2], (see my answer) and [this GitHub issue][3].\r\n\r\n\r\n  [1]: https://github.com/terraform-providers/terraform-provider-archive/issues/37\r\n  [2]: https://stackoverflow.com/questions/52662244/terraform-lambda-source-code-hash-update-with-same-code/54119203#54119203\r\n  [3]: https://github.com/hashicorp/terraform/issues/8344", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The Terraform archive provider gives a file_archive resource which works well when it can be used. ", "keywords": ["provider"]}, {"source": "Text", "text": "See [feature request][1] . ", "keywords": ["feature"]}, {"source": "Text", "text": "# This resource checks the state of the node_modules directory, hoping to determine, # most of the time, when there was a change in that directory. ", "keywords": ["change"]}, {"source": "Text", "text": "That file can be hashed to # trigger updates to zip file creation. resource \"null_resource\" \"get_directory_mark\" { provisioner \"local-exec\" { command = \"ls -l node_modules > node_modules.mark; find node_modules -type d -ls >> node_modules.mark\" interpreter = [\"bash\", \"-lc\"] } triggers = { always = \"${timestamp()}\" # will trigger each run - small cost. } } resource \"null_resource\" \"make_zip\" { depends_on = [\"null_resource.get_directory_mark\"] provisioner \"local-exec\" { command = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\" interpreter = [\"bash\", \"-lc\"] } triggers = { source_hash = \"${sha1(\"${file(\"lambda_process_firewall_updates.js\")}\")}\" node_modules = \"${sha1(\"${file(\"node_modules.mark\")}\")}\" # see above } } resource \"aws_lambda_function\" \"lambda_process\" { depends_on = [\"null_resource.make_zip\"] filename = \"${var.lambda_zip}\" function_name = \"${var.lambda_function_name}\" description = \"process items\" role = \"${aws_iam_role.lambda_process.arn}\" handler = \"${var.lambda_function_name}.handler\" runtime = \"nodejs8.10\" memory_size = \"128\" timeout = \"60\" source_code_hash = \"${base64sha256(file(\"lambda_process.zip\"))}\" } Other related discussion includes: [this question on code hashing][2], (see my answer) and [this GitHub issue][3]. [1]: https://github.com/terraform-providers/terraform-provider-archive/issues/37 [2]: https://stackoverflow.com/questions/52662244/terraform-lambda-source-code-hash-update-with-same-code/54119203#54119203 [3]: https://github.com/hashicorp/terraform/issues/8344", "keywords": ["cost", "provider"]}]}, {"Id": "189310580", "PostHistoryTypeId": "1", "PostId": "54132293", "RevisionGUID": "7b0ff726-67be-468e-a644-7ad2f8331572", "CreationDate": "2019-01-10T15:49:18.547", "UserId": "238074", "Text": "Terraform: Why doesn't this attempt to link resources work?", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "189310581", "PostHistoryTypeId": "3", "PostId": "54132293", "RevisionGUID": "7b0ff726-67be-468e-a644-7ad2f8331572", "CreationDate": "2019-01-10T15:49:18.547", "UserId": "238074", "Text": "<aws-lambda><zip><terraform>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "189341906", "PostHistoryTypeId": "5", "PostId": "54132293", "RevisionGUID": "ebc8f732-4f08-439f-a49e-5b3d45626af1", "CreationDate": "2019-01-11T03:35:48.437", "UserId": "2965993", "Comment": "show terraform syntax highlighting", "Text": "AWS Lambda uploading requires the generation of a zip archive of required source code and libraries. For use of NodeJS as the language for Lambda, it may be more typically the case that you want a source file and the node_modules directory to be included in the zip archive. The Terraform archive provider gives a file_archive resource which works well when it can be used. It can't be used when you want more than just 1 file or 1 directory. See [feature request][1] . To work around this, I came up with this code below. It executes steps but not in the required sequence. Run it once and it updates the zip file, but doesn't upload it to AWS. I run it again and it uploads to AWS. \r\n\r\n```lang-tf\r\n# This resource checks the state of the node_modules directory, hoping to determine,\r\n# most of the time, when there was a change in that directory. Output\r\n# is a 'mark' file with that data in it. That file can be hashed to\r\n# trigger updates to zip file creation.\r\nresource \"null_resource\" \"get_directory_mark\" {\r\n    provisioner \"local-exec\" {\r\n        command     = \"ls -l node_modules > node_modules.mark; find node_modules -type d -ls >> node_modules.mark\"\r\n        interpreter = [\"bash\", \"-lc\"]\r\n    }\r\n\r\n    triggers = {\r\n        always = \"${timestamp()}\" # will trigger each run - small cost.\r\n    }\r\n}\r\n\r\nresource \"null_resource\" \"make_zip\" {\r\n    depends_on = [\"null_resource.get_directory_mark\"]\r\n\r\n    provisioner \"local-exec\" {\r\n        command     = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\"\r\n        interpreter = [\"bash\", \"-lc\"]\r\n    }\r\n\r\n    triggers = {\r\n        source_hash  = \"${sha1(\"${file(\"lambda_process_firewall_updates.js\")}\")}\"\r\n        node_modules = \"${sha1(\"${file(\"node_modules.mark\")}\")}\"                  # see above\r\n    }\r\n}\r\n\r\nresource \"aws_lambda_function\" \"lambda_process\" {\r\n    depends_on       = [\"null_resource.make_zip\"]\r\n    filename         = \"${var.lambda_zip}\"\r\n    function_name    = \"${var.lambda_function_name}\"\r\n    description      = \"process items\"\r\n    role             = \"${aws_iam_role.lambda_process.arn}\"\r\n    handler          = \"${var.lambda_function_name}.handler\"\r\n    runtime          = \"nodejs8.10\"\r\n    memory_size      = \"128\"\r\n    timeout          = \"60\"\r\n    source_code_hash = \"${base64sha256(file(\"lambda_process.zip\"))}\"\r\n}\r\n```\r\nOther related discussion includes: [this question on code hashing][2], (see my answer) and [this GitHub issue][3].\r\n\r\n\r\n  [1]: https://github.com/terraform-providers/terraform-provider-archive/issues/37\r\n  [2]: https://stackoverflow.com/questions/52662244/terraform-lambda-source-code-hash-update-with-same-code/54119203#54119203\r\n  [3]: https://github.com/hashicorp/terraform/issues/8344", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The Terraform archive provider gives a file_archive resource which works well when it can be used. ", "keywords": ["provider"]}, {"source": "Text", "text": "See [feature request][1] . ", "keywords": ["feature"]}, {"source": "Text", "text": "This resource checks the state of the node_modules directory, hoping to determine, # most of the time, when there was a change in that directory. ", "keywords": ["change"]}, {"source": "Text", "text": "That file can be hashed to # trigger updates to zip file creation. resource \"null_resource\" \"get_directory_mark\" { provisioner \"local-exec\" { command = \"ls -l node_modules > node_modules.mark; find node_modules -type d -ls >> node_modules.mark\" interpreter = [\"bash\", \"-lc\"] } triggers = { always = \"${timestamp()}\" # will trigger each run - small cost. } } resource \"null_resource\" \"make_zip\" { depends_on = [\"null_resource.get_directory_mark\"] provisioner \"local-exec\" { command = \"zip -r ${var.lambda_zip} ${var.lambda_function_name}.js node_modules\" interpreter = [\"bash\", \"-lc\"] } triggers = { source_hash = \"${sha1(\"${file(\"lambda_process_firewall_updates.js\")}\")}\" node_modules = \"${sha1(\"${file(\"node_modules.mark\")}\")}\" # see above } } resource \"aws_lambda_function\" \"lambda_process\" { depends_on = [\"null_resource.make_zip\"] filename = \"${var.lambda_zip}\" function_name = \"${var.lambda_function_name}\" description = \"process items\" role = \"${aws_iam_role.lambda_process.arn}\" handler = \"${var.lambda_function_name}.handler\" runtime = \"nodejs8.10\" memory_size = \"128\" timeout = \"60\" source_code_hash = \"${base64sha256(file(\"lambda_process.zip\"))}\" } ``` Other related discussion includes: [this question on code hashing][2], (see my answer) and [this GitHub issue][3]. [1]: https://github.com/terraform-providers/terraform-provider-archive/issues/37 [2]: https://stackoverflow.com/questions/52662244/terraform-lambda-source-code-hash-update-with-same-code/54119203#54119203 [3]: https://github.com/hashicorp/terraform/issues/8344", "keywords": ["cost", "provider"]}]}, {"Id": "189341907", "PostHistoryTypeId": "24", "PostId": "54132293", "RevisionGUID": "ebc8f732-4f08-439f-a49e-5b3d45626af1", "CreationDate": "2019-01-11T03:35:48.437", "Comment": "Proposed by 2965993 approved by 9959152, 10008173 edit id of 4087820", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "The Terraform archive provider gives a file_archive resource which works well when it can be used. ", "keywords": ["provider"]}, {"source": "Body", "text": "See feature request . ", "keywords": ["feature"]}]}