{"Id": "64001298", "PostTypeId": "1", "AcceptedAnswerId": "64002529", "CreationDate": "2020-09-21T23:50:58.930", "Score": "0", "ViewCount": "1969", "Body": "<p><strong>TF Version:</strong> 0.12.28 and 0.13.3</p>\n<p><strong>My Goal:</strong></p>\n<ul>\n<li>Have an AWS S3 bucket for PROD env to store tf state</li>\n<li>Have an AWS S3 bucket for NONPROD env to store tf state</li>\n</ul>\n<p><strong>Following <a href=\"https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa\" rel=\"nofollow noreferrer\">this tutorial</a> I successfully accomplished the following:</strong></p>\n<ul>\n<li>a AWS S3 bucket and a dynamodb from a folder called TEST:</li>\n</ul>\n<pre><code>provider &quot;aws&quot; {\n  region = var.aws_region_id\n}\n\nresource &quot;aws_s3_bucket&quot; &quot;terraform_state&quot; {\n    bucket = var.aws_bucket_name\n    versioning {\n      enabled = true\n    }\n    server_side_encryption_configuration {\n      rule {\n        apply_server_side_encryption_by_default {\n          sse_algorithm = &quot;AES256&quot;\n        }\n      }\n    }\n}\n\nresource &quot;aws_dynamodb_table&quot; &quot;terraform_locks&quot; {\n  name         = var.aws_bucket_name\n  billing_mode = &quot;PAY_PER_REQUEST&quot;\n  hash_key     = &quot;LockID&quot;\n  attribute {\n    name = &quot;LockID&quot;\n    type = &quot;S&quot;\n  }\n}\n\nterraform {\n  backend &quot;s3&quot; {\n    bucket         = &quot;test-myproject-poc&quot;\n    key            = &quot;global/s3/terraform.tfstate&quot;\n    region         = &quot;us-east-1&quot;\n    dynamodb_table = &quot;test-myproject-poc&quot;\n    encrypt        = true\n  }\n}\n</code></pre>\n<p><em><strong>Up to this point everything was successfully deployed</strong></em></p>\n<p><strong>However when I wanted to have another S3 bucket/Dynamodb for PROD env the following happened:</strong></p>\n<ul>\n<li>I went to another folder called PRODUCTION, I did terraform init (initialization was ok)</li>\n<li>copied the same module I have on PROD to this folder. And I renamed PROD with TEST to match the env</li>\n</ul>\n<p>Terrarom plan now says it wants to replace my actual deployment to create the new one:</p>\n<pre><code>\u279c  S3 tf plan\nAcquiring state lock. This may take a few moments...\nRefreshing Terraform state in-memory prior to plan...\nThe refreshed state will be used to calculate this plan, but will not be\npersisted to local or remote state storage.\n\naws_dynamodb_table.terraform_locks: Refreshing state... [id=test-myproject-poc]\naws_s3_bucket.terraform_state: Refreshing state... [id=test-myproject-poc]\n\n------------------------------------------------------------------------\n\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n-/+ destroy and then create replacement\n\nTerraform will perform the following actions:\n\n  # aws_dynamodb_table.terraform_locks must be replaced\n-/+ resource &quot;aws_dynamodb_table&quot; &quot;terraform_locks&quot; {\n      ~ arn              = &quot;arn:aws:dynamodb:us-east-1:1234567890:table/test-myproject-poc&quot; -&gt; (known after apply)\n        billing_mode     = &quot;PAY_PER_REQUEST&quot;\n        hash_key         = &quot;LockID&quot;\n      ~ id               = &quot;test-myproject-poc&quot; -&gt; (known after apply)\n      ~ name             = &quot;test-myproject-poc&quot; -&gt; &quot;prod-myproject-poc&quot; # forces replacement\n</code></pre>\n<ul>\n<li>The state is actually on <code>global/s3/terraform.tfstate</code></li>\n<li>I'm not using workspaces</li>\n</ul>\n<p>What is the proper way to create S3_PROD <strong>without</strong> deleting the first one?</p>\n", "OwnerUserId": "13976210", "LastActivityDate": "2020-09-22T03:07:05.723", "Title": "Terraform wants to replace existing resources", "Tags": "<amazon-s3><terraform>", "AnswerCount": "1", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "231290944", "PostHistoryTypeId": "2", "PostId": "64001298", "RevisionGUID": "ddfba695-4abd-464b-9290-42d60adfeb75", "CreationDate": "2020-09-21T23:50:58.930", "UserId": "13976210", "Text": "**TF Version:** 0.12.28 and 0.13.3\r\n\r\n**My Goal:**\r\n\r\n- Have an AWS S3 bucket for PROD env to store tf state\r\n- Have an AWS S3 bucket for NONPROD env to store tf state\r\n\r\n**Following [this tutorial][1] I successfully accomplished the following:**\r\n\r\n- a AWS S3 bucket and a dynamodb from a folder called TEST:\r\n\r\n```\r\nprovider \"aws\" {\r\n  region = var.aws_region_id\r\n}\r\n\r\nresource \"aws_s3_bucket\" \"terraform_state\" {\r\n    bucket = var.aws_bucket_name\r\n    versioning {\r\n      enabled = true\r\n    }\r\n    server_side_encryption_configuration {\r\n      rule {\r\n        apply_server_side_encryption_by_default {\r\n          sse_algorithm = \"AES256\"\r\n        }\r\n      }\r\n    }\r\n}\r\n\r\nresource \"aws_dynamodb_table\" \"terraform_locks\" {\r\n  name         = var.aws_bucket_name\r\n  billing_mode = \"PAY_PER_REQUEST\"\r\n  hash_key     = \"LockID\"\r\n  attribute {\r\n    name = \"LockID\"\r\n    type = \"S\"\r\n  }\r\n}\r\n\r\nterraform {\r\n  backend \"s3\" {\r\n    bucket         = \"test-myproject-poc\"\r\n    key            = \"global/s3/terraform.tfstate\"\r\n    region         = \"us-east-1\"\r\n    dynamodb_table = \"test-myproject-poc\"\r\n    encrypt        = true\r\n  }\r\n}\r\n```\r\n\r\n***Up to this point everything was successfully deployed***\r\n\r\n**However when I wanted to have another S3 bucket/Dynamodb for PROD env the following happened:**\r\n\r\n- I went to another folder called PRODUCTION, I did terraform init (initialization was ok)\r\n- copied the same module I have on PROD to this folder. And I renamed PROD with TEST to match the env\r\n\r\nTerrarom plan now says it wants to replace my actual deployment to create the new one:\r\n\r\n```\r\n\u279c  S3 tf plan\r\nAcquiring state lock. This may take a few moments...\r\nRefreshing Terraform state in-memory prior to plan...\r\nThe refreshed state will be used to calculate this plan, but will not be\r\npersisted to local or remote state storage.\r\n\r\naws_dynamodb_table.terraform_locks: Refreshing state... [id=test-myproject-poc]\r\naws_s3_bucket.terraform_state: Refreshing state... [id=test-myproject-poc]\r\n\r\n------------------------------------------------------------------------\r\n\r\nAn execution plan has been generated and is shown below.\r\nResource actions are indicated with the following symbols:\r\n-/+ destroy and then create replacement\r\n\r\nTerraform will perform the following actions:\r\n\r\n  # aws_dynamodb_table.terraform_locks must be replaced\r\n-/+ resource \"aws_dynamodb_table\" \"terraform_locks\" {\r\n      ~ arn              = \"arn:aws:dynamodb:us-east-1:1234567890:table/test-myproject-poc\" -> (known after apply)\r\n        billing_mode     = \"PAY_PER_REQUEST\"\r\n        hash_key         = \"LockID\"\r\n      ~ id               = \"test-myproject-poc\" -> (known after apply)\r\n      ~ name             = \"test-myproject-poc\" -> \"prod-myproject-poc\" # forces replacement\r\n```\r\n\r\n- The state is actually on `global/s3/terraform.tfstate`\r\n- I'm not using workspaces\r\n\r\nWhat is the proper way to create S3_PROD **without** deleting the first one?\r\n\r\n\r\n  [1]: https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "I successfully accomplished the following:** - a AWS S3 bucket and a dynamodb from a folder called TEST: ``` provider \"aws\" { region = var.aws_region_id } resource \"aws_s3_bucket\" \"terraform_state\" { bucket = var.aws_bucket_name versioning { enabled = true } server_side_encryption_configuration { rule { apply_server_side_encryption_by_default { sse_algorithm = \"AES256\" } } } } resource \"aws_dynamodb_table\" \"terraform_locks\" { name = var.aws_bucket_name billing_mode = \"PAY_PER_REQUEST\" hash_key = \"LockID\" attribute { name = \"LockID\" type = \"S\" } } terraform { backend \"s3\" { bucket = \"test-myproject-poc\" key = \"global/s3/terraform.tfstate\" region = \"us-east-1\" dynamodb_table = \"test-myproject-poc\" encrypt = true } } ``` ", "keywords": ["bill", "provider", "test"]}, {"source": "Text", "text": "And I renamed PROD with TEST to match the env Terrarom plan now says it wants to replace my actual deployment to create the new one: ``` ", "keywords": ["test"]}, {"source": "Text", "text": "The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ", "keywords": ["storage"]}, {"source": "Text", "text": "aws_dynamodb_table.terraform_locks: Refreshing state... [id=test-myproject-poc] aws_s3_bucket.terraform_state: Refreshing state... [id=test-myproject-poc] ------------------------------------------------------------------------ ", "keywords": ["test"]}, {"source": "Text", "text": "Resource actions are indicated with the following symbols: -/+ destroy and then create replacement Terraform will perform the following actions: # aws_dynamodb_table.terraform_locks must be replaced -/+ resource \"aws_dynamodb_table\" \"terraform_locks\" { ~ arn = \"arn:aws:dynamodb:us-east-1:1234567890:table/test-myproject-poc\" -> (known after apply) billing_mode = \"PAY_PER_REQUEST\" hash_key = \"LockID\" ~ id = \"test-myproject-poc\" -> (known after apply) ~ name = \"test-myproject-poc\" -> \"prod-myproject-poc\" # forces replacement ``` - The state is actually on `global/s3/terraform.tfstate` - I'm not using workspaces What is the proper way to create S3_PROD **without** deleting the first one? [1]: https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa", "keywords": ["bill", "test"]}]}, {"Id": "231290945", "PostHistoryTypeId": "1", "PostId": "64001298", "RevisionGUID": "ddfba695-4abd-464b-9290-42d60adfeb75", "CreationDate": "2020-09-21T23:50:58.930", "UserId": "13976210", "Text": "Terraform wants to replace existing resources", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "231290946", "PostHistoryTypeId": "3", "PostId": "64001298", "RevisionGUID": "ddfba695-4abd-464b-9290-42d60adfeb75", "CreationDate": "2020-09-21T23:50:58.930", "UserId": "13976210", "Text": "<amazon-s3><terraform>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "answers": [{"Id": "64002529", "PostTypeId": "2", "ParentId": "64001298", "CreationDate": "2020-09-22T03:07:05.723", "Score": "0", "Body": "<p>I solved the issue!   Just found out that I needed to remove this block:</p>\n<pre><code>terraform {\n  backend &quot;s3&quot; {\n    bucket         = &quot;test-myproject-poc&quot;\n    key            = &quot;global/s3/terraform.tfstate&quot;\n    region         = &quot;us-east-1&quot;\n    dynamodb_table = &quot;test-myproject-poc&quot;\n    encrypt        = true\n  }\n}\n</code></pre>\n<p>dropped .terraform folder and run init again.</p>\n<p>After doing these steps, plan ran as expected (it didn't try to remove my deployment).</p>\n<p>What I think, but not sure tough, is that it was trying to use the same state file previously deployed.  So I just left tf to create the bucket and dynamo table to finally run the process of storing the new state of the new folder (PROD) in S3.</p>\n<p>HTH</p>\n", "OwnerUserId": "13976210", "LastActivityDate": "2020-09-22T03:07:05.723", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "231296813", "PostHistoryTypeId": "2", "PostId": "64002529", "RevisionGUID": "b6213d52-50cd-4dc3-b58b-009691c3493c", "CreationDate": "2020-09-22T03:07:05.723", "UserId": "13976210", "Text": "I solved the issue!   Just found out that I needed to remove this block:\r\n\r\n    terraform {\r\n      backend \"s3\" {\r\n        bucket         = \"test-myproject-poc\"\r\n        key            = \"global/s3/terraform.tfstate\"\r\n        region         = \"us-east-1\"\r\n        dynamodb_table = \"test-myproject-poc\"\r\n        encrypt        = true\r\n      }\r\n    }\r\n\r\ndropped .terraform folder and run init again.\r\n\r\nAfter doing these steps, plan ran as expected (it didn't try to remove my deployment).\r\n\r\nWhat I think, but not sure tough, is that it was trying to use the same state file previously deployed.  So I just left tf to create the bucket and dynamo table to finally run the process of storing the new state of the new folder (PROD) in S3.\r\n\r\nHTH", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Just found out that I needed to remove this block: terraform { backend \"s3\" { bucket = \"test-myproject-poc\" key = \"global/s3/terraform.tfstate\" region = \"us-east-1\" dynamodb_table = \"test-myproject-poc\" encrypt = true } } dropped .terraform folder and run init again. ", "keywords": ["test"]}]}], "filtered-sentences": []}], "contains-topic": true, "filtered-sentences": [{"source": "Body", "text": "TF Version: 0.12.28 and 0.13.3 My Goal: Have an AWS S3 bucket for PROD env to store tf state Have an AWS S3 bucket for NONPROD env to store tf state Following this tutorial I successfully accomplished the following: a AWS S3 bucket and a dynamodb from a folder called TEST: Up to this point everything was successfully deployed ", "keywords": ["test"]}, {"source": "Body", "text": "And I renamed PROD with TEST to match the env Terrarom plan now says it wants to replace my actual deployment to create the new one: The state is actually on global/s3/terraform.tfstate I'm not using workspaces ", "keywords": ["test"]}]}