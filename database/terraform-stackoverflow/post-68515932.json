{"Id": "68515932", "PostTypeId": "1", "AcceptedAnswerId": "68523605", "CreationDate": "2021-07-25T06:01:57.813", "Score": "1", "ViewCount": "975", "Body": "<p>So I created EKS Cluster using example given in<br />\n<a href=\"https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete\" rel=\"nofollow noreferrer\">Cloudposse eks terraform module</a></p>\n<p>On top of this, I created AWS S3 and Dynamodb for storing state file and lock file respectively and added the same in <a href=\"https://www.terraform.io/docs/language/settings/backends/s3.html\" rel=\"nofollow noreferrer\">terraform backend config</a>.</p>\n<p>This is how it looks :</p>\n<pre><code>resource &quot;aws_s3_bucket&quot; &quot;terraform_state&quot; {\n  bucket = &quot;${var.namespace}-${var.name}-terraform-state&quot;\n  # Enable versioning so we can see the full revision history of our\n  # state files\n  versioning {\n    enabled = true\n  }\n  # Enable server-side encryption by default\n  server_side_encryption_configuration {\n    rule {\n      apply_server_side_encryption_by_default {\n        sse_algorithm = &quot;aws:kms&quot;\n      }\n    }\n  }\n}\n\nresource &quot;aws_dynamodb_table&quot; &quot;terraform_locks&quot; {\n  name         = &quot;${var.namespace}-${var.name}-running-locks&quot;\n  billing_mode = &quot;PAY_PER_REQUEST&quot;\n  hash_key     = &quot;LockID&quot;\n  attribute {\n    name = &quot;LockID&quot;\n    type = &quot;S&quot;\n  }\n}\n\nterraform {\n  backend &quot;s3&quot; {\n    bucket = &quot;${var.namespace}-${var.name}-terraform-state&quot;\n    key    = &quot;${var.stage}/terraform.tfstate&quot;\n    region = var.region\n    # Replace this with your DynamoDB table name!\n    dynamodb_table = &quot;${var.namespace}-${var.name}-running-locks&quot;\n    encrypt        = true\n  }\n}\n</code></pre>\n<p>Now when I try to delete EKS cluster using <code>terraform destroy</code> I get this error:</p>\n<pre><code>Error: error deleting S3 Bucket (abc-eks-terraform-state): BucketNotEmpty: The bucket you tried to delete is not empty. You must delete all versions in the bucket.\n</code></pre>\n<p>This is the output of <code>terraform plan -destroy</code> after the cluster is partially destroyed because of s3 error</p>\n<pre><code>Changes to Outputs:\n  - dynamodb_table_name             = &quot;abc-eks-running-locks&quot; -&gt; null\n  - eks_cluster_security_group_name = &quot;abc-staging-eks-cluster&quot; -&gt; null\n  - eks_cluster_version             = &quot;1.19&quot; -&gt; null\n  - eks_node_group_role_name        = &quot;abc-staging-eks-workers&quot; -&gt; null\n  - private_subnet_cidrs            = [\n      - &quot;172.16.0.0/19&quot;,\n      - &quot;172.16.32.0/19&quot;,\n    ] -&gt; null\n  - public_subnet_cidrs             = [\n      - &quot;172.16.96.0/19&quot;,\n      - &quot;172.16.128.0/19&quot;,\n    ] -&gt; null\n  - s3_bucket_arn                   = &quot;arn:aws:s3:::abc-eks-terraform-state&quot; -&gt; null\n  - vpc_cidr                        = &quot;172.16.0.0/16&quot; -&gt; null\n</code></pre>\n<p>I cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false)</p>\n<p>So I wanted to know is there a way to tell terraform to delete s3 at the end once everything is deleted. Or is there a way to use the terraform which is there in s3 locally?</p>\n<p>What's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform.</p>\n", "OwnerUserId": "5073662", "LastEditorUserId": "712765", "LastEditDate": "2022-08-24T19:45:21.050", "LastActivityDate": "2022-08-24T19:45:21.050", "Title": "Terraform : \"Error: error deleting S3 Bucket\" while trying to destroy EKS Cluster", "Tags": "<kubernetes><terraform><terraform-provider-aws><amazon-eks><cloudposse>", "AnswerCount": "1", "CommentCount": "3", "ContentLicense": "CC BY-SA 4.0", "comments": [{"Id": "121087973", "PostId": "68515932", "Score": "0", "Text": "The error is about S3, not EKS. So EKS has already been destroyed?", "CreationDate": "2021-07-25T06:19:21.617", "UserId": "248823", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "121089901", "PostId": "68515932", "Score": "0", "Text": "The error is while destroying EKS Cluster, the cluster is not entirely destroyed and it stops at AWS S3 deletion.", "CreationDate": "2021-07-25T09:15:59.527", "UserId": "5073662", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "The error is while destroying EKS Cluster, the cluster is not entirely destroyed and it stops at AWS S3 deletion.", "keywords": ["cluster"]}]}, {"Id": "121089937", "PostId": "68515932", "Score": "0", "Text": "@Marcin I've added the destroy plan output\nA couple of things are deleted and a couple of things are pending.", "CreationDate": "2021-07-25T09:18:38.170", "UserId": "5073662", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "history": [{"Id": "250837742", "PostHistoryTypeId": "2", "PostId": "68515932", "RevisionGUID": "2b05b757-3d80-4c23-a4de-7398312738c8", "CreationDate": "2021-07-25T06:01:57.813", "UserId": "5073662", "Text": "So I created EKS Cluster using example given in  \r\n[Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete)\r\n\r\nOn top of this, I created AWS S3 and Dynamodb for storing state file and lock file respectively and added the same in [terraform backend config][1]. \r\n\r\nThis is how it looks : \r\n\r\n    resource \"aws_s3_bucket\" \"terraform_state\" {\r\n      bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n      # Enable versioning so we can see the full revision history of our\r\n      # state files\r\n      versioning {\r\n        enabled = true\r\n      }\r\n      # Enable server-side encryption by default\r\n      server_side_encryption_configuration {\r\n        rule {\r\n          apply_server_side_encryption_by_default {\r\n            sse_algorithm = \"aws:kms\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n    \r\n    resource \"aws_dynamodb_table\" \"terraform_locks\" {\r\n      name         = \"${var.namespace}-${var.name}-running-locks\"\r\n      billing_mode = \"PAY_PER_REQUEST\"\r\n      hash_key     = \"LockID\"\r\n      attribute {\r\n        name = \"LockID\"\r\n        type = \"S\"\r\n      }\r\n    }\r\n    \r\n    terraform {\r\n      backend \"s3\" {\r\n        bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n        key    = \"${var.stage}/terraform.tfstate\"\r\n        region = var.region\r\n        # Replace this with your DynamoDB table name!\r\n        dynamodb_table = \"${var.namespace}-${var.name}-running-locks\"\r\n        encrypt        = true\r\n      }\r\n    }\r\n\r\nNow when I try to delete EKS cluster using `terraform destroy` I get this error:\r\n\r\n    Error: error deleting S3 Bucket (abhyasu-eks-terraform-state): BucketNotEmpty: The bucket you tried to delete is not empty. You must delete all versions in the bucket.\r\n\r\nI cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false)\r\n\r\nSo I wanted to know is there a way to tell terraform to delete s3 at the end once everything is deleted. Or is there a way to use the terraform which is there in s3 locally?\r\n\r\nWhat's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform.\r\n\r\n \r\n  [1]: https://www.terraform.io/docs/language/settings/backends/s3.html\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "So I created EKS Cluster using example given in [Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete) ", "keywords": ["cluster"]}, {"source": "Text", "text": "This is how it looks : resource \"aws_s3_bucket\" \"terraform_state\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" # Enable versioning so we can see the full revision history of our # state files versioning { enabled = true } # Enable server-side encryption by default server_side_encryption_configuration { rule { apply_server_side_encryption_by_default { sse_algorithm = \"aws:kms\" } } } } resource \"aws_dynamodb_table\" \"terraform_locks\" { name = \"${var.namespace}-${var.name}-running-locks\" billing_mode = \"PAY_PER_REQUEST\" hash_key = \"LockID\" attribute { name = \"LockID\" type = \"S\" } } terraform { backend \"s3\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" key = \"${var.stage}/terraform.tfstate\" region = var.region # Replace this with your DynamoDB table name! dynamodb_table = \"${var.namespace}-${var.name}-running-locks\" encrypt = true } } Now when I try to delete EKS cluster using `terraform destroy` ", "keywords": ["bill", "cluster"]}, {"source": "Text", "text": "What's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform. ", "keywords": ["cluster"]}]}, {"Id": "250837743", "PostHistoryTypeId": "1", "PostId": "68515932", "RevisionGUID": "2b05b757-3d80-4c23-a4de-7398312738c8", "CreationDate": "2021-07-25T06:01:57.813", "UserId": "5073662", "Text": "Terraform : \"Error: error deleting S3 Bucket\" while trying to destroy EKS Cluster", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "Terraform : \"Error: error deleting S3 Bucket\" while trying to destroy EKS Cluster", "keywords": ["cluster"]}]}, {"Id": "250837744", "PostHistoryTypeId": "3", "PostId": "68515932", "RevisionGUID": "2b05b757-3d80-4c23-a4de-7398312738c8", "CreationDate": "2021-07-25T06:01:57.813", "UserId": "5073662", "Text": "<kubernetes><terraform><terraform-provider-aws><amazon-eks>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}, {"Id": "250842648", "PostHistoryTypeId": "5", "PostId": "68515932", "RevisionGUID": "7fce676c-b5da-4883-81af-05221ca15561", "CreationDate": "2021-07-25T09:09:57.543", "UserId": "5073662", "Comment": "deleted 4 characters in body", "Text": "So I created EKS Cluster using example given in  \r\n[Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete)\r\n\r\nOn top of this, I created AWS S3 and Dynamodb for storing state file and lock file respectively and added the same in [terraform backend config][1]. \r\n\r\nThis is how it looks : \r\n\r\n    resource \"aws_s3_bucket\" \"terraform_state\" {\r\n      bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n      # Enable versioning so we can see the full revision history of our\r\n      # state files\r\n      versioning {\r\n        enabled = true\r\n      }\r\n      # Enable server-side encryption by default\r\n      server_side_encryption_configuration {\r\n        rule {\r\n          apply_server_side_encryption_by_default {\r\n            sse_algorithm = \"aws:kms\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n    \r\n    resource \"aws_dynamodb_table\" \"terraform_locks\" {\r\n      name         = \"${var.namespace}-${var.name}-running-locks\"\r\n      billing_mode = \"PAY_PER_REQUEST\"\r\n      hash_key     = \"LockID\"\r\n      attribute {\r\n        name = \"LockID\"\r\n        type = \"S\"\r\n      }\r\n    }\r\n    \r\n    terraform {\r\n      backend \"s3\" {\r\n        bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n        key    = \"${var.stage}/terraform.tfstate\"\r\n        region = var.region\r\n        # Replace this with your DynamoDB table name!\r\n        dynamodb_table = \"${var.namespace}-${var.name}-running-locks\"\r\n        encrypt        = true\r\n      }\r\n    }\r\n\r\nNow when I try to delete EKS cluster using `terraform destroy` I get this error:\r\n\r\n    Error: error deleting S3 Bucket (abc-eks-terraform-state): BucketNotEmpty: The bucket you tried to delete is not empty. You must delete all versions in the bucket.\r\n\r\nI cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false)\r\n\r\nSo I wanted to know is there a way to tell terraform to delete s3 at the end once everything is deleted. Or is there a way to use the terraform which is there in s3 locally?\r\n\r\nWhat's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform.\r\n\r\n \r\n  [1]: https://www.terraform.io/docs/language/settings/backends/s3.html\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "So I created EKS Cluster using example given in [Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete) ", "keywords": ["cluster"]}, {"source": "Text", "text": "This is how it looks : resource \"aws_s3_bucket\" \"terraform_state\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" # Enable versioning so we can see the full revision history of our # state files versioning { enabled = true } # Enable server-side encryption by default server_side_encryption_configuration { rule { apply_server_side_encryption_by_default { sse_algorithm = \"aws:kms\" } } } } resource \"aws_dynamodb_table\" \"terraform_locks\" { name = \"${var.namespace}-${var.name}-running-locks\" billing_mode = \"PAY_PER_REQUEST\" hash_key = \"LockID\" attribute { name = \"LockID\" type = \"S\" } } terraform { backend \"s3\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" key = \"${var.stage}/terraform.tfstate\" region = var.region # Replace this with your DynamoDB table name! dynamodb_table = \"${var.namespace}-${var.name}-running-locks\" encrypt = true } } Now when I try to delete EKS cluster using `terraform destroy` ", "keywords": ["bill", "cluster"]}, {"source": "Text", "text": "What's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform. ", "keywords": ["cluster"]}]}, {"Id": "250843023", "PostHistoryTypeId": "5", "PostId": "68515932", "RevisionGUID": "637bf728-c42a-4c15-b453-92382a4d94f8", "CreationDate": "2021-07-25T09:20:42.963", "UserId": "5073662", "Comment": "added 839 characters in body", "Text": "So I created EKS Cluster using example given in  \r\n[Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete)\r\n\r\nOn top of this, I created AWS S3 and Dynamodb for storing state file and lock file respectively and added the same in [terraform backend config][1]. \r\n\r\nThis is how it looks : \r\n\r\n    resource \"aws_s3_bucket\" \"terraform_state\" {\r\n      bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n      # Enable versioning so we can see the full revision history of our\r\n      # state files\r\n      versioning {\r\n        enabled = true\r\n      }\r\n      # Enable server-side encryption by default\r\n      server_side_encryption_configuration {\r\n        rule {\r\n          apply_server_side_encryption_by_default {\r\n            sse_algorithm = \"aws:kms\"\r\n          }\r\n        }\r\n      }\r\n    }\r\n    \r\n    resource \"aws_dynamodb_table\" \"terraform_locks\" {\r\n      name         = \"${var.namespace}-${var.name}-running-locks\"\r\n      billing_mode = \"PAY_PER_REQUEST\"\r\n      hash_key     = \"LockID\"\r\n      attribute {\r\n        name = \"LockID\"\r\n        type = \"S\"\r\n      }\r\n    }\r\n    \r\n    terraform {\r\n      backend \"s3\" {\r\n        bucket = \"${var.namespace}-${var.name}-terraform-state\"\r\n        key    = \"${var.stage}/terraform.tfstate\"\r\n        region = var.region\r\n        # Replace this with your DynamoDB table name!\r\n        dynamodb_table = \"${var.namespace}-${var.name}-running-locks\"\r\n        encrypt        = true\r\n      }\r\n    }\r\n\r\nNow when I try to delete EKS cluster using `terraform destroy` I get this error:\r\n\r\n    Error: error deleting S3 Bucket (abc-eks-terraform-state): BucketNotEmpty: The bucket you tried to delete is not empty. You must delete all versions in the bucket.\r\n\r\nThis is the output of `terraform plan -destroy` after the cluster is partially destroyed because of s3 error\r\n\r\n    Changes to Outputs:\r\n      - dynamodb_table_name             = \"abc-eks-running-locks\" -> null\r\n      - eks_cluster_security_group_name = \"abc-staging-eks-cluster\" -> null\r\n      - eks_cluster_version             = \"1.19\" -> null\r\n      - eks_node_group_role_name        = \"abc-staging-eks-workers\" -> null\r\n      - private_subnet_cidrs            = [\r\n          - \"172.16.0.0/19\",\r\n          - \"172.16.32.0/19\",\r\n        ] -> null\r\n      - public_subnet_cidrs             = [\r\n          - \"172.16.96.0/19\",\r\n          - \"172.16.128.0/19\",\r\n        ] -> null\r\n      - s3_bucket_arn                   = \"arn:aws:s3:::abc-eks-terraform-state\" -> null\r\n      - vpc_cidr                        = \"172.16.0.0/16\" -> null\r\n\r\n\r\nI cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false)\r\n\r\nSo I wanted to know is there a way to tell terraform to delete s3 at the end once everything is deleted. Or is there a way to use the terraform which is there in s3 locally?\r\n\r\nWhat's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform.\r\n\r\n \r\n  [1]: https://www.terraform.io/docs/language/settings/backends/s3.html\r\n\r\n", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": [{"source": "Text", "text": "So I created EKS Cluster using example given in [Cloudposse eks terraform module](https://github.com/cloudposse/terraform-aws-eks-cluster/tree/master/examples/complete) ", "keywords": ["cluster"]}, {"source": "Text", "text": "This is how it looks : resource \"aws_s3_bucket\" \"terraform_state\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" # Enable versioning so we can see the full revision history of our # state files versioning { enabled = true } # Enable server-side encryption by default server_side_encryption_configuration { rule { apply_server_side_encryption_by_default { sse_algorithm = \"aws:kms\" } } } } resource \"aws_dynamodb_table\" \"terraform_locks\" { name = \"${var.namespace}-${var.name}-running-locks\" billing_mode = \"PAY_PER_REQUEST\" hash_key = \"LockID\" attribute { name = \"LockID\" type = \"S\" } } terraform { backend \"s3\" { bucket = \"${var.namespace}-${var.name}-terraform-state\" key = \"${var.stage}/terraform.tfstate\" region = var.region # Replace this with your DynamoDB table name! dynamodb_table = \"${var.namespace}-${var.name}-running-locks\" encrypt = true } } Now when I try to delete EKS cluster using `terraform destroy` ", "keywords": ["bill", "cluster"]}, {"source": "Text", "text": "This is the output of `terraform plan -destroy` after the cluster is partially destroyed because of s3 error Changes to Outputs: - dynamodb_table_name = \"abc-eks-running-locks\" -> null - eks_cluster_security_group_name = \"abc-staging-eks-cluster\" -> null - eks_cluster_version = \"1.19\" -> null - eks_node_group_role_name = \"abc-staging-eks-workers\" -> null - private_subnet_cidrs = [ - \"172.16.0.0/19\", - \"172.16.32.0/19\", ] -> null - public_subnet_cidrs = [ - \"172.16.96.0/19\", - \"172.16.128.0/19\", ] -> null - s3_bucket_arn = \"arn:aws:s3:::abc-eks-terraform-state\" -> null - vpc_cidr = \"172.16.0.0/16\" -> null I cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false) ", "keywords": ["cluster", "change"]}, {"source": "Text", "text": "What's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform. ", "keywords": ["cluster"]}]}, {"Id": "276908018", "PostHistoryTypeId": "6", "PostId": "68515932", "RevisionGUID": "987d20b1-185c-435d-bff7-0e94ca523226", "CreationDate": "2022-08-24T19:45:21.050", "UserId": "712765", "Comment": "edited tags", "Text": "<kubernetes><terraform><terraform-provider-aws><amazon-eks><cloudposse>", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "answers": [{"Id": "68523605", "PostTypeId": "2", "ParentId": "68515932", "CreationDate": "2021-07-26T01:20:47.653", "Score": "1", "Body": "<p>Generally, it is not recommended to keep your S3 bucket that you use for Terraform's backend state management in the Terraform state itself (for this exact reason). I've seen this explicitly stated in Terraform documentation, but I've been unable to find it in a quick search.</p>\n<p>What I would do to solve this issue:</p>\n<ol>\n<li><a href=\"https://www.terraform.io/docs/cli/commands/force-unlock.html\" rel=\"nofollow noreferrer\">Force unlock</a> the Terraform lock (<code>terraform force-unlock LOCK_ID</code>, where <code>LOCK_ID</code> is shown in the error message it gives you when you try to run a command).</li>\n<li>Download the state file from S3 (via the AWS console or CLI).</li>\n<li>Create a new S3 bucket (manually, not in Terraform).</li>\n<li>Manually upload the state file to the new bucket.</li>\n<li>Modify your Terraform backend config to use the new bucket.</li>\n<li>Empty the old S3 bucket (via the AWS console or CLI).</li>\n<li>Re-run Terraform and allow it to delete the old S3 bucket.</li>\n</ol>\n<p>Since it's still using the same old state file (just from a different bucket now), it won't re-create everything, and you'll be able to decouple your TF state bucket/file from other resources.</p>\n<p>If, for whatever reason, Terraform refuses to force-unlock, you can go into the DynamoDB table via the AWS console and delete the lock manually.</p>\n", "OwnerUserId": "612580", "LastActivityDate": "2021-07-26T01:20:47.653", "CommentCount": "0", "ContentLicense": "CC BY-SA 4.0", "history": [{"Id": "250870070", "PostHistoryTypeId": "2", "PostId": "68523605", "RevisionGUID": "7f9165d3-2496-4151-9084-d07b1e630649", "CreationDate": "2021-07-26T01:20:47.653", "UserId": "612580", "Text": "Generally, it is not recommended to keep your S3 bucket that you use for Terraform's backend state management in the Terraform state itself (for this exact reason). I've seen this explicitly stated in Terraform documentation, but I've been unable to find it in a quick search.\r\n\r\nWhat I would do to solve this issue:\r\n1. [Force unlock][1] the Terraform lock (`terraform force-unlock LOCK_ID`, where `LOCK_ID` is shown in the error message it gives you when you try to run a command).\r\n2. Download the state file from S3 (via the AWS console or CLI).\r\n3. Create a new S3 bucket (manually, not in Terraform).\r\n4. Manually upload the state file to the new bucket.\r\n5. Modify your Terraform backend config to use the new bucket.\r\n6. Empty the old S3 bucket (via the AWS console or CLI).\r\n7. Re-run Terraform and allow it to delete the old S3 bucket.\r\n\r\nSince it's still using the same old state file (just from a different bucket now), it won't re-create everything, and you'll be able to decouple your TF state bucket/file from other resources.\r\n\r\nIf, for whatever reason, Terraform refuses to force-unlock, you can go into the DynamoDB table via the AWS console and delete the lock manually.\r\n\r\n  [1]: https://www.terraform.io/docs/cli/commands/force-unlock.html", "ContentLicense": "CC BY-SA 4.0", "filtered-sentences": []}], "filtered-sentences": []}], "contains-topic": true, "filtered-sentences": [{"source": "Title", "text": "Terraform : \"Error: error deleting S3 Bucket\" while trying to destroy EKS Cluster", "keywords": ["cluster"]}, {"source": "Body", "text": "So I created EKS Cluster using example given in Cloudposse eks terraform module ", "keywords": ["cluster"]}, {"source": "Body", "text": "This is how it looks : Now when I try to delete EKS cluster using terraform destroy I get this error: ", "keywords": ["cluster"]}, {"source": "Body", "text": "This is the output of terraform plan -destroy after the cluster is partially destroyed because of s3 error I cannot manually delete the tfstate in s3 because that'll make terraform recreate everything, also I tried to remove s3 resource from tfstate but it gives me lock error(also tried to forcefully remove lock and with -lock=false) ", "keywords": ["cluster"]}, {"source": "Body", "text": "What's the correct approach to delete EKS cluster when your TF state resides in s3 backend and you have created s3 and dynamodb using same terraform.", "keywords": ["cluster"]}]}